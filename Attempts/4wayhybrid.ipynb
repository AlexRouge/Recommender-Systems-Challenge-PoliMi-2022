{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "208c1c41",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-26T22:26:51.415879Z",
     "iopub.status.busy": "2022-12-26T22:26:51.415417Z",
     "iopub.status.idle": "2022-12-26T22:26:56.274201Z",
     "shell.execute_reply": "2022-12-26T22:26:56.272761Z"
    },
    "papermill": {
     "duration": 4.870493,
     "end_time": "2022-12-26T22:26:56.277441",
     "exception": false,
     "start_time": "2022-12-26T22:26:51.406948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r ../input/recsys-repo/RecSys_Course_AT_PoliMi-master/* ./\n",
    "%config Completer.use_jedi = False\n",
    "%load_ext Cython\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "import matplotlib.pyplot as pyplot\n",
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "from Recommenders.GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "from Recommenders.GraphBased.P3alphaRecommender import P3alphaRecommender\n",
    "from Recommenders.EASE_R.EASE_R_Recommender import EASE_R_Recommender\n",
    "from Recommenders.KNN.ItemKNNCustomSimilarityRecommender import ItemKNNCustomSimilarityRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a65f14d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T22:26:56.292053Z",
     "iopub.status.busy": "2022-12-26T22:26:56.291601Z",
     "iopub.status.idle": "2022-12-26T22:26:56.843570Z",
     "shell.execute_reply": "2022-12-26T22:26:56.841898Z"
    },
    "papermill": {
     "duration": 0.561986,
     "end_time": "2022-12-26T22:26:56.845880",
     "exception": false,
     "start_time": "2022-12-26T22:26:56.283894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<41629x24507 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1554640 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_all_dataframe = pd.read_csv('/kaggle/input/urm-true-binary/URM_True_Binary.csv')\n",
    "URM_all_dataframe\n",
    "URM_all = sps.coo_matrix((URM_all_dataframe[\"Data\"].values, \n",
    "                          (URM_all_dataframe[\"UserID\"].values, URM_all_dataframe[\"ItemID\"].values)))\n",
    "URM_all = URM_all.tocsr() # to obtain fast access to rows (users)\n",
    "URM_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8ad8077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T22:26:56.861802Z",
     "iopub.status.busy": "2022-12-26T22:26:56.861369Z",
     "iopub.status.idle": "2022-12-26T22:26:57.376757Z",
     "shell.execute_reply": "2022-12-26T22:26:57.375930Z"
    },
    "papermill": {
     "duration": 0.52609,
     "end_time": "2022-12-26T22:26:57.379165",
     "exception": false,
     "start_time": "2022-12-26T22:26:56.853075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<41629x24507 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1243712 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_train_dataframe = pd.read_csv('/kaggle/input/urm-split/Train_df.csv')\n",
    "URM_train_dataframe\n",
    "URM_train = sps.coo_matrix((URM_train_dataframe[\"Data\"].values, \n",
    "                          (URM_train_dataframe[\"UserID\"].values, URM_train_dataframe[\"ItemID\"].values)))\n",
    "URM_train = URM_train.tocsr() # to obtain fast access to rows (users)\n",
    "URM_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf41554b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T22:26:57.393866Z",
     "iopub.status.busy": "2022-12-26T22:26:57.393322Z",
     "iopub.status.idle": "2022-12-26T22:26:57.522948Z",
     "shell.execute_reply": "2022-12-26T22:26:57.521631Z"
    },
    "papermill": {
     "duration": 0.140263,
     "end_time": "2022-12-26T22:26:57.525967",
     "exception": false,
     "start_time": "2022-12-26T22:26:57.385704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<41629x24507 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1554640 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_val_dataframe = pd.read_csv('/kaggle/input/urm-split/Test_df.csv')\n",
    "URM_val_dataframe\n",
    "URM_valid = sps.coo_matrix((URM_val_dataframe[\"Data\"].values, \n",
    "                          (URM_val_dataframe[\"UserID\"].values, URM_val_dataframe[\"ItemID\"].values)))\n",
    "URM_valid = URM_all.tocsr() # to obtain fast access to rows (users)\n",
    "URM_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d02202a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T22:26:57.541964Z",
     "iopub.status.busy": "2022-12-26T22:26:57.541605Z",
     "iopub.status.idle": "2022-12-26T22:26:57.614161Z",
     "shell.execute_reply": "2022-12-26T22:26:57.612682Z"
    },
    "papermill": {
     "duration": 0.083069,
     "end_time": "2022-12-26T22:26:57.616866",
     "exception": false,
     "start_time": "2022-12-26T22:26:57.533797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "\n",
    "#create an evaluator object to evaluate validation set\n",
    "#we will use it for hyperparameter tuning\n",
    "evaluator_valid = EvaluatorHoldout(URM_valid, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d28c3df2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T22:26:57.632869Z",
     "iopub.status.busy": "2022-12-26T22:26:57.632028Z",
     "iopub.status.idle": "2022-12-26T22:26:57.944813Z",
     "shell.execute_reply": "2022-12-26T22:26:57.943443Z"
    },
    "papermill": {
     "duration": 0.324069,
     "end_time": "2022-12-26T22:26:57.947470",
     "exception": false,
     "start_time": "2022-12-26T22:26:57.623401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "from Recommenders.Recommender_utils import check_matrix\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from Recommenders.BaseSimilarityMatrixRecommender import BaseItemSimilarityMatrixRecommender\n",
    "from Utils.seconds_to_biggest_unit import seconds_to_biggest_unit\n",
    "import time, sys\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# os.environ[\"PYTHONWARNINGS\"] = ('ignore::exceptions.ConvergenceWarning:sklearn.linear_model')\n",
    "# os.environ[\"PYTHONWARNINGS\"] = ('ignore:Objective did not converge:ConvergenceWarning:')\n",
    "\n",
    "class SLIMElasticNetRecommender(BaseItemSimilarityMatrixRecommender):\n",
    "    \"\"\"\n",
    "    Train a Sparse Linear Methods (SLIM) item similarity model.\n",
    "    NOTE: ElasticNet solver is parallel, a single intance of SLIM_ElasticNet will\n",
    "          make use of half the cores available\n",
    "    See:\n",
    "        Efficient Top-N Recommendation by Linear Regression,\n",
    "        M. Levy and K. Jack, LSRS workshop at RecSys 2013.\n",
    "        SLIM: Sparse linear methods for top-n recommender systems,\n",
    "        X. Ning and G. Karypis, ICDM 2011.\n",
    "        http://glaros.dtc.umn.edu/gkhome/fetch/papers/SLIM2011icdm.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"SLIMElasticNetRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, verbose = True):\n",
    "        super(SLIMElasticNetRecommender, self).__init__(URM_train, verbose = verbose)\n",
    "\n",
    "    @ignore_warnings(category=ConvergenceWarning)\n",
    "    def fit(self, l1_ratio=0.1, alpha = 1.0, positive_only=True, topK = 100,**earlystopping_kwargs):\n",
    "\n",
    "        assert l1_ratio>= 0 and l1_ratio<=1, \"{}: l1_ratio must be between 0 and 1, provided value was {}\".format(self.RECOMMENDER_NAME, l1_ratio)\n",
    "\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.positive_only = positive_only\n",
    "        self.topK = topK\n",
    "\n",
    "\n",
    "        # initialize the ElasticNet model\n",
    "        self.model = ElasticNet(alpha=alpha,\n",
    "                                l1_ratio=self.l1_ratio,\n",
    "                                positive=self.positive_only,\n",
    "                                fit_intercept=False,\n",
    "                                copy_X=False,\n",
    "                                precompute=True,\n",
    "                                selection='random',\n",
    "                                max_iter=100,\n",
    "                                tol=1e-4)\n",
    "\n",
    "        URM_train = check_matrix(self.URM_train, 'csc', dtype=np.float32)\n",
    "\n",
    "        n_items = URM_train.shape[1]\n",
    "\n",
    "        # Use array as it reduces memory requirements compared to lists\n",
    "        dataBlock = 10000000\n",
    "\n",
    "        rows = np.zeros(dataBlock, dtype=np.int32)\n",
    "        cols = np.zeros(dataBlock, dtype=np.int32)\n",
    "        values = np.zeros(dataBlock, dtype=np.float32)\n",
    "\n",
    "        numCells = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        start_time_printBatch = start_time\n",
    "\n",
    "        # fit each item's factors sequentially (not in parallel)\n",
    "        for currentItem in range(n_items):\n",
    "\n",
    "            # get the target column\n",
    "            y = URM_train[:, currentItem].toarray()\n",
    "\n",
    "            # set the j-th column of X to zero\n",
    "            start_pos = URM_train.indptr[currentItem]\n",
    "            end_pos = URM_train.indptr[currentItem + 1]\n",
    "\n",
    "            current_item_data_backup = URM_train.data[start_pos: end_pos].copy()\n",
    "            URM_train.data[start_pos: end_pos] = 0.0\n",
    "\n",
    "            # fit one ElasticNet model per column\n",
    "            self.model.fit(URM_train, y)\n",
    "\n",
    "            # self.model.coef_ contains the coefficient of the ElasticNet model\n",
    "            # let's keep only the non-zero values\n",
    "\n",
    "            # Select topK values\n",
    "            # Sorting is done in three steps. Faster then plain np.argsort for higher number of items\n",
    "            # - Partition the data to extract the set of relevant items\n",
    "            # - Sort only the relevant items\n",
    "            # - Get the original item index\n",
    "\n",
    "            nonzero_model_coef_index = self.model.sparse_coef_.indices\n",
    "            nonzero_model_coef_value = self.model.sparse_coef_.data\n",
    "\n",
    "            local_topK = min(len(nonzero_model_coef_value)-1, self.topK)\n",
    "\n",
    "            relevant_items_partition = (-nonzero_model_coef_value).argpartition(local_topK)[0:local_topK]\n",
    "            relevant_items_partition_sorting = np.argsort(-nonzero_model_coef_value[relevant_items_partition])\n",
    "            ranking = relevant_items_partition[relevant_items_partition_sorting]\n",
    "\n",
    "            for index in range(len(ranking)):\n",
    "\n",
    "                if numCells == len(rows):\n",
    "                    rows = np.concatenate((rows, np.zeros(dataBlock, dtype=np.int32)))\n",
    "                    cols = np.concatenate((cols, np.zeros(dataBlock, dtype=np.int32)))\n",
    "                    values = np.concatenate((values, np.zeros(dataBlock, dtype=np.float32)))\n",
    "\n",
    "\n",
    "                rows[numCells] = nonzero_model_coef_index[ranking[index]]\n",
    "                cols[numCells] = currentItem\n",
    "                values[numCells] = nonzero_model_coef_value[ranking[index]]\n",
    "\n",
    "                numCells += 1\n",
    "\n",
    "            # finally, replace the original values of the j-th column\n",
    "            URM_train.data[start_pos:end_pos] = current_item_data_backup\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "            new_time_value, new_time_unit = seconds_to_biggest_unit(elapsed_time)\n",
    "\n",
    "\n",
    "            if time.time() - start_time_printBatch > 300 or currentItem == n_items-1:\n",
    "                self._print(\"Processed {} ({:4.1f}%) in {:.2f} {}. Items per second: {:.2f}\".format(\n",
    "                    currentItem+1,\n",
    "                    100.0* float(currentItem+1)/n_items,\n",
    "                    new_time_value,\n",
    "                    new_time_unit,\n",
    "                    float(currentItem)/elapsed_time))\n",
    "\n",
    "                sys.stdout.flush()\n",
    "                sys.stderr.flush()\n",
    "\n",
    "                start_time_printBatch = time.time()\n",
    "\n",
    "        # generate the sparse weight matrix\n",
    "        self.W_sparse = sps.csr_matrix((values[:numCells], (rows[:numCells], cols[:numCells])),\n",
    "                                       shape=(n_items, n_items), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46f6fd45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T22:26:57.962795Z",
     "iopub.status.busy": "2022-12-26T22:26:57.962375Z",
     "iopub.status.idle": "2022-12-26T22:26:58.131260Z",
     "shell.execute_reply": "2022-12-26T22:26:58.130231Z"
    },
    "papermill": {
     "duration": 0.179829,
     "end_time": "2022-12-26T22:26:58.133996",
     "exception": false,
     "start_time": "2022-12-26T22:26:57.954167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import implicit\n",
    "import numpy as np\n",
    "\n",
    "from Recommenders.BaseMatrixFactorizationRecommender import BaseMatrixFactorizationRecommender\n",
    "\n",
    "\n",
    "class IALSRecommender_implicit(BaseMatrixFactorizationRecommender):\n",
    "    \"\"\"\n",
    "    ALS implemented with implicit following guideline of\n",
    "    https://medium.com/radon-dev/als-implicit-collaborative-filtering-5ed653ba39fe\n",
    "    IDEA:\n",
    "    Recomputing x_{u} and y_i can be done with Stochastic Gradient Descent, but this is a non-convex optimization problem.\n",
    "    We can convert it into a set of quadratic problems, by keeping either x_u or y_i fixed while optimizing the other.\n",
    "    In that case, we can iteratively solve x and y by alternating between them until the algorithm converges.\n",
    "    This is Alternating Least Squares.\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"IALSRecommender_implicit\"\n",
    "\n",
    "    def __init__(self, URM_train, verbose=True):\n",
    "        super(IALSRecommender_implicit, self).__init__(URM_train, verbose=verbose)\n",
    "\n",
    "    def fit(self, n_factors=50, regularization=0.001847510119137634, iterations=30, num_threads=2):\n",
    "        self.n_factors = n_factors\n",
    "        self.regularization = regularization\n",
    "        self.iterations = iterations\n",
    "\n",
    "        sparse_item_user = self.URM_train.T\n",
    "\n",
    "        # Initialize the als model and fit it using the sparse item-user matrix\n",
    "        model = implicit.als.AlternatingLeastSquares(factors=self.n_factors, regularization=self.regularization,\n",
    "                                                     iterations=self.iterations, num_threads=num_threads)\n",
    "\n",
    "        alpha_val = 2\n",
    "        # Calculate the confidence by multiplying it by our alpha value.\n",
    "\n",
    "        data_conf = (sparse_item_user * alpha_val).astype('double')\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(data_conf)\n",
    "\n",
    "        # Get the user and item vectors from our trained model\n",
    "        self.USER_factors = model.user_factors\n",
    "        self.ITEM_factors = model.item_factors\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute=None):\n",
    "        \"\"\"\n",
    "        USER_factors is n_users x n_factors\n",
    "        ITEM_factors is n_items x n_factors\n",
    "\n",
    "        The prediction for cold users will always be -inf for ALL items\n",
    "\n",
    "        :param user_id_array:\n",
    "        :param items_to_compute:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        assert self.USER_factors.shape[1] == self.ITEM_factors.shape[1], \\\n",
    "            \"{}: User and Item factors have inconsistent shape\".format(self.RECOMMENDER_NAME)\n",
    "\n",
    "        assert self.USER_factors.shape[0] > np.max(user_id_array), \\\n",
    "            \"{}: Cold users not allowed. Users in trained model are {}, requested prediction for users up to {}\".format(\n",
    "                self.RECOMMENDER_NAME, self.USER_factors.shape[0], np.max(user_id_array))\n",
    "\n",
    "        if items_to_compute is not None:\n",
    "            item_scores = - np.ones((len(user_id_array), self.ITEM_factors.shape[0]), dtype=np.float32) * np.inf\n",
    "            item_scores[:, items_to_compute] = np.dot(self.USER_factors[user_id_array],\n",
    "                                                      np.transpose(self.ITEM_factors[items_to_compute, :]))\n",
    "\n",
    "        else:\n",
    "            item_factors_T = np.transpose(self.ITEM_factors)\n",
    "            user_factors = self.USER_factors[user_id_array]\n",
    "            item_scores = np.dot(user_factors, item_factors_T)\n",
    "\n",
    "        # No need to select only the specific negative items or warm users because the -inf score will not change\n",
    "        if self.use_bias:\n",
    "            item_scores += self.ITEM_bias + self.GLOBAL_bias\n",
    "            item_scores = np.transpose(np.transpose(item_scores) + self.USER_bias[user_id_array])\n",
    "\n",
    "        return item_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "882deb59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T22:26:58.150392Z",
     "iopub.status.busy": "2022-12-26T22:26:58.149648Z",
     "iopub.status.idle": "2022-12-26T22:26:58.156377Z",
     "shell.execute_reply": "2022-12-26T22:26:58.154642Z"
    },
    "papermill": {
     "duration": 0.017587,
     "end_time": "2022-12-26T22:26:58.159431",
     "exception": false,
     "start_time": "2022-12-26T22:26:58.141844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_folder_path = \"result_experiments/\"\n",
    "\n",
    "# If directory does not exist, create\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20cd2b47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T22:26:58.174652Z",
     "iopub.status.busy": "2022-12-26T22:26:58.174196Z",
     "iopub.status.idle": "2022-12-26T22:47:57.277557Z",
     "shell.execute_reply": "2022-12-26T22:47:57.275828Z"
    },
    "papermill": {
     "duration": 1259.114381,
     "end_time": "2022-12-26T22:47:57.280394",
     "exception": false,
     "start_time": "2022-12-26T22:26:58.166013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: Processed 5306 (21.7%) in 5.00 min. Items per second: 17.68\n",
      "SLIMElasticNetRecommender: Processed 11204 (45.7%) in 10.00 min. Items per second: 18.67\n",
      "SLIMElasticNetRecommender: Processed 17225 (70.3%) in 15.00 min. Items per second: 19.14\n",
      "SLIMElasticNetRecommender: Processed 23276 (95.0%) in 20.00 min. Items per second: 19.39\n",
      "SLIMElasticNetRecommender: Processed 24507 (100.0%) in 20.98 min. Items per second: 19.46\n"
     ]
    }
   ],
   "source": [
    "recommender_SLIMElasticNet = SLIMElasticNetRecommender(URM_train)\n",
    "recommender_SLIMElasticNet.fit(l1_ratio = 0.02, alpha = 0.0018503383172588782,  positive_only = True, topK = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "828fa748",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T22:47:57.296048Z",
     "iopub.status.busy": "2022-12-26T22:47:57.295604Z",
     "iopub.status.idle": "2022-12-26T22:48:07.378442Z",
     "shell.execute_reply": "2022-12-26T22:48:07.377090Z"
    },
    "papermill": {
     "duration": 10.093585,
     "end_time": "2022-12-26T22:48:07.380902",
     "exception": false,
     "start_time": "2022-12-26T22:47:57.287317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RP3betaRecommender: Similarity column 24507 (100.0%), 3024.32 column/sec. Elapsed time 8.10 sec\n"
     ]
    }
   ],
   "source": [
    "RP3beta_all = RP3betaRecommender(URM_train)\n",
    "RP3beta_all.fit(alpha= 1.0, beta= 0.28666076265452467, topK= 57, implicit= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9abf91c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T22:48:07.395471Z",
     "iopub.status.busy": "2022-12-26T22:48:07.395100Z",
     "iopub.status.idle": "2022-12-26T22:56:44.320682Z",
     "shell.execute_reply": "2022-12-26T22:56:44.319655Z"
    },
    "papermill": {
     "duration": 516.935982,
     "end_time": "2022-12-26T22:56:44.323503",
     "exception": false,
     "start_time": "2022-12-26T22:48:07.387521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EASE_R_Recommender: Fitting model... \n",
      "EASE_R_Recommender: Fitting model... done in 8.14 min\n"
     ]
    }
   ],
   "source": [
    "EASE_R = EASE_R_Recommender(URM_train)\n",
    "#%%\n",
    "EASE_R.fit(topK = 416, l2_norm = 115.67139771839786, normalize_matrix = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "875629db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T22:56:44.339009Z",
     "iopub.status.busy": "2022-12-26T22:56:44.338661Z",
     "iopub.status.idle": "2022-12-26T23:01:09.525411Z",
     "shell.execute_reply": "2022-12-26T23:01:09.524565Z"
    },
    "papermill": {
     "duration": 265.19737,
     "end_time": "2022-12-26T23:01:09.528132",
     "exception": false,
     "start_time": "2022-12-26T22:56:44.330762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749b73f3f6fe460b983e5ebd5d96fc67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "impl_IALS =  IALSRecommender_implicit(URM_train)\n",
    "impl_IALS.fit(n_factors= 287, regularization= 40.37562274633393, iterations=70, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "384e3a40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T23:01:09.548890Z",
     "iopub.status.busy": "2022-12-26T23:01:09.548454Z",
     "iopub.status.idle": "2022-12-26T23:01:09.555199Z",
     "shell.execute_reply": "2022-12-26T23:01:09.554346Z"
    },
    "papermill": {
     "duration": 0.019935,
     "end_time": "2022-12-26T23:01:09.557656",
     "exception": false,
     "start_time": "2022-12-26T23:01:09.537721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "slim_matrix = recommender_SLIMElasticNet.W_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "070a5db4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T23:01:09.578424Z",
     "iopub.status.busy": "2022-12-26T23:01:09.577749Z",
     "iopub.status.idle": "2022-12-26T23:01:09.582971Z",
     "shell.execute_reply": "2022-12-26T23:01:09.582131Z"
    },
    "papermill": {
     "duration": 0.020609,
     "end_time": "2022-12-26T23:01:09.587227",
     "exception": false,
     "start_time": "2022-12-26T23:01:09.566618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rp3_matrix = RP3beta_all.W_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efa07696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T23:01:09.608605Z",
     "iopub.status.busy": "2022-12-26T23:01:09.608132Z",
     "iopub.status.idle": "2022-12-26T23:01:14.061492Z",
     "shell.execute_reply": "2022-12-26T23:01:14.060695Z"
    },
    "papermill": {
     "duration": 4.466787,
     "end_time": "2022-12-26T23:01:14.064011",
     "exception": false,
     "start_time": "2022-12-26T23:01:09.597224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ease_matrix = sps.csr_matrix(EASE_R.W_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1aa0d1b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T23:01:14.079815Z",
     "iopub.status.busy": "2022-12-26T23:01:14.079463Z",
     "iopub.status.idle": "2022-12-26T23:05:04.261981Z",
     "shell.execute_reply": "2022-12-26T23:05:04.261231Z"
    },
    "papermill": {
     "duration": 230.192739,
     "end_time": "2022-12-26T23:05:04.263969",
     "exception": false,
     "start_time": "2022-12-26T23:01:14.071230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 41629 (100.0%) in 23.38 sec. Users per second: 1781\n",
      "Alpha: 0.0, Beta: 0.0, Theta: 1.0, MAP: 0.033378569464889915\n",
      "EvaluatorHoldout: Processed 41629 (100.0%) in 39.14 sec. Users per second: 1064\n",
      "Alpha: 0.0, Beta: 0.5, Theta: 0.5, MAP: 0.035351897162652496\n",
      "EvaluatorHoldout: Processed 41629 (100.0%) in 38.43 sec. Users per second: 1083\n",
      "Alpha: 0.0, Beta: 1.0, Theta: 0.0, MAP: 0.034900350869565236\n",
      "EvaluatorHoldout: Processed 41629 (100.0%) in 40.89 sec. Users per second: 1018\n",
      "Alpha: 0.5, Beta: 0.0, Theta: 0.5, MAP: 0.03579859335696452\n",
      "EvaluatorHoldout: Processed 41629 (100.0%) in 47.43 sec. Users per second: 878\n",
      "Alpha: 0.5, Beta: 0.5, Theta: 0.0, MAP: 0.03546774474601058\n",
      "EvaluatorHoldout: Processed 41629 (100.0%) in 40.06 sec. Users per second: 1039\n",
      "Alpha: 1.0, Beta: 0.0, Theta: 0.0, MAP: 0.03565055286169016\n"
     ]
    }
   ],
   "source": [
    "from Recommenders.KNN.ItemKNNCustomSimilarityRecommender import ItemKNNCustomSimilarityRecommender\n",
    "\n",
    "for alpha in np.arange(0, 1.1, 0.5):\n",
    "    for beta in np.arange(0, 1.1-alpha, 0.5):\n",
    "        new_similarity = slim_matrix * alpha + ease_matrix * beta + rp3_matrix * (1-(alpha+beta))\n",
    "        recommender_object = ItemKNNCustomSimilarityRecommender(URM_train)\n",
    "        recommender_object.fit(new_similarity)\n",
    "        result_df, _ = evaluator_valid.evaluateRecommender(recommender_object)\n",
    "        print(f\"Alpha: {alpha}, Beta: {beta}, Theta: {1-(alpha+beta)}, MAP: {result_df.loc[10]['MAP']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48806a39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T23:05:04.281163Z",
     "iopub.status.busy": "2022-12-26T23:05:04.280580Z",
     "iopub.status.idle": "2022-12-26T23:05:04.284213Z",
     "shell.execute_reply": "2022-12-26T23:05:04.283514Z"
    },
    "papermill": {
     "duration": 0.014882,
     "end_time": "2022-12-26T23:05:04.286484",
     "exception": false,
     "start_time": "2022-12-26T23:05:04.271602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#impl_IALS.W_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68a31694",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T23:05:04.303826Z",
     "iopub.status.busy": "2022-12-26T23:05:04.303453Z",
     "iopub.status.idle": "2022-12-26T23:05:04.309925Z",
     "shell.execute_reply": "2022-12-26T23:05:04.308865Z"
    },
    "papermill": {
     "duration": 0.018457,
     "end_time": "2022-12-26T23:05:04.312615",
     "exception": false,
     "start_time": "2022-12-26T23:05:04.294158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from Recommenders.SLIM.Cython.SLIM_BPR_Cython import SLIM_BPR_Cython\\nrecommender_SLIM_BPR_Cython = SLIM_BPR_Cython(URM_all)\\nrecommender_SLIM_BPR_Cython.fit(epochs= 615, sgd_mode= 'sgd', topK= 49, lambda_i= 0.0001, lambda_j= 0.0017579136035800475, learning_rate= 0.032671047315169746)\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from Recommenders.SLIM.Cython.SLIM_BPR_Cython import SLIM_BPR_Cython\n",
    "recommender_SLIM_BPR_Cython = SLIM_BPR_Cython(URM_all)\n",
    "recommender_SLIM_BPR_Cython.fit(epochs= 615, sgd_mode= 'sgd', topK= 49, lambda_i= 0.0001, lambda_j= 0.0017579136035800475, learning_rate= 0.032671047315169746)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "376e8e1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T23:05:04.330072Z",
     "iopub.status.busy": "2022-12-26T23:05:04.329355Z",
     "iopub.status.idle": "2022-12-26T23:05:04.336396Z",
     "shell.execute_reply": "2022-12-26T23:05:04.334847Z"
    },
    "papermill": {
     "duration": 0.018303,
     "end_time": "2022-12-26T23:05:04.338798",
     "exception": false,
     "start_time": "2022-12-26T23:05:04.320495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(\"MAP of the starting models\")\\n\\nresult_df, _ = evaluator_valid.evaluateRecommender(recommender_SLIMElasticNet)\\nprint(\"SLIM - MAP: {}\".format(result_df.loc[10][\"MAP\"]))\\n\\nresult_df, _ = evaluator_valid.evaluateRecommender(RP3beta_all)\\nprint(\"RP3beta - MAP: {}\".format(result_df.loc[10][\"MAP\"]))\\n\\nresult_df, _ = evaluator_valid.evaluateRecommender(EASE_R)\\nprint(\"Ease - MAP: {}\".format(result_df.loc[10][\"MAP\"]))\\n\\nresult_df, _ = evaluator_valid.evaluateRecommender(impl_IALS)\\nprint(\"iIALS - MAP: {}\".format(result_df.loc[10][\"MAP\"]))'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(\"MAP of the starting models\")\n",
    "\n",
    "result_df, _ = evaluator_valid.evaluateRecommender(recommender_SLIMElasticNet)\n",
    "print(\"SLIM - MAP: {}\".format(result_df.loc[10][\"MAP\"]))\n",
    "\n",
    "result_df, _ = evaluator_valid.evaluateRecommender(RP3beta_all)\n",
    "print(\"RP3beta - MAP: {}\".format(result_df.loc[10][\"MAP\"]))\n",
    "\n",
    "result_df, _ = evaluator_valid.evaluateRecommender(EASE_R)\n",
    "print(\"Ease - MAP: {}\".format(result_df.loc[10][\"MAP\"]))\n",
    "\n",
    "result_df, _ = evaluator_valid.evaluateRecommender(impl_IALS)\n",
    "print(\"iIALS - MAP: {}\".format(result_df.loc[10][\"MAP\"]))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc2622a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T23:05:04.356657Z",
     "iopub.status.busy": "2022-12-26T23:05:04.356241Z",
     "iopub.status.idle": "2022-12-26T23:05:04.365255Z",
     "shell.execute_reply": "2022-12-26T23:05:04.363147Z"
    },
    "papermill": {
     "duration": 0.021257,
     "end_time": "2022-12-26T23:05:04.367863",
     "exception": false,
     "start_time": "2022-12-26T23:05:04.346606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from numpy import linalg as LA\\nfrom Recommenders.BaseRecommender import BaseRecommender\\n\\nclass DifferentLossScoresHybridRecommender(BaseRecommender):\\n\\n    RECOMMENDER_NAME = \"DifferentLossScoresHybridRecommender\"\\n\\n\\n    def __init__(self, URM_train, recommender_1, recommender_2, recommender_3, recommender_4):\\n        super(DifferentLossScoresHybridRecommender, self).__init__(URM_train)\\n\\n        self.URM_train = sps.csr_matrix(URM_train)\\n        self.recommender_1 = recommender_1\\n        self.recommender_2 = recommender_2\\n        self.recommender_3 = recommender_3\\n        self.recommender_4 = recommender_4\\n        \\n        \\n        \\n    def fit(self, norm, alpha = 0.5, beta = 0.5, theta = 0):\\n\\n        self.alpha = alpha\\n        self.beta = beta\\n        self.theta = theta\\n        self.norm = norm\\n\\n\\n    def _compute_item_score(self, user_id_array, items_to_compute):\\n        \\n        item_weights_1 = self.recommender_1._compute_item_score(user_id_array)\\n        item_weights_2 = self.recommender_2._compute_item_score(user_id_array)\\n        item_weights_3 = self.recommender_3._compute_item_score(user_id_array)\\n        item_weights_4 = self.recommender_4._compute_item_score(user_id_array)\\n\\n        norm_item_weights_1 = LA.norm(item_weights_1, self.norm)\\n        norm_item_weights_2 = LA.norm(item_weights_2, self.norm)\\n        norm_item_weights_3 = LA.norm(item_weights_3, self.norm)\\n        norm_item_weights_4 = LA.norm(item_weights_4, self.norm)\\n        \\n        \\n        if norm_item_weights_1 == 0:\\n            raise ValueError(\"Norm {} of item weights for recommender 1 is zero. Avoiding division by zero\".format(self.norm))\\n        \\n        if norm_item_weights_2 == 0:\\n            raise ValueError(\"Norm {} of item weights for recommender 2 is zero. Avoiding division by zero\".format(self.norm))\\n            \\n        if norm_item_weights_3 == 0:\\n            raise ValueError(\"Norm {} of item weights for recommender 3 is zero. Avoiding division by zero\".format(self.norm))\\n            \\n        if norm_item_weights_4 == 0:\\n            raise ValueError(\"Norm {} of item weights for recommender 4 is zero. Avoiding division by zero\".format(self.norm))\\n        \\n        item_weights = item_weights_1 / norm_item_weights_1 * self.alpha + item_weights_2 / norm_item_weights_2 * self.beta + item_weights_3 / norm_item_weights_3 * self.theta + item_weights_4 / norm_item_weights_4 * (1-(self.alpha+self.beta+self.theta))\\n\\n        return item_weights'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from numpy import linalg as LA\n",
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "\n",
    "class DifferentLossScoresHybridRecommender(BaseRecommender):\n",
    "\n",
    "    RECOMMENDER_NAME = \"DifferentLossScoresHybridRecommender\"\n",
    "\n",
    "\n",
    "    def __init__(self, URM_train, recommender_1, recommender_2, recommender_3, recommender_4):\n",
    "        super(DifferentLossScoresHybridRecommender, self).__init__(URM_train)\n",
    "\n",
    "        self.URM_train = sps.csr_matrix(URM_train)\n",
    "        self.recommender_1 = recommender_1\n",
    "        self.recommender_2 = recommender_2\n",
    "        self.recommender_3 = recommender_3\n",
    "        self.recommender_4 = recommender_4\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self, norm, alpha = 0.5, beta = 0.5, theta = 0):\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.theta = theta\n",
    "        self.norm = norm\n",
    "\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute):\n",
    "        \n",
    "        item_weights_1 = self.recommender_1._compute_item_score(user_id_array)\n",
    "        item_weights_2 = self.recommender_2._compute_item_score(user_id_array)\n",
    "        item_weights_3 = self.recommender_3._compute_item_score(user_id_array)\n",
    "        item_weights_4 = self.recommender_4._compute_item_score(user_id_array)\n",
    "\n",
    "        norm_item_weights_1 = LA.norm(item_weights_1, self.norm)\n",
    "        norm_item_weights_2 = LA.norm(item_weights_2, self.norm)\n",
    "        norm_item_weights_3 = LA.norm(item_weights_3, self.norm)\n",
    "        norm_item_weights_4 = LA.norm(item_weights_4, self.norm)\n",
    "        \n",
    "        \n",
    "        if norm_item_weights_1 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 1 is zero. Avoiding division by zero\".format(self.norm))\n",
    "        \n",
    "        if norm_item_weights_2 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 2 is zero. Avoiding division by zero\".format(self.norm))\n",
    "            \n",
    "        if norm_item_weights_3 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 3 is zero. Avoiding division by zero\".format(self.norm))\n",
    "            \n",
    "        if norm_item_weights_4 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 4 is zero. Avoiding division by zero\".format(self.norm))\n",
    "        \n",
    "        item_weights = item_weights_1 / norm_item_weights_1 * self.alpha + item_weights_2 / norm_item_weights_2 * self.beta + item_weights_3 / norm_item_weights_3 * self.theta + item_weights_4 / norm_item_weights_4 * (1-(self.alpha+self.beta+self.theta))\n",
    "\n",
    "        return item_weights\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5e4ecf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T23:05:04.385668Z",
     "iopub.status.busy": "2022-12-26T23:05:04.385260Z",
     "iopub.status.idle": "2022-12-26T23:05:04.393687Z",
     "shell.execute_reply": "2022-12-26T23:05:04.392317Z"
    },
    "papermill": {
     "duration": 0.020107,
     "end_time": "2022-12-26T23:05:04.396067",
     "exception": false,
     "start_time": "2022-12-26T23:05:04.375960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import random\\n\\nrecommender_object = DifferentLossScoresHybridRecommender(URM_train, recommender_SLIMElasticNet, RP3beta_all, EASE_R, impl_IALS)\\n\\nbest_model = {\\n    \"MAP\" : 0,\\n    \"alpha\" : 0,\\n    \"beta\": 0,\\n    \"theta\": 0,\\n    \"norm\" : 0\\n}\\n\\nn_searches = 0\\n\\nfor norm in [1,2]:\\n    while n_searches<50:\\n        alpha = random.uniform(0, 1)\\n        beta = random.uniform(0, 1-alpha)\\n        theta = random.uniform(0, 1- (alpha+beta))\\n        print(\"----\")\\n        recommender_object.fit(norm, alpha, beta, theta)\\n\\n        result_df, _ = evaluator_valid.evaluateRecommender(recommender_object)\\n        print(\"Norm: {}, Alpha: {}, Beta: {}, Theta: {}, Gamma: {}, Result: {}\".format(norm, alpha, beta, theta, 1-(alpha+beta+theta), result_df.loc[10][\"MAP\"]))\\n\\n        if result_df.loc[10][\"MAP\"] > best_model[\"MAP\"]:\\n            best_model[\"MAP\"] = result_df.loc[10][\"MAP\"]\\n            best_model[\"alpha\"] = alpha\\n            best_model[\"beta\"] = beta\\n            best_model[\"theta\"] = theta\\n            best_model[\"norm\"] = norm\\n                \\n        n_searches += 1\\n    n_searches = 30\\nprint(\"----\")\\nprint(\"Best model has MAP: {} with alpha: {}, norm: {}\".format(best_model[\"MAP\"], best_model[\"alpha\"], best_model[\"norm\"]))\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import random\n",
    "\n",
    "recommender_object = DifferentLossScoresHybridRecommender(URM_train, recommender_SLIMElasticNet, RP3beta_all, EASE_R, impl_IALS)\n",
    "\n",
    "best_model = {\n",
    "    \"MAP\" : 0,\n",
    "    \"alpha\" : 0,\n",
    "    \"beta\": 0,\n",
    "    \"theta\": 0,\n",
    "    \"norm\" : 0\n",
    "}\n",
    "\n",
    "n_searches = 0\n",
    "\n",
    "for norm in [1,2]:\n",
    "    while n_searches<50:\n",
    "        alpha = random.uniform(0, 1)\n",
    "        beta = random.uniform(0, 1-alpha)\n",
    "        theta = random.uniform(0, 1- (alpha+beta))\n",
    "        print(\"----\")\n",
    "        recommender_object.fit(norm, alpha, beta, theta)\n",
    "\n",
    "        result_df, _ = evaluator_valid.evaluateRecommender(recommender_object)\n",
    "        print(\"Norm: {}, Alpha: {}, Beta: {}, Theta: {}, Gamma: {}, Result: {}\".format(norm, alpha, beta, theta, 1-(alpha+beta+theta), result_df.loc[10][\"MAP\"]))\n",
    "\n",
    "        if result_df.loc[10][\"MAP\"] > best_model[\"MAP\"]:\n",
    "            best_model[\"MAP\"] = result_df.loc[10][\"MAP\"]\n",
    "            best_model[\"alpha\"] = alpha\n",
    "            best_model[\"beta\"] = beta\n",
    "            best_model[\"theta\"] = theta\n",
    "            best_model[\"norm\"] = norm\n",
    "                \n",
    "        n_searches += 1\n",
    "    n_searches = 30\n",
    "print(\"----\")\n",
    "print(\"Best model has MAP: {} with alpha: {}, norm: {}\".format(best_model[\"MAP\"], best_model[\"alpha\"], best_model[\"norm\"]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d843a26d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T23:05:04.414733Z",
     "iopub.status.busy": "2022-12-26T23:05:04.413486Z",
     "iopub.status.idle": "2022-12-26T23:05:04.419912Z",
     "shell.execute_reply": "2022-12-26T23:05:04.418757Z"
    },
    "papermill": {
     "duration": 0.018038,
     "end_time": "2022-12-26T23:05:04.422520",
     "exception": false,
     "start_time": "2022-12-26T23:05:04.404482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'recommender = DifferentLossScoresHybridRecommender(URM_all, recommender_SLIMElasticNet, RP3beta_all, EASE_R, recommender_SLIM_BPR_Cython)\\nrecommender.fit(1, 0.250566125884653, 0.1663158546388771, 0.573487903866556)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"recommender = DifferentLossScoresHybridRecommender(URM_all, recommender_SLIMElasticNet, RP3beta_all, EASE_R, recommender_SLIM_BPR_Cython)\n",
    "recommender.fit(1, 0.250566125884653, 0.1663158546388771, 0.573487903866556)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7332ad84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T23:05:04.441508Z",
     "iopub.status.busy": "2022-12-26T23:05:04.440506Z",
     "iopub.status.idle": "2022-12-26T23:05:04.446522Z",
     "shell.execute_reply": "2022-12-26T23:05:04.445637Z"
    },
    "papermill": {
     "duration": 0.017645,
     "end_time": "2022-12-26T23:05:04.448440",
     "exception": false,
     "start_time": "2022-12-26T23:05:04.430795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"test_users = pd.read_csv('/kaggle/input/competition-data/data_target_users_test.csv')\\ntest_users\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"test_users = pd.read_csv('/kaggle/input/competition-data/data_target_users_test.csv')\n",
    "test_users\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c35d2e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T23:05:04.466709Z",
     "iopub.status.busy": "2022-12-26T23:05:04.466103Z",
     "iopub.status.idle": "2022-12-26T23:05:04.474170Z",
     "shell.execute_reply": "2022-12-26T23:05:04.472745Z"
    },
    "papermill": {
     "duration": 0.020199,
     "end_time": "2022-12-26T23:05:04.477040",
     "exception": false,
     "start_time": "2022-12-26T23:05:04.456841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user_id = test_users[\\'user_id\\']\\nrecommendations = []\\nfor user in user_id:\\n    recommendations.append(recommender.recommend(user,cutoff = 10, remove_seen_flag = True))\\nfor index in range(len(recommendations)):\\n    recommendations[index]=np.array(recommendations[index])\\n    \\ntest_users[\\'item_list\\']= recommendations\\ntest_users[\\'item_list\\'] = pd.DataFrame([str(line).strip(\\'[\\').strip(\\']\\').replace(\"\\'\",\"\") for line in test_users[\\'item_list\\']])\\ntest_users.to_csv(\\'submission4.csv\\', index=False)'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"user_id = test_users['user_id']\n",
    "recommendations = []\n",
    "for user in user_id:\n",
    "    recommendations.append(recommender.recommend(user,cutoff = 10, remove_seen_flag = True))\n",
    "for index in range(len(recommendations)):\n",
    "    recommendations[index]=np.array(recommendations[index])\n",
    "    \n",
    "test_users['item_list']= recommendations\n",
    "test_users['item_list'] = pd.DataFrame([str(line).strip('[').strip(']').replace(\"'\",\"\") for line in test_users['item_list']])\n",
    "test_users.to_csv('submission4.csv', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81abff38",
   "metadata": {
    "papermill": {
     "duration": 0.007804,
     "end_time": "2022-12-26T23:05:04.493428",
     "exception": false,
     "start_time": "2022-12-26T23:05:04.485624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2302.144843,
   "end_time": "2022-12-26T23:05:05.429621",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-26T22:26:43.284778",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "3339bada26014629b65a29385a21242f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_65cf01fb9de04048baaad85e9355a3b4",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_c2ed23b3055640ac829dd2c225cad134",
       "value": "100%"
      }
     },
     "65cf01fb9de04048baaad85e9355a3b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "738fc0ec8ccd496e9555a8e3330faab6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9af36835e1f9482995ecbb9b3ecd71ed",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_7c2bb39f45554377b9bc7152ff1367ce",
       "value": " 70/70 [04:24&lt;00:00,  3.93s/it]"
      }
     },
     "749b73f3f6fe460b983e5ebd5d96fc67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3339bada26014629b65a29385a21242f",
        "IPY_MODEL_e246de5edc314ca39071a3d5b835d9d4",
        "IPY_MODEL_738fc0ec8ccd496e9555a8e3330faab6"
       ],
       "layout": "IPY_MODEL_d3bb42094c5449a1b9c29b3717dd5b9d"
      }
     },
     "7c2bb39f45554377b9bc7152ff1367ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9af36835e1f9482995ecbb9b3ecd71ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2f00a9af3da4c18925b4bf21c1aaed5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c2ed23b3055640ac829dd2c225cad134": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d3bb42094c5449a1b9c29b3717dd5b9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e246de5edc314ca39071a3d5b835d9d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_faeda715f3ac4027be9a1416fc9cb60a",
       "max": 70.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b2f00a9af3da4c18925b4bf21c1aaed5",
       "value": 70.0
      }
     },
     "faeda715f3ac4027be9a1416fc9cb60a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
