{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af4147fb",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T22:27:39.533815Z",
     "iopub.status.busy": "2022-12-26T22:27:39.533363Z",
     "iopub.status.idle": "2022-12-26T22:27:43.800890Z",
     "shell.execute_reply": "2022-12-26T22:27:43.799388Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.283727,
     "end_time": "2022-12-26T22:27:43.804123",
     "exception": false,
     "start_time": "2022-12-26T22:27:39.520396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r ../input/recsys-repo/RecSys_Course_AT_PoliMi-master/* ./\n",
    "#%%\n",
    "%config Completer.use_jedi = False\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "import matplotlib.pyplot as pyplot\n",
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f29d41",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T22:27:43.825867Z",
     "iopub.status.busy": "2022-12-26T22:27:43.825401Z",
     "iopub.status.idle": "2022-12-26T22:27:44.427668Z",
     "shell.execute_reply": "2022-12-26T22:27:44.426454Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.616135,
     "end_time": "2022-12-26T22:27:44.430523",
     "exception": false,
     "start_time": "2022-12-26T22:27:43.814388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<41629x24507 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1554640 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_all_dataframe = pd.read_csv('/kaggle/input/urm-true-binary/URM_True_Binary.csv')\n",
    "URM_all_dataframe\n",
    "URM_all = sps.coo_matrix((URM_all_dataframe[\"Data\"].values, \n",
    "                          (URM_all_dataframe[\"UserID\"].values, URM_all_dataframe[\"ItemID\"].values)))\n",
    "URM_all = URM_all.tocsr() # to obtain fast access to rows (users)\n",
    "URM_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be27bd3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T22:27:44.451445Z",
     "iopub.status.busy": "2022-12-26T22:27:44.451050Z",
     "iopub.status.idle": "2022-12-26T22:27:45.053136Z",
     "shell.execute_reply": "2022-12-26T22:27:45.052000Z"
    },
    "papermill": {
     "duration": 0.615581,
     "end_time": "2022-12-26T22:27:45.055881",
     "exception": false,
     "start_time": "2022-12-26T22:27:44.440300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<41629x24507 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1243712 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_train_dataframe = pd.read_csv('/kaggle/input/urm-split/Train_df.csv')\n",
    "URM_train_dataframe\n",
    "URM_train = sps.coo_matrix((URM_train_dataframe[\"Data\"].values, \n",
    "                          (URM_train_dataframe[\"UserID\"].values, URM_train_dataframe[\"ItemID\"].values)))\n",
    "URM_train = URM_train.tocsr() # to obtain fast access to rows (users)\n",
    "URM_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c6d7ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T22:27:45.077906Z",
     "iopub.status.busy": "2022-12-26T22:27:45.077513Z",
     "iopub.status.idle": "2022-12-26T22:27:45.234328Z",
     "shell.execute_reply": "2022-12-26T22:27:45.233276Z"
    },
    "papermill": {
     "duration": 0.170532,
     "end_time": "2022-12-26T22:27:45.237092",
     "exception": false,
     "start_time": "2022-12-26T22:27:45.066560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<41629x24507 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1554640 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_val_dataframe = pd.read_csv('/kaggle/input/urm-split/Test_df.csv')\n",
    "URM_val_dataframe\n",
    "URM_valid = sps.coo_matrix((URM_val_dataframe[\"Data\"].values, \n",
    "                          (URM_val_dataframe[\"UserID\"].values, URM_val_dataframe[\"ItemID\"].values)))\n",
    "URM_valid = URM_all.tocsr() # to obtain fast access to rows (users)\n",
    "URM_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ef106cf",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T22:27:45.259829Z",
     "iopub.status.busy": "2022-12-26T22:27:45.259422Z",
     "iopub.status.idle": "2022-12-26T22:27:45.305430Z",
     "shell.execute_reply": "2022-12-26T22:27:45.303816Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.060343,
     "end_time": "2022-12-26T22:27:45.308923",
     "exception": false,
     "start_time": "2022-12-26T22:27:45.248580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items\t 24507, Number of users\t 41629\n",
      "Max ID items\t 24506, Max Id users\t 41628\n",
      "\n",
      "Average interactions per user 37.35\n",
      "Average interactions per item 63.44\n",
      "\n",
      "Sparsity 99.85 %\n"
     ]
    }
   ],
   "source": [
    "userID_unique = URM_all_dataframe[\"UserID\"].unique()\n",
    "itemID_unique = URM_all_dataframe[\"ItemID\"].unique()\n",
    "\n",
    "n_users = len(userID_unique)\n",
    "n_items = len(itemID_unique)\n",
    "n_interactions = len(URM_all_dataframe)\n",
    "\n",
    "print (\"Number of items\\t {}, Number of users\\t {}\".format(n_items, n_users))\n",
    "print (\"Max ID items\\t {}, Max Id users\\t {}\\n\".format(max(itemID_unique), max(userID_unique)))\n",
    "print (\"Average interactions per user {:.2f}\".format(n_interactions/n_users))\n",
    "print (\"Average interactions per item {:.2f}\\n\".format(n_interactions/n_items))\n",
    "\n",
    "print (\"Sparsity {:.2f} %\".format((1-float(n_interactions)/(n_items*n_users))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34a0a4cb",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T22:27:45.330642Z",
     "iopub.status.busy": "2022-12-26T22:27:45.330222Z",
     "iopub.status.idle": "2022-12-26T22:27:45.432337Z",
     "shell.execute_reply": "2022-12-26T22:27:45.431351Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.115467,
     "end_time": "2022-12-26T22:27:45.434883",
     "exception": false,
     "start_time": "2022-12-26T22:27:45.319416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "\n",
    "#create an evaluator object to evaluate validation set\n",
    "#we will use it for hyperparameter tuning\n",
    "evaluator_valid = EvaluatorHoldout(URM_valid, cutoff_list=[10])\n",
    "#%% md\n",
    "# Split users in groups and train multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23eb04c3",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T22:27:45.456335Z",
     "iopub.status.busy": "2022-12-26T22:27:45.455901Z",
     "iopub.status.idle": "2022-12-26T22:27:45.465840Z",
     "shell.execute_reply": "2022-12-26T22:27:45.464741Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.023304,
     "end_time": "2022-12-26T22:27:45.468119",
     "exception": false,
     "start_time": "2022-12-26T22:27:45.444815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([49, 18, 89, ..., 18, 39, 22], dtype=int32), (41629,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import scipy.sparse as sps\n",
    "\n",
    "# count how many interactions each user has\n",
    "profile_length = np.ediff1d(sps.csr_matrix(URM_train).indptr)\n",
    "profile_length, profile_length.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f575b129",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T22:27:45.489966Z",
     "iopub.status.busy": "2022-12-26T22:27:45.489009Z",
     "iopub.status.idle": "2022-12-26T22:27:45.496495Z",
     "shell.execute_reply": "2022-12-26T22:27:45.495585Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.020807,
     "end_time": "2022-12-26T22:27:45.498764",
     "exception": false,
     "start_time": "2022-12-26T22:27:45.477957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2081"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select 5% of users with least interactions\n",
    "block_size = int(len(profile_length)*0.05)\n",
    "block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4affab30",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T22:27:45.520687Z",
     "iopub.status.busy": "2022-12-26T22:27:45.519891Z",
     "iopub.status.idle": "2022-12-26T22:27:45.529370Z",
     "shell.execute_reply": "2022-12-26T22:27:45.528462Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.023137,
     "end_time": "2022-12-26T22:27:45.531680",
     "exception": false,
     "start_time": "2022-12-26T22:27:45.508543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36889, 36096, 25061, ..., 19407,  8693, 12454])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_users = np.argsort(profile_length)\n",
    "sorted_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e0fd4f4",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T22:27:45.555788Z",
     "iopub.status.busy": "2022-12-26T22:27:45.555299Z",
     "iopub.status.idle": "2022-12-26T22:27:45.568837Z",
     "shell.execute_reply": "2022-12-26T22:27:45.567345Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.0298,
     "end_time": "2022-12-26T22:27:45.571423",
     "exception": false,
     "start_time": "2022-12-26T22:27:45.541623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0, #users in group 2081, average p.len 9.79, median 10.0, min 3, max 12\n",
      "Group 1, #users in group 2081, average p.len 12.54, median 13.0, min 12, max 13\n",
      "Group 2, #users in group 2081, average p.len 14.08, median 14.0, min 13, max 15\n",
      "Group 3, #users in group 2081, average p.len 15.37, median 15.0, min 15, max 16\n",
      "Group 4, #users in group 2081, average p.len 16.44, median 16.0, min 16, max 17\n",
      "Group 5, #users in group 2081, average p.len 17.53, median 18.0, min 17, max 18\n",
      "Group 6, #users in group 2081, average p.len 18.62, median 19.0, min 18, max 19\n",
      "Group 7, #users in group 2081, average p.len 19.75, median 20.0, min 19, max 20\n",
      "Group 8, #users in group 2081, average p.len 20.98, median 21.0, min 20, max 22\n",
      "Group 9, #users in group 2081, average p.len 22.30, median 22.0, min 22, max 23\n",
      "Group 10, #users in group 2081, average p.len 23.63, median 24.0, min 23, max 24\n",
      "Group 11, #users in group 2081, average p.len 25.40, median 25.0, min 24, max 26\n",
      "Group 12, #users in group 2081, average p.len 27.22, median 27.0, min 26, max 28\n",
      "Group 13, #users in group 2081, average p.len 29.57, median 30.0, min 28, max 31\n",
      "Group 14, #users in group 2081, average p.len 32.37, median 32.0, min 31, max 34\n",
      "Group 15, #users in group 2081, average p.len 35.92, median 36.0, min 34, max 38\n",
      "Group 16, #users in group 2081, average p.len 40.68, median 41.0, min 38, max 44\n",
      "Group 17, #users in group 2081, average p.len 47.60, median 47.0, min 44, max 52\n",
      "Group 18, #users in group 2081, average p.len 59.16, median 58.0, min 52, max 69\n",
      "Group 19, #users in group 2081, average p.len 105.83, median 89.0, min 69, max 465\n"
     ]
    }
   ],
   "source": [
    "# do the same for all users to obtain a division in 20 different groups of users\n",
    "for group_id in range(0, 20):\n",
    "    start_pos = group_id * block_size\n",
    "    end_pos = min((group_id+1) * block_size, len(profile_length))\n",
    "    \n",
    "    users_in_group = sorted_users[start_pos:end_pos]\n",
    "    \n",
    "    users_in_group_p_len = profile_length[users_in_group]\n",
    "    \n",
    "    print(\"Group {}, #users in group {}, average p.len {:.2f}, median {}, min {}, max {}\".format(\n",
    "        group_id, \n",
    "        users_in_group.shape[0],\n",
    "        users_in_group_p_len.mean(),\n",
    "        np.median(users_in_group_p_len),\n",
    "        users_in_group_p_len.min(),\n",
    "        users_in_group_p_len.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9a5ffdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T22:27:45.594117Z",
     "iopub.status.busy": "2022-12-26T22:27:45.593680Z",
     "iopub.status.idle": "2022-12-26T22:27:45.879201Z",
     "shell.execute_reply": "2022-12-26T22:27:45.877569Z"
    },
    "papermill": {
     "duration": 0.301973,
     "end_time": "2022-12-26T22:27:45.883840",
     "exception": false,
     "start_time": "2022-12-26T22:27:45.581867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import implicit\n",
    "import numpy as np\n",
    "\n",
    "from Recommenders.BaseMatrixFactorizationRecommender import BaseMatrixFactorizationRecommender\n",
    "\n",
    "\n",
    "class IALSRecommender_implicit(BaseMatrixFactorizationRecommender):\n",
    "    \"\"\"\n",
    "    ALS implemented with implicit following guideline of\n",
    "    https://medium.com/radon-dev/als-implicit-collaborative-filtering-5ed653ba39fe\n",
    "    IDEA:\n",
    "    Recomputing x_{u} and y_i can be done with Stochastic Gradient Descent, but this is a non-convex optimization problem.\n",
    "    We can convert it into a set of quadratic problems, by keeping either x_u or y_i fixed while optimizing the other.\n",
    "    In that case, we can iteratively solve x and y by alternating between them until the algorithm converges.\n",
    "    This is Alternating Least Squares.\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"IALSRecommender_implicit\"\n",
    "\n",
    "    def __init__(self, URM_train, verbose=True):\n",
    "        super(IALSRecommender_implicit, self).__init__(URM_train, verbose=verbose)\n",
    "\n",
    "    def fit(self, n_factors=50, regularization=0.001847510119137634, iterations=30, num_threads=2):\n",
    "        self.n_factors = n_factors\n",
    "        self.regularization = regularization\n",
    "        self.iterations = iterations\n",
    "\n",
    "        sparse_item_user = self.URM_train.T\n",
    "\n",
    "        # Initialize the als model and fit it using the sparse item-user matrix\n",
    "        model = implicit.als.AlternatingLeastSquares(factors=self.n_factors, regularization=self.regularization,\n",
    "                                                     iterations=self.iterations, num_threads=num_threads)\n",
    "\n",
    "        alpha_val = 2\n",
    "        # Calculate the confidence by multiplying it by our alpha value.\n",
    "\n",
    "        data_conf = (sparse_item_user * alpha_val).astype('double')\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(data_conf)\n",
    "\n",
    "        # Get the user and item vectors from our trained model\n",
    "        self.USER_factors = model.user_factors\n",
    "        self.ITEM_factors = model.item_factors\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute=None):\n",
    "        \"\"\"\n",
    "        USER_factors is n_users x n_factors\n",
    "        ITEM_factors is n_items x n_factors\n",
    "\n",
    "        The prediction for cold users will always be -inf for ALL items\n",
    "\n",
    "        :param user_id_array:\n",
    "        :param items_to_compute:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        assert self.USER_factors.shape[1] == self.ITEM_factors.shape[1], \\\n",
    "            \"{}: User and Item factors have inconsistent shape\".format(self.RECOMMENDER_NAME)\n",
    "\n",
    "        assert self.USER_factors.shape[0] > np.max(user_id_array), \\\n",
    "            \"{}: Cold users not allowed. Users in trained model are {}, requested prediction for users up to {}\".format(\n",
    "                self.RECOMMENDER_NAME, self.USER_factors.shape[0], np.max(user_id_array))\n",
    "\n",
    "        if items_to_compute is not None:\n",
    "            item_scores = - np.ones((len(user_id_array), self.ITEM_factors.shape[0]), dtype=np.float32) * np.inf\n",
    "            item_scores[:, items_to_compute] = np.dot(self.USER_factors[user_id_array],\n",
    "                                                      np.transpose(self.ITEM_factors[items_to_compute, :]))\n",
    "\n",
    "        else:\n",
    "            item_factors_T = np.transpose(self.ITEM_factors)\n",
    "            user_factors = self.USER_factors[user_id_array]\n",
    "            item_scores = np.dot(user_factors, item_factors_T)\n",
    "\n",
    "        # No need to select only the specific negative items or warm users because the -inf score will not change\n",
    "        if self.use_bias:\n",
    "            item_scores += self.ITEM_bias + self.GLOBAL_bias\n",
    "            item_scores = np.transpose(np.transpose(item_scores) + self.USER_bias[user_id_array])\n",
    "\n",
    "        return item_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44e30332",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T22:27:45.911422Z",
     "iopub.status.busy": "2022-12-26T22:27:45.911036Z",
     "iopub.status.idle": "2022-12-26T22:27:47.075547Z",
     "shell.execute_reply": "2022-12-26T22:27:47.074362Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.179542,
     "end_time": "2022-12-26T22:27:47.078455",
     "exception": false,
     "start_time": "2022-12-26T22:27:45.898913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "from Recommenders.Recommender_utils import check_matrix\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from Recommenders.BaseSimilarityMatrixRecommender import BaseItemSimilarityMatrixRecommender\n",
    "from Utils.seconds_to_biggest_unit import seconds_to_biggest_unit\n",
    "import time, sys\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# os.environ[\"PYTHONWARNINGS\"] = ('ignore::exceptions.ConvergenceWarning:sklearn.linear_model')\n",
    "# os.environ[\"PYTHONWARNINGS\"] = ('ignore:Objective did not converge:ConvergenceWarning:')\n",
    "\n",
    "class SLIMElasticNetRecommender(BaseItemSimilarityMatrixRecommender):\n",
    "    \"\"\"\n",
    "    Train a Sparse Linear Methods (SLIM) item similarity model.\n",
    "    NOTE: ElasticNet solver is parallel, a single intance of SLIM_ElasticNet will\n",
    "          make use of half the cores available\n",
    "    See:\n",
    "        Efficient Top-N Recommendation by Linear Regression,\n",
    "        M. Levy and K. Jack, LSRS workshop at RecSys 2013.\n",
    "        SLIM: Sparse linear methods for top-n recommender systems,\n",
    "        X. Ning and G. Karypis, ICDM 2011.\n",
    "        http://glaros.dtc.umn.edu/gkhome/fetch/papers/SLIM2011icdm.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"SLIMElasticNetRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, verbose = True):\n",
    "        super(SLIMElasticNetRecommender, self).__init__(URM_train, verbose = verbose)\n",
    "\n",
    "    @ignore_warnings(category=ConvergenceWarning)\n",
    "    def fit(self, l1_ratio=0.1, alpha = 1.0, positive_only=True, topK = 100,**earlystopping_kwargs):\n",
    "\n",
    "        assert l1_ratio>= 0 and l1_ratio<=1, \"{}: l1_ratio must be between 0 and 1, provided value was {}\".format(self.RECOMMENDER_NAME, l1_ratio)\n",
    "\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.positive_only = positive_only\n",
    "        self.topK = topK\n",
    "\n",
    "\n",
    "        # initialize the ElasticNet model\n",
    "        self.model = ElasticNet(alpha=alpha,\n",
    "                                l1_ratio=self.l1_ratio,\n",
    "                                positive=self.positive_only,\n",
    "                                fit_intercept=False,\n",
    "                                copy_X=False,\n",
    "                                precompute=True,\n",
    "                                selection='random',\n",
    "                                max_iter=100,\n",
    "                                tol=1e-4)\n",
    "\n",
    "        URM_train = check_matrix(self.URM_train, 'csc', dtype=np.float32)\n",
    "\n",
    "        n_items = URM_train.shape[1]\n",
    "\n",
    "        # Use array as it reduces memory requirements compared to lists\n",
    "        dataBlock = 10000000\n",
    "\n",
    "        rows = np.zeros(dataBlock, dtype=np.int32)\n",
    "        cols = np.zeros(dataBlock, dtype=np.int32)\n",
    "        values = np.zeros(dataBlock, dtype=np.float32)\n",
    "\n",
    "        numCells = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        start_time_printBatch = start_time\n",
    "\n",
    "        # fit each item's factors sequentially (not in parallel)\n",
    "        for currentItem in range(n_items):\n",
    "\n",
    "            # get the target column\n",
    "            y = URM_train[:, currentItem].toarray()\n",
    "\n",
    "            # set the j-th column of X to zero\n",
    "            start_pos = URM_train.indptr[currentItem]\n",
    "            end_pos = URM_train.indptr[currentItem + 1]\n",
    "\n",
    "            current_item_data_backup = URM_train.data[start_pos: end_pos].copy()\n",
    "            URM_train.data[start_pos: end_pos] = 0.0\n",
    "\n",
    "            # fit one ElasticNet model per column\n",
    "            self.model.fit(URM_train, y)\n",
    "\n",
    "            # self.model.coef_ contains the coefficient of the ElasticNet model\n",
    "            # let's keep only the non-zero values\n",
    "\n",
    "            # Select topK values\n",
    "            # Sorting is done in three steps. Faster then plain np.argsort for higher number of items\n",
    "            # - Partition the data to extract the set of relevant items\n",
    "            # - Sort only the relevant items\n",
    "            # - Get the original item index\n",
    "\n",
    "            nonzero_model_coef_index = self.model.sparse_coef_.indices\n",
    "            nonzero_model_coef_value = self.model.sparse_coef_.data\n",
    "\n",
    "            local_topK = min(len(nonzero_model_coef_value)-1, self.topK)\n",
    "\n",
    "            relevant_items_partition = (-nonzero_model_coef_value).argpartition(local_topK)[0:local_topK]\n",
    "            relevant_items_partition_sorting = np.argsort(-nonzero_model_coef_value[relevant_items_partition])\n",
    "            ranking = relevant_items_partition[relevant_items_partition_sorting]\n",
    "\n",
    "            for index in range(len(ranking)):\n",
    "\n",
    "                if numCells == len(rows):\n",
    "                    rows = np.concatenate((rows, np.zeros(dataBlock, dtype=np.int32)))\n",
    "                    cols = np.concatenate((cols, np.zeros(dataBlock, dtype=np.int32)))\n",
    "                    values = np.concatenate((values, np.zeros(dataBlock, dtype=np.float32)))\n",
    "\n",
    "\n",
    "                rows[numCells] = nonzero_model_coef_index[ranking[index]]\n",
    "                cols[numCells] = currentItem\n",
    "                values[numCells] = nonzero_model_coef_value[ranking[index]]\n",
    "\n",
    "                numCells += 1\n",
    "\n",
    "            # finally, replace the original values of the j-th column\n",
    "            URM_train.data[start_pos:end_pos] = current_item_data_backup\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "            new_time_value, new_time_unit = seconds_to_biggest_unit(elapsed_time)\n",
    "\n",
    "\n",
    "            if time.time() - start_time_printBatch > 300 or currentItem == n_items-1:\n",
    "                self._print(\"Processed {} ({:4.1f}%) in {:.2f} {}. Items per second: {:.2f}\".format(\n",
    "                    currentItem+1,\n",
    "                    100.0* float(currentItem+1)/n_items,\n",
    "                    new_time_value,\n",
    "                    new_time_unit,\n",
    "                    float(currentItem)/elapsed_time))\n",
    "\n",
    "                sys.stdout.flush()\n",
    "                sys.stderr.flush()\n",
    "\n",
    "                start_time_printBatch = time.time()\n",
    "\n",
    "        # generate the sparse weight matrix\n",
    "        self.W_sparse = sps.csr_matrix((values[:numCells], (rows[:numCells], cols[:numCells])),\n",
    "                                       shape=(n_items, n_items), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6336019",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T22:27:47.101419Z",
     "iopub.status.busy": "2022-12-26T22:27:47.100971Z",
     "iopub.status.idle": "2022-12-26T22:27:47.107221Z",
     "shell.execute_reply": "2022-12-26T22:27:47.105782Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.020423,
     "end_time": "2022-12-26T22:27:47.109591",
     "exception": false,
     "start_time": "2022-12-26T22:27:47.089168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_folder_path = \"result_experiments/\"\n",
    "\n",
    "# If directory does not exist, create\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6a488d6",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T22:27:47.132271Z",
     "iopub.status.busy": "2022-12-26T22:27:47.131822Z",
     "iopub.status.idle": "2022-12-26T22:27:47.144755Z",
     "shell.execute_reply": "2022-12-26T22:27:47.143199Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.027328,
     "end_time": "2022-12-26T22:27:47.147382",
     "exception": false,
     "start_time": "2022-12-26T22:27:47.120054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, <pyximport.pyximport.PyxImporter at 0x7fed64396c10>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyximport\n",
    "pyximport.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc0b2601",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T22:27:47.171126Z",
     "iopub.status.busy": "2022-12-26T22:27:47.170413Z",
     "iopub.status.idle": "2022-12-26T22:30:38.260520Z",
     "shell.execute_reply": "2022-12-26T22:30:38.259108Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 171.105113,
     "end_time": "2022-12-26T22:30:38.263266",
     "exception": false,
     "start_time": "2022-12-26T22:27:47.158153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_compile_all_cython: Found 10 Cython files in 4 folders...\r\n",
      "run_compile_all_cython: All files will be compiled using your current python environment: '/opt/conda/bin/python'\r\n",
      "Compiling [1/10]: MatrixFactorizationImpressions_Cython_Epoch.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_f_43MatrixFactorizationImpressions_Cython_Epoch_32MatrixFactorization_Cython_Epoch_sampleBPR_Cython\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:12758:17:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_start_pos_impression_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      "12758 |       \u001b[01;35m\u001b[K__pyx_t_4 = (__pyx_v_start_pos_impression_items + __pyx_v_index)\u001b[m\u001b[K;\r\n",
      "      |       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_43MatrixFactorizationImpressions_Cython_Epoch_32MatrixFactorization_Cython_Epoch_10epochIteration_Cython_ASY_SVD_SGD\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:8736:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_end_pos_seen_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 8736 |       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K (__pyx_t_19 = __pyx_v_start_pos_seen_items; __pyx_t_19 < __pyx_t_18; __pyx_t_19+=1) {\r\n",
      "      |       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:8736:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_start_pos_seen_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/MatrixFactorization/Cython/MatrixFactorizationImpressions_Cython_Epoch.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [1/10]: MatrixFactorizationImpressions_Cython_Epoch.pyx... PASS\r\n",
      "\r\n",
      "Compiling [2/10]: MatrixFactorization_Cython_Epoch.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KMatrixFactorization_Cython_Epoch.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorization_Cython_Epoch.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_32MatrixFactorization_Cython_Epoch_32MatrixFactorization_Cython_Epoch_10epochIteration_Cython_ASY_SVD_SGD\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KMatrixFactorization_Cython_Epoch.c:8669:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_end_pos_seen_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 8669 |         \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K (__pyx_t_19 = __pyx_v_start_pos_seen_items; __pyx_t_19 < __pyx_t_18; __pyx_t_19+=1) {\r\n",
      "      |         \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorization_Cython_Epoch.c:8669:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_start_pos_seen_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/MatrixFactorization/Cython/MatrixFactorization_Cython_Epoch.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [2/10]: MatrixFactorization_Cython_Epoch.pyx... PASS\r\n",
      "\r\n",
      "Compiling [3/10]: Compute_Similarity_Cython.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KCompute_Similarity_Cython.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/Similarity/Cython/Compute_Similarity_Cython.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [3/10]: Compute_Similarity_Cython.pyx... PASS\r\n",
      "\r\n",
      "Compiling [4/10]: Sparse_Matrix_Tree_CSR.pyx... \r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KSparse_Matrix_Tree_CSR.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KSparse_Matrix_Tree_CSR.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_f_22Sparse_Matrix_Tree_CSR_22Sparse_Matrix_Tree_CSR_test_list_tree_conversion\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KSparse_Matrix_Tree_CSR.c:5844:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_previous_element\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 5844 |     \u001b[01;35m\u001b[K__pyx_t_7 = __pyx_v_current_element->lower\u001b[m\u001b[K;\r\n",
      "      |     \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/SLIM/Cython/Sparse_Matrix_Tree_CSR.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "Compiling [4/10]: Sparse_Matrix_Tree_CSR.pyx... PASS\r\n",
      "\r\n",
      "Compiling [5/10]: SLIM_BPR_Cython_Epoch.pyx... \r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KSLIM_BPR_Cython_Epoch.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KSLIM_BPR_Cython_Epoch.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_f_21SLIM_BPR_Cython_Epoch_22Sparse_Matrix_Tree_CSR_test_list_tee_conversion\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KSLIM_BPR_Cython_Epoch.c:10848:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_previous_element\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      "10848 |     \u001b[01;35m\u001b[K__pyx_t_7 = __pyx_v_current_element->lower\u001b[m\u001b[K;\r\n",
      "      |     \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/SLIM/Cython/SLIM_BPR_Cython_Epoch.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "Compiling [5/10]: SLIM_BPR_Cython_Epoch.pyx... PASS\r\n",
      "\r\n",
      "Compiling [6/10]: Triangular_Matrix.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KTriangular_Matrix.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/SLIM/Cython/Triangular_Matrix.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [6/10]: Triangular_Matrix.pyx... PASS\r\n",
      "\r\n",
      "Compiling [7/10]: CFW_D_Similarity_Cython_SGD.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KCFW_D_Similarity_Cython_SGD.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KCFW_D_Similarity_Cython_SGD.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_27CFW_D_Similarity_Cython_SGD_27CFW_D_Similarity_Cython_SGD_6fit\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KCFW_D_Similarity_Cython_SGD.c:6056:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_sample_num\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 6056 |   __pyx_t_3 = PyFloat_FromDouble((__pyx_v_cum_loss / \u001b[01;35m\u001b[K((double)__pyx_v_sample_num)\u001b[m\u001b[K)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 290, __pyx_L1_error)\r\n",
      "      |                                                      \u001b[01;35m\u001b[K~^~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/CFW_D_Similarity_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [7/10]: CFW_D_Similarity_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "Compiling [8/10]: FBSM_Rating_Cython_SGD.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KFBSM_Rating_Cython_SGD.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KFBSM_Rating_Cython_SGD.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_22FBSM_Rating_Cython_SGD_22FBSM_Rating_Cython_SGD_2fit\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KFBSM_Rating_Cython_SGD.c:9031:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_num_sample\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 9031 |   __pyx_t_5 = PyFloat_FromDouble((__pyx_v_cum_loss / \u001b[01;35m\u001b[K((double)__pyx_v_num_sample)\u001b[m\u001b[K)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 551, __pyx_L1_error)\r\n",
      "      |                                                      \u001b[01;35m\u001b[K~^~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/FBSM_Rating_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [8/10]: FBSM_Rating_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "Compiling [9/10]: HP3_Similarity_Cython_SGD.pyx... \r\n",
      "warning: HP3_Similarity_Cython_SGD.pyx:113:40: Index should be typed for more efficient access\r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KHP3_Similarity_Cython_SGD.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KHP3_Similarity_Cython_SGD.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_25HP3_Similarity_Cython_SGD_25HP3_Similarity_Cython_SGD_4fit\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KHP3_Similarity_Cython_SGD.c:6303:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_sample_num\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 6303 |   __pyx_t_1 = PyFloat_FromDouble((__pyx_v_cum_loss / \u001b[01;35m\u001b[K((double)__pyx_v_sample_num)\u001b[m\u001b[K)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 291, __pyx_L1_error)\r\n",
      "      |                                                      \u001b[01;35m\u001b[K~^~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/HP3_Similarity_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "warning: HP3_Similarity_Cython_SGD.pyx:113:40: Index should be typed for more efficient access\r\n",
      "Compiling [9/10]: HP3_Similarity_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "Compiling [10/10]: CFW_DVV_Similarity_Cython_SGD.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KCFW_DVV_Similarity_Cython_SGD.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/CFW_DVV_Similarity_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [10/10]: CFW_DVV_Similarity_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "run_compile_all_cython: Compilation finished. SUCCESS.\r\n",
      "Compilation log can be found here: './result_experiments/run_compile_all_cython.txt'\r\n"
     ]
    }
   ],
   "source": [
    "#prepare the environment to run Cython code\n",
    "!python run_compile_all_cython.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "960c8cef",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T22:30:38.292488Z",
     "iopub.status.busy": "2022-12-26T22:30:38.291993Z",
     "iopub.status.idle": "2022-12-26T22:30:38.296892Z",
     "shell.execute_reply": "2022-12-26T22:30:38.296062Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.022424,
     "end_time": "2022-12-26T22:30:38.299249",
     "exception": false,
     "start_time": "2022-12-26T22:30:38.276825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#here we will save MAPs of different user groups\n",
    "MAP_recommender_per_group = {}\n",
    "\n",
    "#here we will save pairs label : recommnder_object\n",
    "recommender_object_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e5620e8",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T22:30:38.327950Z",
     "iopub.status.busy": "2022-12-26T22:30:38.327538Z",
     "iopub.status.idle": "2022-12-26T22:39:11.763751Z",
     "shell.execute_reply": "2022-12-26T22:39:11.762083Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 513.454918,
     "end_time": "2022-12-26T22:39:11.767977",
     "exception": false,
     "start_time": "2022-12-26T22:30:38.313059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IALSRecommender: Epoch 1 of 40. Elapsed time 13.87 sec\n",
      "IALSRecommender: Epoch 2 of 40. Elapsed time 26.04 sec\n",
      "IALSRecommender: Epoch 3 of 40. Elapsed time 38.25 sec\n",
      "IALSRecommender: Epoch 4 of 40. Elapsed time 51.96 sec\n",
      "IALSRecommender: Epoch 5 of 40. Elapsed time 1.07 min\n",
      "IALSRecommender: Epoch 6 of 40. Elapsed time 1.30 min\n",
      "IALSRecommender: Epoch 7 of 40. Elapsed time 1.50 min\n",
      "IALSRecommender: Epoch 8 of 40. Elapsed time 1.70 min\n",
      "IALSRecommender: Epoch 9 of 40. Elapsed time 1.93 min\n",
      "IALSRecommender: Epoch 10 of 40. Elapsed time 2.13 min\n",
      "IALSRecommender: Epoch 11 of 40. Elapsed time 2.36 min\n",
      "IALSRecommender: Epoch 12 of 40. Elapsed time 2.57 min\n",
      "IALSRecommender: Epoch 13 of 40. Elapsed time 2.78 min\n",
      "IALSRecommender: Epoch 14 of 40. Elapsed time 3.01 min\n",
      "IALSRecommender: Epoch 15 of 40. Elapsed time 3.22 min\n",
      "IALSRecommender: Epoch 16 of 40. Elapsed time 3.45 min\n",
      "IALSRecommender: Epoch 17 of 40. Elapsed time 3.65 min\n",
      "IALSRecommender: Epoch 18 of 40. Elapsed time 3.86 min\n",
      "IALSRecommender: Epoch 19 of 40. Elapsed time 4.08 min\n",
      "IALSRecommender: Epoch 20 of 40. Elapsed time 4.28 min\n",
      "IALSRecommender: Epoch 21 of 40. Elapsed time 4.51 min\n",
      "IALSRecommender: Epoch 22 of 40. Elapsed time 4.71 min\n",
      "IALSRecommender: Epoch 23 of 40. Elapsed time 4.91 min\n",
      "IALSRecommender: Epoch 24 of 40. Elapsed time 5.14 min\n",
      "IALSRecommender: Epoch 25 of 40. Elapsed time 5.34 min\n",
      "IALSRecommender: Epoch 26 of 40. Elapsed time 5.57 min\n",
      "IALSRecommender: Epoch 27 of 40. Elapsed time 5.77 min\n",
      "IALSRecommender: Epoch 28 of 40. Elapsed time 5.98 min\n",
      "IALSRecommender: Epoch 29 of 40. Elapsed time 6.20 min\n",
      "IALSRecommender: Epoch 30 of 40. Elapsed time 6.41 min\n",
      "IALSRecommender: Epoch 31 of 40. Elapsed time 6.64 min\n",
      "IALSRecommender: Epoch 32 of 40. Elapsed time 6.84 min\n",
      "IALSRecommender: Epoch 33 of 40. Elapsed time 7.04 min\n",
      "IALSRecommender: Epoch 34 of 40. Elapsed time 7.28 min\n",
      "IALSRecommender: Epoch 35 of 40. Elapsed time 7.48 min\n",
      "IALSRecommender: Epoch 36 of 40. Elapsed time 7.71 min\n",
      "IALSRecommender: Epoch 37 of 40. Elapsed time 7.92 min\n",
      "IALSRecommender: Epoch 38 of 40. Elapsed time 8.12 min\n",
      "IALSRecommender: Epoch 39 of 40. Elapsed time 8.35 min\n",
      "IALSRecommender: Epoch 40 of 40. Elapsed time 8.55 min\n",
      "IALSRecommender: Terminating at epoch 40. Elapsed time 8.56 min\n"
     ]
    }
   ],
   "source": [
    "from Recommenders.MatrixFactorization.IALSRecommender import IALSRecommender\n",
    "\n",
    "mf_ials = IALSRecommender(URM_train)\n",
    "mf_ials.fit(num_factors = 31, confidence_scaling= 'log',alpha = 0.0024941846820976015, epsilon = 3.449297756742473, reg = 5.61162089901928e-05, epochs = 40)\n",
    "recommender_object_dict[\"MF_IALS\"] = mf_ials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1abda75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T22:39:11.852100Z",
     "iopub.status.busy": "2022-12-26T22:39:11.851344Z",
     "iopub.status.idle": "2022-12-26T22:47:33.093110Z",
     "shell.execute_reply": "2022-12-26T22:47:33.091467Z"
    },
    "papermill": {
     "duration": 501.28973,
     "end_time": "2022-12-26T22:47:33.098271",
     "exception": false,
     "start_time": "2022-12-26T22:39:11.808541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf763e49f61e47a1992b91a34e06d7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "impl_IALS =  IALSRecommender_implicit(URM_train)\n",
    "impl_IALS.fit(n_factors= 382, regularization= 36.55096224415435, iterations=70, num_threads=2)\n",
    "recommender_object_dict[\"IALS_implicit\"] = mf_ials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3124edd1",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T22:47:33.163134Z",
     "iopub.status.busy": "2022-12-26T22:47:33.162735Z",
     "iopub.status.idle": "2022-12-26T22:47:35.351247Z",
     "shell.execute_reply": "2022-12-26T22:47:35.349041Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.215561,
     "end_time": "2022-12-26T22:47:35.355742",
     "exception": false,
     "start_time": "2022-12-26T22:47:33.140181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PureSVDRecommender: Computing SVD decomposition...\n",
      "PureSVDRecommender: Computing SVD decomposition... done in 2.14 sec\n"
     ]
    }
   ],
   "source": [
    "from Recommenders.MatrixFactorization.PureSVDRecommender import PureSVDRecommender\n",
    "\n",
    "pure_svd = PureSVDRecommender(URM_train)\n",
    "pure_svd.fit(num_factors=40)\n",
    "recommender_object_dict[\"PURE_SVD\"] = pure_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ccd025e",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T22:47:35.430671Z",
     "iopub.status.busy": "2022-12-26T22:47:35.430268Z",
     "iopub.status.idle": "2022-12-26T22:47:41.657558Z",
     "shell.execute_reply": "2022-12-26T22:47:41.656707Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 6.249318,
     "end_time": "2022-12-26T22:47:41.660060",
     "exception": false,
     "start_time": "2022-12-26T22:47:35.410742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity column 24507 (100.0%), 4149.15 column/sec. Elapsed time 5.91 sec\n"
     ]
    }
   ],
   "source": [
    "from Recommenders.KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "\n",
    "itemknn_cf = ItemKNNCFRecommender(URM_train)\n",
    "itemknn_cf.fit(topK = 157, shrink = 463, similarity = 'cosine', normalize = True, feature_weighting = 'TF-IDF')\n",
    "recommender_object_dict[\"ItemKNNCF\"] = itemknn_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "836bd54d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T22:47:41.694097Z",
     "iopub.status.busy": "2022-12-26T22:47:41.693377Z",
     "iopub.status.idle": "2022-12-26T22:47:41.716492Z",
     "shell.execute_reply": "2022-12-26T22:47:41.715375Z"
    },
    "papermill": {
     "duration": 0.04304,
     "end_time": "2022-12-26T22:47:41.719002",
     "exception": false,
     "start_time": "2022-12-26T22:47:41.675962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "from Recommenders.Recommender_utils import check_matrix\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from Recommenders.BaseSimilarityMatrixRecommender import BaseItemSimilarityMatrixRecommender\n",
    "from Utils.seconds_to_biggest_unit import seconds_to_biggest_unit\n",
    "import time, sys\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# os.environ[\"PYTHONWARNINGS\"] = ('ignore::exceptions.ConvergenceWarning:sklearn.linear_model')\n",
    "# os.environ[\"PYTHONWARNINGS\"] = ('ignore:Objective did not converge:ConvergenceWarning:')\n",
    "\n",
    "class SLIMElasticNetRecommender(BaseItemSimilarityMatrixRecommender):\n",
    "    \"\"\"\n",
    "    Train a Sparse Linear Methods (SLIM) item similarity model.\n",
    "    NOTE: ElasticNet solver is parallel, a single intance of SLIM_ElasticNet will\n",
    "          make use of half the cores available\n",
    "    See:\n",
    "        Efficient Top-N Recommendation by Linear Regression,\n",
    "        M. Levy and K. Jack, LSRS workshop at RecSys 2013.\n",
    "        SLIM: Sparse linear methods for top-n recommender systems,\n",
    "        X. Ning and G. Karypis, ICDM 2011.\n",
    "        http://glaros.dtc.umn.edu/gkhome/fetch/papers/SLIM2011icdm.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"SLIMElasticNetRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, verbose = True):\n",
    "        super(SLIMElasticNetRecommender, self).__init__(URM_train, verbose = verbose)\n",
    "\n",
    "    @ignore_warnings(category=ConvergenceWarning)\n",
    "    def fit(self, l1_ratio=0.1, alpha = 1.0, positive_only=True, topK = 100,**earlystopping_kwargs):\n",
    "\n",
    "        assert l1_ratio>= 0 and l1_ratio<=1, \"{}: l1_ratio must be between 0 and 1, provided value was {}\".format(self.RECOMMENDER_NAME, l1_ratio)\n",
    "\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.positive_only = positive_only\n",
    "        self.topK = topK\n",
    "\n",
    "\n",
    "        # initialize the ElasticNet model\n",
    "        self.model = ElasticNet(alpha=alpha,\n",
    "                                l1_ratio=self.l1_ratio,\n",
    "                                positive=self.positive_only,\n",
    "                                fit_intercept=False,\n",
    "                                copy_X=False,\n",
    "                                precompute=True,\n",
    "                                selection='random',\n",
    "                                max_iter=100,\n",
    "                                tol=1e-4)\n",
    "\n",
    "        URM_train = check_matrix(self.URM_train, 'csc', dtype=np.float32)\n",
    "\n",
    "        n_items = URM_train.shape[1]\n",
    "\n",
    "        # Use array as it reduces memory requirements compared to lists\n",
    "        dataBlock = 10000000\n",
    "\n",
    "        rows = np.zeros(dataBlock, dtype=np.int32)\n",
    "        cols = np.zeros(dataBlock, dtype=np.int32)\n",
    "        values = np.zeros(dataBlock, dtype=np.float32)\n",
    "\n",
    "        numCells = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        start_time_printBatch = start_time\n",
    "\n",
    "        # fit each item's factors sequentially (not in parallel)\n",
    "        for currentItem in range(n_items):\n",
    "\n",
    "            # get the target column\n",
    "            y = URM_train[:, currentItem].toarray()\n",
    "\n",
    "            # set the j-th column of X to zero\n",
    "            start_pos = URM_train.indptr[currentItem]\n",
    "            end_pos = URM_train.indptr[currentItem + 1]\n",
    "\n",
    "            current_item_data_backup = URM_train.data[start_pos: end_pos].copy()\n",
    "            URM_train.data[start_pos: end_pos] = 0.0\n",
    "\n",
    "            # fit one ElasticNet model per column\n",
    "            self.model.fit(URM_train, y)\n",
    "\n",
    "            # self.model.coef_ contains the coefficient of the ElasticNet model\n",
    "            # let's keep only the non-zero values\n",
    "\n",
    "            # Select topK values\n",
    "            # Sorting is done in three steps. Faster then plain np.argsort for higher number of items\n",
    "            # - Partition the data to extract the set of relevant items\n",
    "            # - Sort only the relevant items\n",
    "            # - Get the original item index\n",
    "\n",
    "            nonzero_model_coef_index = self.model.sparse_coef_.indices\n",
    "            nonzero_model_coef_value = self.model.sparse_coef_.data\n",
    "\n",
    "            local_topK = min(len(nonzero_model_coef_value)-1, self.topK)\n",
    "\n",
    "            relevant_items_partition = (-nonzero_model_coef_value).argpartition(local_topK)[0:local_topK]\n",
    "            relevant_items_partition_sorting = np.argsort(-nonzero_model_coef_value[relevant_items_partition])\n",
    "            ranking = relevant_items_partition[relevant_items_partition_sorting]\n",
    "\n",
    "            for index in range(len(ranking)):\n",
    "\n",
    "                if numCells == len(rows):\n",
    "                    rows = np.concatenate((rows, np.zeros(dataBlock, dtype=np.int32)))\n",
    "                    cols = np.concatenate((cols, np.zeros(dataBlock, dtype=np.int32)))\n",
    "                    values = np.concatenate((values, np.zeros(dataBlock, dtype=np.float32)))\n",
    "\n",
    "\n",
    "                rows[numCells] = nonzero_model_coef_index[ranking[index]]\n",
    "                cols[numCells] = currentItem\n",
    "                values[numCells] = nonzero_model_coef_value[ranking[index]]\n",
    "\n",
    "                numCells += 1\n",
    "\n",
    "            # finally, replace the original values of the j-th column\n",
    "            URM_train.data[start_pos:end_pos] = current_item_data_backup\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "            new_time_value, new_time_unit = seconds_to_biggest_unit(elapsed_time)\n",
    "\n",
    "\n",
    "            if time.time() - start_time_printBatch > 300 or currentItem == n_items-1:\n",
    "                self._print(\"Processed {} ({:4.1f}%) in {:.2f} {}. Items per second: {:.2f}\".format(\n",
    "                    currentItem+1,\n",
    "                    100.0* float(currentItem+1)/n_items,\n",
    "                    new_time_value,\n",
    "                    new_time_unit,\n",
    "                    float(currentItem)/elapsed_time))\n",
    "\n",
    "                sys.stdout.flush()\n",
    "                sys.stderr.flush()\n",
    "\n",
    "                start_time_printBatch = time.time()\n",
    "\n",
    "        # generate the sparse weight matrix\n",
    "        self.W_sparse = sps.csr_matrix((values[:numCells], (rows[:numCells], cols[:numCells])),\n",
    "                                       shape=(n_items, n_items), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba207010",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T22:47:41.753249Z",
     "iopub.status.busy": "2022-12-26T22:47:41.752594Z",
     "iopub.status.idle": "2022-12-26T23:14:38.110087Z",
     "shell.execute_reply": "2022-12-26T23:14:38.108455Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1616.377466,
     "end_time": "2022-12-26T23:14:38.112894",
     "exception": false,
     "start_time": "2022-12-26T22:47:41.735428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: Processed 4230 (17.3%) in 5.00 min. Items per second: 14.09\n",
      "SLIMElasticNetRecommender: Processed 8972 (36.6%) in 10.00 min. Items per second: 14.95\n",
      "SLIMElasticNetRecommender: Processed 13727 (56.0%) in 15.00 min. Items per second: 15.25\n",
      "SLIMElasticNetRecommender: Processed 18392 (75.0%) in 20.00 min. Items per second: 15.32\n",
      "SLIMElasticNetRecommender: Processed 22750 (92.8%) in 25.00 min. Items per second: 15.16\n",
      "SLIMElasticNetRecommender: Processed 24507 (100.0%) in 26.94 min. Items per second: 15.16\n"
     ]
    }
   ],
   "source": [
    "slim_en = SLIMElasticNetRecommender(URM_train)\n",
    "slim_en.fit(l1_ratio = 0.02, alpha = 0.0018503383172588782,  positive_only = True, topK = 600)\n",
    "recommender_object_dict[\"SLIM_EN\"] = slim_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3908cb9e",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T23:14:38.158845Z",
     "iopub.status.busy": "2022-12-26T23:14:38.157572Z",
     "iopub.status.idle": "2022-12-26T23:18:09.343419Z",
     "shell.execute_reply": "2022-12-26T23:18:09.342073Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 211.38417,
     "end_time": "2022-12-26T23:18:09.519955",
     "exception": false,
     "start_time": "2022-12-26T23:14:38.135785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIM_BPR_Recommender: Automatic selection of fastest train mode. Available RAM is 30585.00 MB (95.25%) of 32110.00 MB, required is 2402.37 MB. Using dense matrix.\n",
      "Processed 41629 (100.0%) in 1.11 sec. BPR loss is 1.94E-03. Sample per second: 37650\n",
      "SLIM_BPR_Recommender: Epoch 1 of 650. Elapsed time 0.22 sec\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 1.28E-02. Sample per second: 124711\n",
      "SLIM_BPR_Recommender: Epoch 2 of 650. Elapsed time 0.45 sec\n",
      "Processed 41629 (100.0%) in 0.55 sec. BPR loss is 3.07E-02. Sample per second: 75293\n",
      "SLIM_BPR_Recommender: Epoch 3 of 650. Elapsed time 0.67 sec\n",
      "Processed 41629 (100.0%) in 0.77 sec. BPR loss is 5.39E-02. Sample per second: 53995\n",
      "SLIM_BPR_Recommender: Epoch 4 of 650. Elapsed time 0.89 sec\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 7.79E-02. Sample per second: 42416\n",
      "SLIM_BPR_Recommender: Epoch 5 of 650. Elapsed time 1.10 sec\n",
      "Processed 41629 (100.0%) in 1.20 sec. BPR loss is 1.10E-01. Sample per second: 34663\n",
      "SLIM_BPR_Recommender: Epoch 6 of 650. Elapsed time 1.32 sec\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 1.30E-01. Sample per second: 98529\n",
      "SLIM_BPR_Recommender: Epoch 7 of 650. Elapsed time 1.54 sec\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 1.70E-01. Sample per second: 65417\n",
      "SLIM_BPR_Recommender: Epoch 8 of 650. Elapsed time 1.75 sec\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 1.99E-01. Sample per second: 49343\n",
      "SLIM_BPR_Recommender: Epoch 9 of 650. Elapsed time 1.96 sec\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 2.24E-01. Sample per second: 39368\n",
      "SLIM_BPR_Recommender: Epoch 10 of 650. Elapsed time 2.17 sec\n",
      "Processed 41629 (100.0%) in 0.28 sec. BPR loss is 2.51E-01. Sample per second: 149763\n",
      "SLIM_BPR_Recommender: Epoch 11 of 650. Elapsed time 2.39 sec\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 2.60E-01. Sample per second: 85577\n",
      "SLIM_BPR_Recommender: Epoch 12 of 650. Elapsed time 2.60 sec\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 3.20E-01. Sample per second: 60144\n",
      "SLIM_BPR_Recommender: Epoch 13 of 650. Elapsed time 2.81 sec\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 3.62E-01. Sample per second: 46636\n",
      "SLIM_BPR_Recommender: Epoch 14 of 650. Elapsed time 3.01 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 3.74E-01. Sample per second: 38106\n",
      "SLIM_BPR_Recommender: Epoch 15 of 650. Elapsed time 3.21 sec\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 4.16E-01. Sample per second: 144586\n",
      "SLIM_BPR_Recommender: Epoch 16 of 650. Elapsed time 3.40 sec\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 4.50E-01. Sample per second: 85766\n",
      "SLIM_BPR_Recommender: Epoch 17 of 650. Elapsed time 3.60 sec\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 4.67E-01. Sample per second: 60663\n",
      "SLIM_BPR_Recommender: Epoch 18 of 650. Elapsed time 3.80 sec\n",
      "Processed 41629 (100.0%) in 0.88 sec. BPR loss is 5.37E-01. Sample per second: 47163\n",
      "SLIM_BPR_Recommender: Epoch 19 of 650. Elapsed time 4.00 sec\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 5.70E-01. Sample per second: 38564\n",
      "SLIM_BPR_Recommender: Epoch 20 of 650. Elapsed time 4.19 sec\n",
      "Processed 41629 (100.0%) in 0.27 sec. BPR loss is 5.81E-01. Sample per second: 152895\n",
      "SLIM_BPR_Recommender: Epoch 21 of 650. Elapsed time 4.39 sec\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 6.14E-01. Sample per second: 89982\n",
      "SLIM_BPR_Recommender: Epoch 22 of 650. Elapsed time 4.58 sec\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 6.40E-01. Sample per second: 62814\n",
      "SLIM_BPR_Recommender: Epoch 23 of 650. Elapsed time 4.78 sec\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 6.91E-01. Sample per second: 48526\n",
      "SLIM_BPR_Recommender: Epoch 24 of 650. Elapsed time 4.97 sec\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 7.04E-01. Sample per second: 39458\n",
      "SLIM_BPR_Recommender: Epoch 25 of 650. Elapsed time 5.17 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 7.05E-01. Sample per second: 164950\n",
      "SLIM_BPR_Recommender: Epoch 26 of 650. Elapsed time 5.37 sec\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 7.44E-01. Sample per second: 93068\n",
      "SLIM_BPR_Recommender: Epoch 27 of 650. Elapsed time 5.56 sec\n",
      "Processed 41629 (100.0%) in 0.65 sec. BPR loss is 7.82E-01. Sample per second: 64502\n",
      "SLIM_BPR_Recommender: Epoch 28 of 650. Elapsed time 5.76 sec\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 7.97E-01. Sample per second: 48561\n",
      "SLIM_BPR_Recommender: Epoch 29 of 650. Elapsed time 5.97 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 9.00E-01. Sample per second: 38885\n",
      "SLIM_BPR_Recommender: Epoch 30 of 650. Elapsed time 6.19 sec\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 8.92E-01. Sample per second: 142829\n",
      "SLIM_BPR_Recommender: Epoch 31 of 650. Elapsed time 6.41 sec\n",
      "Processed 41629 (100.0%) in 0.50 sec. BPR loss is 8.53E-01. Sample per second: 83120\n",
      "SLIM_BPR_Recommender: Epoch 32 of 650. Elapsed time 6.62 sec\n",
      "Processed 41629 (100.0%) in 0.71 sec. BPR loss is 9.61E-01. Sample per second: 58887\n",
      "SLIM_BPR_Recommender: Epoch 33 of 650. Elapsed time 6.82 sec\n",
      "Processed 41629 (100.0%) in 0.92 sec. BPR loss is 9.89E-01. Sample per second: 45253\n",
      "SLIM_BPR_Recommender: Epoch 34 of 650. Elapsed time 7.03 sec\n",
      "Processed 41629 (100.0%) in 1.12 sec. BPR loss is 9.80E-01. Sample per second: 37181\n",
      "SLIM_BPR_Recommender: Epoch 35 of 650. Elapsed time 7.23 sec\n",
      "Processed 41629 (100.0%) in 0.32 sec. BPR loss is 1.06E+00. Sample per second: 129711\n",
      "SLIM_BPR_Recommender: Epoch 36 of 650. Elapsed time 7.44 sec\n",
      "Processed 41629 (100.0%) in 0.52 sec. BPR loss is 1.03E+00. Sample per second: 79484\n",
      "SLIM_BPR_Recommender: Epoch 37 of 650. Elapsed time 7.64 sec\n",
      "Processed 41629 (100.0%) in 0.73 sec. BPR loss is 1.09E+00. Sample per second: 57096\n",
      "SLIM_BPR_Recommender: Epoch 38 of 650. Elapsed time 7.84 sec\n",
      "Processed 41629 (100.0%) in 0.93 sec. BPR loss is 1.04E+00. Sample per second: 44696\n",
      "SLIM_BPR_Recommender: Epoch 39 of 650. Elapsed time 8.05 sec\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 1.14E+00. Sample per second: 36597\n",
      "SLIM_BPR_Recommender: Epoch 40 of 650. Elapsed time 8.25 sec\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 1.20E+00. Sample per second: 121194\n",
      "SLIM_BPR_Recommender: Epoch 41 of 650. Elapsed time 8.46 sec\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 1.18E+00. Sample per second: 76454\n",
      "SLIM_BPR_Recommender: Epoch 42 of 650. Elapsed time 8.66 sec\n",
      "Processed 41629 (100.0%) in 0.74 sec. BPR loss is 1.19E+00. Sample per second: 56297\n",
      "SLIM_BPR_Recommender: Epoch 43 of 650. Elapsed time 8.85 sec\n",
      "Processed 41629 (100.0%) in 0.94 sec. BPR loss is 1.31E+00. Sample per second: 44479\n",
      "SLIM_BPR_Recommender: Epoch 44 of 650. Elapsed time 9.05 sec\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 1.35E+00. Sample per second: 35822\n",
      "SLIM_BPR_Recommender: Epoch 45 of 650. Elapsed time 9.28 sec\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 1.39E+00. Sample per second: 115466\n",
      "SLIM_BPR_Recommender: Epoch 46 of 650. Elapsed time 9.48 sec\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 1.38E+00. Sample per second: 73270\n",
      "SLIM_BPR_Recommender: Epoch 47 of 650. Elapsed time 9.68 sec\n",
      "Processed 41629 (100.0%) in 0.77 sec. BPR loss is 1.38E+00. Sample per second: 53919\n",
      "SLIM_BPR_Recommender: Epoch 48 of 650. Elapsed time 9.89 sec\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 1.47E+00. Sample per second: 42342\n",
      "SLIM_BPR_Recommender: Epoch 49 of 650. Elapsed time 10.10 sec\n",
      "Processed 41629 (100.0%) in 1.20 sec. BPR loss is 1.41E+00. Sample per second: 34695\n",
      "SLIM_BPR_Recommender: Epoch 50 of 650. Elapsed time 10.32 sec\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 1.43E+00. Sample per second: 98801\n",
      "SLIM_BPR_Recommender: Epoch 51 of 650. Elapsed time 10.54 sec\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 1.56E+00. Sample per second: 66522\n",
      "SLIM_BPR_Recommender: Epoch 52 of 650. Elapsed time 10.74 sec\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 1.51E+00. Sample per second: 50649\n",
      "SLIM_BPR_Recommender: Epoch 53 of 650. Elapsed time 10.94 sec\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 1.53E+00. Sample per second: 40583\n",
      "SLIM_BPR_Recommender: Epoch 54 of 650. Elapsed time 11.14 sec\n",
      "Processed 41629 (100.0%) in 0.23 sec. BPR loss is 1.61E+00. Sample per second: 180375\n",
      "SLIM_BPR_Recommender: Epoch 55 of 650. Elapsed time 11.35 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 1.63E+00. Sample per second: 96695\n",
      "SLIM_BPR_Recommender: Epoch 56 of 650. Elapsed time 11.55 sec\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 1.65E+00. Sample per second: 65683\n",
      "SLIM_BPR_Recommender: Epoch 57 of 650. Elapsed time 11.75 sec\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 1.64E+00. Sample per second: 49513\n",
      "SLIM_BPR_Recommender: Epoch 58 of 650. Elapsed time 11.96 sec\n",
      "Processed 41629 (100.0%) in 1.04 sec. BPR loss is 1.70E+00. Sample per second: 39959\n",
      "SLIM_BPR_Recommender: Epoch 59 of 650. Elapsed time 12.16 sec\n",
      "Processed 41629 (100.0%) in 0.24 sec. BPR loss is 1.80E+00. Sample per second: 172090\n",
      "SLIM_BPR_Recommender: Epoch 60 of 650. Elapsed time 12.36 sec\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 1.74E+00. Sample per second: 94165\n",
      "SLIM_BPR_Recommender: Epoch 61 of 650. Elapsed time 12.56 sec\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 1.74E+00. Sample per second: 65167\n",
      "SLIM_BPR_Recommender: Epoch 62 of 650. Elapsed time 12.75 sec\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 1.76E+00. Sample per second: 49511\n",
      "SLIM_BPR_Recommender: Epoch 63 of 650. Elapsed time 12.96 sec\n",
      "Processed 41629 (100.0%) in 1.04 sec. BPR loss is 1.93E+00. Sample per second: 40134\n",
      "SLIM_BPR_Recommender: Epoch 64 of 650. Elapsed time 13.15 sec\n",
      "Processed 41629 (100.0%) in 0.24 sec. BPR loss is 1.91E+00. Sample per second: 176082\n",
      "SLIM_BPR_Recommender: Epoch 65 of 650. Elapsed time 13.35 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 1.88E+00. Sample per second: 97071\n",
      "SLIM_BPR_Recommender: Epoch 66 of 650. Elapsed time 13.54 sec\n",
      "Processed 41629 (100.0%) in 0.62 sec. BPR loss is 1.94E+00. Sample per second: 67136\n",
      "SLIM_BPR_Recommender: Epoch 67 of 650. Elapsed time 13.74 sec\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 1.96E+00. Sample per second: 50214\n",
      "SLIM_BPR_Recommender: Epoch 68 of 650. Elapsed time 13.94 sec\n",
      "Processed 41629 (100.0%) in 1.02 sec. BPR loss is 1.94E+00. Sample per second: 40680\n",
      "SLIM_BPR_Recommender: Epoch 69 of 650. Elapsed time 14.14 sec\n",
      "Processed 41629 (100.0%) in 0.22 sec. BPR loss is 2.08E+00. Sample per second: 192194\n",
      "SLIM_BPR_Recommender: Epoch 70 of 650. Elapsed time 14.33 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 2.03E+00. Sample per second: 96251\n",
      "SLIM_BPR_Recommender: Epoch 71 of 650. Elapsed time 14.55 sec\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 2.07E+00. Sample per second: 63245\n",
      "SLIM_BPR_Recommender: Epoch 72 of 650. Elapsed time 14.77 sec\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 2.12E+00. Sample per second: 47777\n",
      "SLIM_BPR_Recommender: Epoch 73 of 650. Elapsed time 14.99 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 2.07E+00. Sample per second: 38755\n",
      "SLIM_BPR_Recommender: Epoch 74 of 650. Elapsed time 15.19 sec\n",
      "Processed 41629 (100.0%) in 0.27 sec. BPR loss is 2.09E+00. Sample per second: 154525\n",
      "SLIM_BPR_Recommender: Epoch 75 of 650. Elapsed time 15.38 sec\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 2.16E+00. Sample per second: 90145\n",
      "SLIM_BPR_Recommender: Epoch 76 of 650. Elapsed time 15.58 sec\n",
      "Processed 41629 (100.0%) in 0.65 sec. BPR loss is 2.10E+00. Sample per second: 63905\n",
      "SLIM_BPR_Recommender: Epoch 77 of 650. Elapsed time 15.77 sec\n",
      "Processed 41629 (100.0%) in 0.85 sec. BPR loss is 2.14E+00. Sample per second: 49170\n",
      "SLIM_BPR_Recommender: Epoch 78 of 650. Elapsed time 15.96 sec\n",
      "Processed 41629 (100.0%) in 1.04 sec. BPR loss is 2.23E+00. Sample per second: 39944\n",
      "SLIM_BPR_Recommender: Epoch 79 of 650. Elapsed time 16.16 sec\n",
      "Processed 41629 (100.0%) in 0.24 sec. BPR loss is 2.28E+00. Sample per second: 175109\n",
      "SLIM_BPR_Recommender: Epoch 80 of 650. Elapsed time 16.35 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 2.28E+00. Sample per second: 96492\n",
      "SLIM_BPR_Recommender: Epoch 81 of 650. Elapsed time 16.55 sec\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 2.37E+00. Sample per second: 66424\n",
      "SLIM_BPR_Recommender: Epoch 82 of 650. Elapsed time 16.74 sec\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 2.27E+00. Sample per second: 50735\n",
      "SLIM_BPR_Recommender: Epoch 83 of 650. Elapsed time 16.94 sec\n",
      "Processed 41629 (100.0%) in 1.02 sec. BPR loss is 2.39E+00. Sample per second: 40988\n",
      "SLIM_BPR_Recommender: Epoch 84 of 650. Elapsed time 17.13 sec\n",
      "Processed 41629 (100.0%) in 0.21 sec. BPR loss is 2.35E+00. Sample per second: 199858\n",
      "SLIM_BPR_Recommender: Epoch 85 of 650. Elapsed time 17.32 sec\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 2.43E+00. Sample per second: 103888\n",
      "SLIM_BPR_Recommender: Epoch 86 of 650. Elapsed time 17.52 sec\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 2.43E+00. Sample per second: 69916\n",
      "SLIM_BPR_Recommender: Epoch 87 of 650. Elapsed time 17.71 sec\n",
      "Processed 41629 (100.0%) in 0.79 sec. BPR loss is 2.37E+00. Sample per second: 52532\n",
      "SLIM_BPR_Recommender: Epoch 88 of 650. Elapsed time 17.91 sec\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 2.48E+00. Sample per second: 42168\n",
      "SLIM_BPR_Recommender: Epoch 89 of 650. Elapsed time 18.10 sec\n",
      "Processed 41629 (100.0%) in 1.19 sec. BPR loss is 2.48E+00. Sample per second: 34880\n",
      "SLIM_BPR_Recommender: Epoch 90 of 650. Elapsed time 18.31 sec\n",
      "Processed 41629 (100.0%) in 0.41 sec. BPR loss is 2.50E+00. Sample per second: 102652\n",
      "SLIM_BPR_Recommender: Epoch 91 of 650. Elapsed time 18.52 sec\n",
      "Processed 41629 (100.0%) in 0.62 sec. BPR loss is 2.54E+00. Sample per second: 66823\n",
      "SLIM_BPR_Recommender: Epoch 92 of 650. Elapsed time 18.74 sec\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 2.72E+00. Sample per second: 49813\n",
      "SLIM_BPR_Recommender: Epoch 93 of 650. Elapsed time 18.95 sec\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 2.59E+00. Sample per second: 39734\n",
      "SLIM_BPR_Recommender: Epoch 94 of 650. Elapsed time 19.16 sec\n",
      "Processed 41629 (100.0%) in 0.27 sec. BPR loss is 2.59E+00. Sample per second: 156503\n",
      "SLIM_BPR_Recommender: Epoch 95 of 650. Elapsed time 19.38 sec\n",
      "Processed 41629 (100.0%) in 0.48 sec. BPR loss is 2.66E+00. Sample per second: 86953\n",
      "SLIM_BPR_Recommender: Epoch 96 of 650. Elapsed time 19.59 sec\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 2.58E+00. Sample per second: 60239\n",
      "SLIM_BPR_Recommender: Epoch 97 of 650. Elapsed time 19.81 sec\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 2.69E+00. Sample per second: 46171\n",
      "SLIM_BPR_Recommender: Epoch 98 of 650. Elapsed time 20.02 sec\n",
      "Processed 41629 (100.0%) in 1.13 sec. BPR loss is 2.87E+00. Sample per second: 36702\n",
      "SLIM_BPR_Recommender: Epoch 99 of 650. Elapsed time 20.25 sec\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 2.74E+00. Sample per second: 117714\n",
      "SLIM_BPR_Recommender: Epoch 100 of 650. Elapsed time 20.47 sec\n",
      "Processed 41629 (100.0%) in 0.56 sec. BPR loss is 2.80E+00. Sample per second: 73787\n",
      "SLIM_BPR_Recommender: Epoch 101 of 650. Elapsed time 20.68 sec\n",
      "Processed 41629 (100.0%) in 0.77 sec. BPR loss is 2.81E+00. Sample per second: 53846\n",
      "SLIM_BPR_Recommender: Epoch 102 of 650. Elapsed time 20.89 sec\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 2.87E+00. Sample per second: 41891\n",
      "SLIM_BPR_Recommender: Epoch 103 of 650. Elapsed time 21.11 sec\n",
      "Processed 41629 (100.0%) in 1.21 sec. BPR loss is 2.93E+00. Sample per second: 34467\n",
      "SLIM_BPR_Recommender: Epoch 104 of 650. Elapsed time 21.32 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 2.80E+00. Sample per second: 96738\n",
      "SLIM_BPR_Recommender: Epoch 105 of 650. Elapsed time 21.55 sec\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 3.06E+00. Sample per second: 63515\n",
      "SLIM_BPR_Recommender: Epoch 106 of 650. Elapsed time 21.77 sec\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 2.82E+00. Sample per second: 47715\n",
      "SLIM_BPR_Recommender: Epoch 107 of 650. Elapsed time 21.99 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 3.06E+00. Sample per second: 38197\n",
      "SLIM_BPR_Recommender: Epoch 108 of 650. Elapsed time 22.20 sec\n",
      "Processed 41629 (100.0%) in 0.31 sec. BPR loss is 2.87E+00. Sample per second: 135282\n",
      "SLIM_BPR_Recommender: Epoch 109 of 650. Elapsed time 22.42 sec\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 2.94E+00. Sample per second: 79213\n",
      "SLIM_BPR_Recommender: Epoch 110 of 650. Elapsed time 22.64 sec\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 3.02E+00. Sample per second: 55843\n",
      "SLIM_BPR_Recommender: Epoch 111 of 650. Elapsed time 22.86 sec\n",
      "Processed 41629 (100.0%) in 0.97 sec. BPR loss is 3.02E+00. Sample per second: 42931\n",
      "SLIM_BPR_Recommender: Epoch 112 of 650. Elapsed time 23.08 sec\n",
      "Processed 41629 (100.0%) in 1.19 sec. BPR loss is 2.90E+00. Sample per second: 34937\n",
      "SLIM_BPR_Recommender: Epoch 113 of 650. Elapsed time 23.31 sec\n",
      "Processed 41629 (100.0%) in 0.41 sec. BPR loss is 2.99E+00. Sample per second: 102373\n",
      "SLIM_BPR_Recommender: Epoch 114 of 650. Elapsed time 23.52 sec\n",
      "Processed 41629 (100.0%) in 0.62 sec. BPR loss is 3.01E+00. Sample per second: 67267\n",
      "SLIM_BPR_Recommender: Epoch 115 of 650. Elapsed time 23.73 sec\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 3.33E+00. Sample per second: 49827\n",
      "SLIM_BPR_Recommender: Epoch 116 of 650. Elapsed time 23.95 sec\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 3.12E+00. Sample per second: 39326\n",
      "SLIM_BPR_Recommender: Epoch 117 of 650. Elapsed time 24.17 sec\n",
      "Processed 41629 (100.0%) in 0.28 sec. BPR loss is 2.98E+00. Sample per second: 150618\n",
      "SLIM_BPR_Recommender: Epoch 118 of 650. Elapsed time 24.39 sec\n",
      "Processed 41629 (100.0%) in 0.50 sec. BPR loss is 3.07E+00. Sample per second: 84036\n",
      "SLIM_BPR_Recommender: Epoch 119 of 650. Elapsed time 24.61 sec\n",
      "Processed 41629 (100.0%) in 0.71 sec. BPR loss is 3.12E+00. Sample per second: 58643\n",
      "SLIM_BPR_Recommender: Epoch 120 of 650. Elapsed time 24.82 sec\n",
      "Processed 41629 (100.0%) in 0.93 sec. BPR loss is 3.22E+00. Sample per second: 44710\n",
      "SLIM_BPR_Recommender: Epoch 121 of 650. Elapsed time 25.05 sec\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 3.29E+00. Sample per second: 35971\n",
      "SLIM_BPR_Recommender: Epoch 122 of 650. Elapsed time 25.27 sec\n",
      "Processed 41629 (100.0%) in 0.37 sec. BPR loss is 3.18E+00. Sample per second: 112381\n",
      "SLIM_BPR_Recommender: Epoch 123 of 650. Elapsed time 25.49 sec\n",
      "Processed 41629 (100.0%) in 0.59 sec. BPR loss is 3.32E+00. Sample per second: 70469\n",
      "SLIM_BPR_Recommender: Epoch 124 of 650. Elapsed time 25.71 sec\n",
      "Processed 41629 (100.0%) in 0.80 sec. BPR loss is 3.44E+00. Sample per second: 51764\n",
      "SLIM_BPR_Recommender: Epoch 125 of 650. Elapsed time 25.92 sec\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 3.53E+00. Sample per second: 40415\n",
      "SLIM_BPR_Recommender: Epoch 126 of 650. Elapsed time 26.14 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 3.36E+00. Sample per second: 165993\n",
      "SLIM_BPR_Recommender: Epoch 127 of 650. Elapsed time 26.37 sec\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 3.32E+00. Sample per second: 89637\n",
      "SLIM_BPR_Recommender: Epoch 128 of 650. Elapsed time 26.58 sec\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 3.40E+00. Sample per second: 60243\n",
      "SLIM_BPR_Recommender: Epoch 129 of 650. Elapsed time 26.81 sec\n",
      "Processed 41629 (100.0%) in 0.91 sec. BPR loss is 3.44E+00. Sample per second: 45886\n",
      "SLIM_BPR_Recommender: Epoch 130 of 650. Elapsed time 27.02 sec\n",
      "Processed 41629 (100.0%) in 1.12 sec. BPR loss is 3.46E+00. Sample per second: 37108\n",
      "SLIM_BPR_Recommender: Epoch 131 of 650. Elapsed time 27.24 sec\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 3.45E+00. Sample per second: 125843\n",
      "SLIM_BPR_Recommender: Epoch 132 of 650. Elapsed time 27.45 sec\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 3.56E+00. Sample per second: 76482\n",
      "SLIM_BPR_Recommender: Epoch 133 of 650. Elapsed time 27.66 sec\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 3.49E+00. Sample per second: 55301\n",
      "SLIM_BPR_Recommender: Epoch 134 of 650. Elapsed time 27.87 sec\n",
      "Processed 41629 (100.0%) in 0.96 sec. BPR loss is 3.46E+00. Sample per second: 43180\n",
      "SLIM_BPR_Recommender: Epoch 135 of 650. Elapsed time 28.08 sec\n",
      "Processed 41629 (100.0%) in 1.18 sec. BPR loss is 3.42E+00. Sample per second: 35255\n",
      "SLIM_BPR_Recommender: Epoch 136 of 650. Elapsed time 28.30 sec\n",
      "Processed 41629 (100.0%) in 0.39 sec. BPR loss is 3.50E+00. Sample per second: 106634\n",
      "SLIM_BPR_Recommender: Epoch 137 of 650. Elapsed time 28.51 sec\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 3.78E+00. Sample per second: 68953\n",
      "SLIM_BPR_Recommender: Epoch 138 of 650. Elapsed time 28.72 sec\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 3.42E+00. Sample per second: 50984\n",
      "SLIM_BPR_Recommender: Epoch 139 of 650. Elapsed time 28.93 sec\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 3.57E+00. Sample per second: 40328\n",
      "SLIM_BPR_Recommender: Epoch 140 of 650. Elapsed time 29.15 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 3.67E+00. Sample per second: 164688\n",
      "SLIM_BPR_Recommender: Epoch 141 of 650. Elapsed time 29.37 sec\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 3.59E+00. Sample per second: 89645\n",
      "SLIM_BPR_Recommender: Epoch 142 of 650. Elapsed time 29.58 sec\n",
      "Processed 41629 (100.0%) in 0.68 sec. BPR loss is 3.67E+00. Sample per second: 61257\n",
      "SLIM_BPR_Recommender: Epoch 143 of 650. Elapsed time 29.79 sec\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 3.73E+00. Sample per second: 46640\n",
      "SLIM_BPR_Recommender: Epoch 144 of 650. Elapsed time 30.01 sec\n",
      "Processed 41629 (100.0%) in 1.11 sec. BPR loss is 3.83E+00. Sample per second: 37535\n",
      "SLIM_BPR_Recommender: Epoch 145 of 650. Elapsed time 30.22 sec\n",
      "Processed 41629 (100.0%) in 0.32 sec. BPR loss is 3.72E+00. Sample per second: 129573\n",
      "SLIM_BPR_Recommender: Epoch 146 of 650. Elapsed time 30.44 sec\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 3.75E+00. Sample per second: 78201\n",
      "SLIM_BPR_Recommender: Epoch 147 of 650. Elapsed time 30.65 sec\n",
      "Processed 41629 (100.0%) in 0.74 sec. BPR loss is 3.88E+00. Sample per second: 55884\n",
      "SLIM_BPR_Recommender: Epoch 148 of 650. Elapsed time 30.86 sec\n",
      "Processed 41629 (100.0%) in 0.96 sec. BPR loss is 3.65E+00. Sample per second: 43461\n",
      "SLIM_BPR_Recommender: Epoch 149 of 650. Elapsed time 31.07 sec\n",
      "Processed 41629 (100.0%) in 1.20 sec. BPR loss is 3.73E+00. Sample per second: 34663\n",
      "SLIM_BPR_Recommender: Epoch 150 of 650. Elapsed time 31.32 sec\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 3.98E+00. Sample per second: 99916\n",
      "SLIM_BPR_Recommender: Epoch 151 of 650. Elapsed time 31.53 sec\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 3.99E+00. Sample per second: 65737\n",
      "SLIM_BPR_Recommender: Epoch 152 of 650. Elapsed time 31.75 sec\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 3.88E+00. Sample per second: 49285\n",
      "SLIM_BPR_Recommender: Epoch 153 of 650. Elapsed time 31.96 sec\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 3.90E+00. Sample per second: 39164\n",
      "SLIM_BPR_Recommender: Epoch 154 of 650. Elapsed time 32.18 sec\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 3.93E+00. Sample per second: 141975\n",
      "SLIM_BPR_Recommender: Epoch 155 of 650. Elapsed time 32.41 sec\n",
      "Processed 41629 (100.0%) in 0.51 sec. BPR loss is 4.00E+00. Sample per second: 80856\n",
      "SLIM_BPR_Recommender: Epoch 156 of 650. Elapsed time 32.63 sec\n",
      "Processed 41629 (100.0%) in 0.74 sec. BPR loss is 3.99E+00. Sample per second: 56340\n",
      "SLIM_BPR_Recommender: Epoch 157 of 650. Elapsed time 32.85 sec\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 3.91E+00. Sample per second: 43586\n",
      "SLIM_BPR_Recommender: Epoch 158 of 650. Elapsed time 33.07 sec\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 3.92E+00. Sample per second: 35431\n",
      "SLIM_BPR_Recommender: Epoch 159 of 650. Elapsed time 33.29 sec\n",
      "Processed 41629 (100.0%) in 0.39 sec. BPR loss is 3.93E+00. Sample per second: 107272\n",
      "SLIM_BPR_Recommender: Epoch 160 of 650. Elapsed time 33.50 sec\n",
      "Processed 41629 (100.0%) in 0.61 sec. BPR loss is 3.82E+00. Sample per second: 68619\n",
      "SLIM_BPR_Recommender: Epoch 161 of 650. Elapsed time 33.72 sec\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 4.08E+00. Sample per second: 50240\n",
      "SLIM_BPR_Recommender: Epoch 162 of 650. Elapsed time 33.94 sec\n",
      "Processed 41629 (100.0%) in 1.04 sec. BPR loss is 3.93E+00. Sample per second: 39945\n",
      "SLIM_BPR_Recommender: Epoch 163 of 650. Elapsed time 34.16 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 4.12E+00. Sample per second: 163972\n",
      "SLIM_BPR_Recommender: Epoch 164 of 650. Elapsed time 34.37 sec\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 3.95E+00. Sample per second: 88655\n",
      "SLIM_BPR_Recommender: Epoch 165 of 650. Elapsed time 34.58 sec\n",
      "Processed 41629 (100.0%) in 0.68 sec. BPR loss is 4.05E+00. Sample per second: 61626\n",
      "SLIM_BPR_Recommender: Epoch 166 of 650. Elapsed time 34.79 sec\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 4.08E+00. Sample per second: 47813\n",
      "SLIM_BPR_Recommender: Epoch 167 of 650. Elapsed time 34.99 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 4.07E+00. Sample per second: 38945\n",
      "SLIM_BPR_Recommender: Epoch 168 of 650. Elapsed time 35.18 sec\n",
      "Processed 41629 (100.0%) in 0.27 sec. BPR loss is 4.12E+00. Sample per second: 156425\n",
      "SLIM_BPR_Recommender: Epoch 169 of 650. Elapsed time 35.38 sec\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 4.11E+00. Sample per second: 89952\n",
      "SLIM_BPR_Recommender: Epoch 170 of 650. Elapsed time 35.58 sec\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 4.45E+00. Sample per second: 63247\n",
      "SLIM_BPR_Recommender: Epoch 171 of 650. Elapsed time 35.77 sec\n",
      "Processed 41629 (100.0%) in 0.85 sec. BPR loss is 4.60E+00. Sample per second: 48776\n",
      "SLIM_BPR_Recommender: Epoch 172 of 650. Elapsed time 35.97 sec\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 4.30E+00. Sample per second: 39611\n",
      "SLIM_BPR_Recommender: Epoch 173 of 650. Elapsed time 36.17 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 4.37E+00. Sample per second: 165412\n",
      "SLIM_BPR_Recommender: Epoch 174 of 650. Elapsed time 36.37 sec\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 4.20E+00. Sample per second: 94010\n",
      "SLIM_BPR_Recommender: Epoch 175 of 650. Elapsed time 36.56 sec\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 4.29E+00. Sample per second: 65181\n",
      "SLIM_BPR_Recommender: Epoch 176 of 650. Elapsed time 36.75 sec\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 4.23E+00. Sample per second: 50052\n",
      "SLIM_BPR_Recommender: Epoch 177 of 650. Elapsed time 36.95 sec\n",
      "Processed 41629 (100.0%) in 1.02 sec. BPR loss is 4.27E+00. Sample per second: 40633\n",
      "SLIM_BPR_Recommender: Epoch 178 of 650. Elapsed time 37.14 sec\n",
      "Processed 41629 (100.0%) in 0.24 sec. BPR loss is 4.29E+00. Sample per second: 172606\n",
      "SLIM_BPR_Recommender: Epoch 179 of 650. Elapsed time 37.36 sec\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 4.30E+00. Sample per second: 92316\n",
      "SLIM_BPR_Recommender: Epoch 180 of 650. Elapsed time 37.57 sec\n",
      "Processed 41629 (100.0%) in 0.65 sec. BPR loss is 4.13E+00. Sample per second: 64244\n",
      "SLIM_BPR_Recommender: Epoch 181 of 650. Elapsed time 37.76 sec\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 4.53E+00. Sample per second: 49394\n",
      "SLIM_BPR_Recommender: Epoch 182 of 650. Elapsed time 37.96 sec\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 4.57E+00. Sample per second: 39804\n",
      "SLIM_BPR_Recommender: Epoch 183 of 650. Elapsed time 38.16 sec\n",
      "Processed 41629 (100.0%) in 0.24 sec. BPR loss is 4.32E+00. Sample per second: 172654\n",
      "SLIM_BPR_Recommender: Epoch 184 of 650. Elapsed time 38.36 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 4.49E+00. Sample per second: 96003\n",
      "SLIM_BPR_Recommender: Epoch 185 of 650. Elapsed time 38.55 sec\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 4.64E+00. Sample per second: 66482\n",
      "SLIM_BPR_Recommender: Epoch 186 of 650. Elapsed time 38.74 sec\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 4.51E+00. Sample per second: 50802\n",
      "SLIM_BPR_Recommender: Epoch 187 of 650. Elapsed time 38.93 sec\n",
      "Processed 41629 (100.0%) in 1.02 sec. BPR loss is 4.63E+00. Sample per second: 40814\n",
      "SLIM_BPR_Recommender: Epoch 188 of 650. Elapsed time 39.13 sec\n",
      "Processed 41629 (100.0%) in 0.22 sec. BPR loss is 4.33E+00. Sample per second: 193041\n",
      "SLIM_BPR_Recommender: Epoch 189 of 650. Elapsed time 39.33 sec\n",
      "Processed 41629 (100.0%) in 0.41 sec. BPR loss is 4.56E+00. Sample per second: 102525\n",
      "SLIM_BPR_Recommender: Epoch 190 of 650. Elapsed time 39.52 sec\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 4.54E+00. Sample per second: 69248\n",
      "SLIM_BPR_Recommender: Epoch 191 of 650. Elapsed time 39.72 sec\n",
      "Processed 41629 (100.0%) in 0.79 sec. BPR loss is 4.45E+00. Sample per second: 52434\n",
      "SLIM_BPR_Recommender: Epoch 192 of 650. Elapsed time 39.91 sec\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 4.62E+00. Sample per second: 41921\n",
      "SLIM_BPR_Recommender: Epoch 193 of 650. Elapsed time 40.11 sec\n",
      "Processed 41629 (100.0%) in 1.19 sec. BPR loss is 4.53E+00. Sample per second: 34996\n",
      "SLIM_BPR_Recommender: Epoch 194 of 650. Elapsed time 40.30 sec\n",
      "Processed 41629 (100.0%) in 0.38 sec. BPR loss is 4.46E+00. Sample per second: 109026\n",
      "SLIM_BPR_Recommender: Epoch 195 of 650. Elapsed time 40.50 sec\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 4.79E+00. Sample per second: 72380\n",
      "SLIM_BPR_Recommender: Epoch 196 of 650. Elapsed time 40.69 sec\n",
      "Processed 41629 (100.0%) in 0.77 sec. BPR loss is 4.70E+00. Sample per second: 54398\n",
      "SLIM_BPR_Recommender: Epoch 197 of 650. Elapsed time 40.88 sec\n",
      "Processed 41629 (100.0%) in 0.96 sec. BPR loss is 4.60E+00. Sample per second: 43521\n",
      "SLIM_BPR_Recommender: Epoch 198 of 650. Elapsed time 41.07 sec\n",
      "Processed 41629 (100.0%) in 1.15 sec. BPR loss is 5.09E+00. Sample per second: 36258\n",
      "SLIM_BPR_Recommender: Epoch 199 of 650. Elapsed time 41.26 sec\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 4.63E+00. Sample per second: 123123\n",
      "SLIM_BPR_Recommender: Epoch 200 of 650. Elapsed time 41.45 sec\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 4.90E+00. Sample per second: 78709\n",
      "SLIM_BPR_Recommender: Epoch 201 of 650. Elapsed time 41.64 sec\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 4.76E+00. Sample per second: 57415\n",
      "SLIM_BPR_Recommender: Epoch 202 of 650. Elapsed time 41.84 sec\n",
      "Processed 41629 (100.0%) in 0.92 sec. BPR loss is 4.91E+00. Sample per second: 45334\n",
      "SLIM_BPR_Recommender: Epoch 203 of 650. Elapsed time 42.03 sec\n",
      "Processed 41629 (100.0%) in 1.13 sec. BPR loss is 4.93E+00. Sample per second: 36705\n",
      "SLIM_BPR_Recommender: Epoch 204 of 650. Elapsed time 42.25 sec\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 4.80E+00. Sample per second: 114167\n",
      "SLIM_BPR_Recommender: Epoch 205 of 650. Elapsed time 42.48 sec\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 4.86E+00. Sample per second: 73000\n",
      "SLIM_BPR_Recommender: Epoch 206 of 650. Elapsed time 42.69 sec\n",
      "Processed 41629 (100.0%) in 0.77 sec. BPR loss is 4.89E+00. Sample per second: 54376\n",
      "SLIM_BPR_Recommender: Epoch 207 of 650. Elapsed time 42.88 sec\n",
      "Processed 41629 (100.0%) in 0.96 sec. BPR loss is 4.65E+00. Sample per second: 43186\n",
      "SLIM_BPR_Recommender: Epoch 208 of 650. Elapsed time 43.08 sec\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 4.90E+00. Sample per second: 35805\n",
      "SLIM_BPR_Recommender: Epoch 209 of 650. Elapsed time 43.28 sec\n",
      "Processed 41629 (100.0%) in 0.37 sec. BPR loss is 4.97E+00. Sample per second: 113315\n",
      "SLIM_BPR_Recommender: Epoch 210 of 650. Elapsed time 43.48 sec\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 5.06E+00. Sample per second: 72200\n",
      "SLIM_BPR_Recommender: Epoch 211 of 650. Elapsed time 43.69 sec\n",
      "Processed 41629 (100.0%) in 0.78 sec. BPR loss is 4.96E+00. Sample per second: 53547\n",
      "SLIM_BPR_Recommender: Epoch 212 of 650. Elapsed time 43.89 sec\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 4.83E+00. Sample per second: 42444\n",
      "SLIM_BPR_Recommender: Epoch 213 of 650. Elapsed time 44.10 sec\n",
      "Processed 41629 (100.0%) in 1.19 sec. BPR loss is 4.95E+00. Sample per second: 34939\n",
      "SLIM_BPR_Recommender: Epoch 214 of 650. Elapsed time 44.31 sec\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 4.81E+00. Sample per second: 103711\n",
      "SLIM_BPR_Recommender: Epoch 215 of 650. Elapsed time 44.52 sec\n",
      "Processed 41629 (100.0%) in 0.61 sec. BPR loss is 5.10E+00. Sample per second: 68011\n",
      "SLIM_BPR_Recommender: Epoch 216 of 650. Elapsed time 44.73 sec\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 5.02E+00. Sample per second: 50853\n",
      "SLIM_BPR_Recommender: Epoch 217 of 650. Elapsed time 44.93 sec\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 5.06E+00. Sample per second: 40534\n",
      "SLIM_BPR_Recommender: Epoch 218 of 650. Elapsed time 45.14 sec\n",
      "Processed 41629 (100.0%) in 0.23 sec. BPR loss is 4.99E+00. Sample per second: 183389\n",
      "SLIM_BPR_Recommender: Epoch 219 of 650. Elapsed time 45.34 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 4.94E+00. Sample per second: 96829\n",
      "SLIM_BPR_Recommender: Epoch 220 of 650. Elapsed time 45.55 sec\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 4.99E+00. Sample per second: 65210\n",
      "SLIM_BPR_Recommender: Epoch 221 of 650. Elapsed time 45.75 sec\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 5.12E+00. Sample per second: 49294\n",
      "SLIM_BPR_Recommender: Epoch 222 of 650. Elapsed time 45.96 sec\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 4.85E+00. Sample per second: 39825\n",
      "SLIM_BPR_Recommender: Epoch 223 of 650. Elapsed time 46.16 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 5.14E+00. Sample per second: 164794\n",
      "SLIM_BPR_Recommender: Epoch 224 of 650. Elapsed time 46.37 sec\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 5.05E+00. Sample per second: 92350\n",
      "SLIM_BPR_Recommender: Epoch 225 of 650. Elapsed time 46.57 sec\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 5.21E+00. Sample per second: 62772\n",
      "SLIM_BPR_Recommender: Epoch 226 of 650. Elapsed time 46.78 sec\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 5.27E+00. Sample per second: 47805\n",
      "SLIM_BPR_Recommender: Epoch 227 of 650. Elapsed time 46.99 sec\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 4.99E+00. Sample per second: 38448\n",
      "SLIM_BPR_Recommender: Epoch 228 of 650. Elapsed time 47.20 sec\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 4.98E+00. Sample per second: 140068\n",
      "SLIM_BPR_Recommender: Epoch 229 of 650. Elapsed time 47.41 sec\n",
      "Processed 41629 (100.0%) in 0.50 sec. BPR loss is 5.10E+00. Sample per second: 82424\n",
      "SLIM_BPR_Recommender: Epoch 230 of 650. Elapsed time 47.62 sec\n",
      "Processed 41629 (100.0%) in 0.71 sec. BPR loss is 5.46E+00. Sample per second: 58618\n",
      "SLIM_BPR_Recommender: Epoch 231 of 650. Elapsed time 47.83 sec\n",
      "Processed 41629 (100.0%) in 0.91 sec. BPR loss is 5.17E+00. Sample per second: 45501\n",
      "SLIM_BPR_Recommender: Epoch 232 of 650. Elapsed time 48.03 sec\n",
      "Processed 41629 (100.0%) in 1.12 sec. BPR loss is 5.25E+00. Sample per second: 37077\n",
      "SLIM_BPR_Recommender: Epoch 233 of 650. Elapsed time 48.24 sec\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 5.28E+00. Sample per second: 126256\n",
      "SLIM_BPR_Recommender: Epoch 234 of 650. Elapsed time 48.45 sec\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 4.97E+00. Sample per second: 77876\n",
      "SLIM_BPR_Recommender: Epoch 235 of 650. Elapsed time 48.65 sec\n",
      "Processed 41629 (100.0%) in 0.74 sec. BPR loss is 5.41E+00. Sample per second: 56516\n",
      "SLIM_BPR_Recommender: Epoch 236 of 650. Elapsed time 48.85 sec\n",
      "Processed 41629 (100.0%) in 0.93 sec. BPR loss is 5.26E+00. Sample per second: 44525\n",
      "SLIM_BPR_Recommender: Epoch 237 of 650. Elapsed time 49.05 sec\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 5.28E+00. Sample per second: 36471\n",
      "SLIM_BPR_Recommender: Epoch 238 of 650. Elapsed time 49.26 sec\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 5.27E+00. Sample per second: 121747\n",
      "SLIM_BPR_Recommender: Epoch 239 of 650. Elapsed time 49.46 sec\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 5.29E+00. Sample per second: 76963\n",
      "SLIM_BPR_Recommender: Epoch 240 of 650. Elapsed time 49.66 sec\n",
      "Processed 41629 (100.0%) in 0.74 sec. BPR loss is 5.29E+00. Sample per second: 56261\n",
      "SLIM_BPR_Recommender: Epoch 241 of 650. Elapsed time 49.85 sec\n",
      "Processed 41629 (100.0%) in 0.94 sec. BPR loss is 5.49E+00. Sample per second: 44448\n",
      "SLIM_BPR_Recommender: Epoch 242 of 650. Elapsed time 50.05 sec\n",
      "Processed 41629 (100.0%) in 1.13 sec. BPR loss is 5.37E+00. Sample per second: 36747\n",
      "SLIM_BPR_Recommender: Epoch 243 of 650. Elapsed time 50.25 sec\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 5.41E+00. Sample per second: 125858\n",
      "SLIM_BPR_Recommender: Epoch 244 of 650. Elapsed time 50.45 sec\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 5.32E+00. Sample per second: 78728\n",
      "SLIM_BPR_Recommender: Epoch 245 of 650. Elapsed time 50.64 sec\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 5.42E+00. Sample per second: 57621\n",
      "SLIM_BPR_Recommender: Epoch 246 of 650. Elapsed time 50.84 sec\n",
      "Processed 41629 (100.0%) in 0.91 sec. BPR loss is 5.41E+00. Sample per second: 45536\n",
      "SLIM_BPR_Recommender: Epoch 247 of 650. Elapsed time 51.03 sec\n",
      "Processed 41629 (100.0%) in 1.11 sec. BPR loss is 5.52E+00. Sample per second: 37455\n",
      "SLIM_BPR_Recommender: Epoch 248 of 650. Elapsed time 51.23 sec\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 5.68E+00. Sample per second: 136567\n",
      "SLIM_BPR_Recommender: Epoch 249 of 650. Elapsed time 51.42 sec\n",
      "Processed 41629 (100.0%) in 0.50 sec. BPR loss is 5.72E+00. Sample per second: 83707\n",
      "SLIM_BPR_Recommender: Epoch 250 of 650. Elapsed time 51.61 sec\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 5.59E+00. Sample per second: 60033\n",
      "SLIM_BPR_Recommender: Epoch 251 of 650. Elapsed time 51.81 sec\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 5.73E+00. Sample per second: 46922\n",
      "SLIM_BPR_Recommender: Epoch 252 of 650. Elapsed time 52.00 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 5.51E+00. Sample per second: 38251\n",
      "SLIM_BPR_Recommender: Epoch 253 of 650. Elapsed time 52.20 sec\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 5.46E+00. Sample per second: 142779\n",
      "SLIM_BPR_Recommender: Epoch 254 of 650. Elapsed time 52.41 sec\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 5.66E+00. Sample per second: 84696\n",
      "SLIM_BPR_Recommender: Epoch 255 of 650. Elapsed time 52.61 sec\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 5.50E+00. Sample per second: 60411\n",
      "SLIM_BPR_Recommender: Epoch 256 of 650. Elapsed time 52.80 sec\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 5.62E+00. Sample per second: 46884\n",
      "SLIM_BPR_Recommender: Epoch 257 of 650. Elapsed time 53.00 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 5.59E+00. Sample per second: 38022\n",
      "SLIM_BPR_Recommender: Epoch 258 of 650. Elapsed time 53.21 sec\n",
      "Processed 41629 (100.0%) in 0.31 sec. BPR loss is 5.50E+00. Sample per second: 135875\n",
      "SLIM_BPR_Recommender: Epoch 259 of 650. Elapsed time 53.42 sec\n",
      "Processed 41629 (100.0%) in 0.50 sec. BPR loss is 5.75E+00. Sample per second: 83991\n",
      "SLIM_BPR_Recommender: Epoch 260 of 650. Elapsed time 53.61 sec\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 5.64E+00. Sample per second: 60333\n",
      "SLIM_BPR_Recommender: Epoch 261 of 650. Elapsed time 53.80 sec\n",
      "Processed 41629 (100.0%) in 0.88 sec. BPR loss is 5.64E+00. Sample per second: 47062\n",
      "SLIM_BPR_Recommender: Epoch 262 of 650. Elapsed time 54.00 sec\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 5.67E+00. Sample per second: 38422\n",
      "SLIM_BPR_Recommender: Epoch 263 of 650. Elapsed time 54.20 sec\n",
      "Processed 41629 (100.0%) in 0.28 sec. BPR loss is 5.85E+00. Sample per second: 148473\n",
      "SLIM_BPR_Recommender: Epoch 264 of 650. Elapsed time 54.40 sec\n",
      "Processed 41629 (100.0%) in 0.48 sec. BPR loss is 5.74E+00. Sample per second: 87231\n",
      "SLIM_BPR_Recommender: Epoch 265 of 650. Elapsed time 54.59 sec\n",
      "Processed 41629 (100.0%) in 0.67 sec. BPR loss is 5.81E+00. Sample per second: 61662\n",
      "SLIM_BPR_Recommender: Epoch 266 of 650. Elapsed time 54.79 sec\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 5.62E+00. Sample per second: 47840\n",
      "SLIM_BPR_Recommender: Epoch 267 of 650. Elapsed time 54.98 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 6.05E+00. Sample per second: 38898\n",
      "SLIM_BPR_Recommender: Epoch 268 of 650. Elapsed time 55.18 sec\n",
      "Processed 41629 (100.0%) in 0.26 sec. BPR loss is 5.74E+00. Sample per second: 160060\n",
      "SLIM_BPR_Recommender: Epoch 269 of 650. Elapsed time 55.38 sec\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 5.74E+00. Sample per second: 91710\n",
      "SLIM_BPR_Recommender: Epoch 270 of 650. Elapsed time 55.57 sec\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 5.78E+00. Sample per second: 63155\n",
      "SLIM_BPR_Recommender: Epoch 271 of 650. Elapsed time 55.77 sec\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 5.94E+00. Sample per second: 48030\n",
      "SLIM_BPR_Recommender: Epoch 272 of 650. Elapsed time 55.98 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 5.71E+00. Sample per second: 39080\n",
      "SLIM_BPR_Recommender: Epoch 273 of 650. Elapsed time 56.18 sec\n",
      "Processed 41629 (100.0%) in 0.26 sec. BPR loss is 5.98E+00. Sample per second: 158685\n",
      "SLIM_BPR_Recommender: Epoch 274 of 650. Elapsed time 56.38 sec\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 5.86E+00. Sample per second: 91151\n",
      "SLIM_BPR_Recommender: Epoch 275 of 650. Elapsed time 56.57 sec\n",
      "Processed 41629 (100.0%) in 0.65 sec. BPR loss is 6.00E+00. Sample per second: 63828\n",
      "SLIM_BPR_Recommender: Epoch 276 of 650. Elapsed time 56.77 sec\n",
      "Processed 41629 (100.0%) in 0.85 sec. BPR loss is 6.04E+00. Sample per second: 49060\n",
      "SLIM_BPR_Recommender: Epoch 277 of 650. Elapsed time 56.96 sec\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 5.92E+00. Sample per second: 39790\n",
      "SLIM_BPR_Recommender: Epoch 278 of 650. Elapsed time 57.16 sec\n",
      "Processed 41629 (100.0%) in 0.24 sec. BPR loss is 5.86E+00. Sample per second: 170885\n",
      "SLIM_BPR_Recommender: Epoch 279 of 650. Elapsed time 57.36 sec\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 5.92E+00. Sample per second: 94622\n",
      "SLIM_BPR_Recommender: Epoch 280 of 650. Elapsed time 57.55 sec\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 6.31E+00. Sample per second: 65486\n",
      "SLIM_BPR_Recommender: Epoch 281 of 650. Elapsed time 57.75 sec\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 5.82E+00. Sample per second: 50071\n",
      "SLIM_BPR_Recommender: Epoch 282 of 650. Elapsed time 57.95 sec\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 6.01E+00. Sample per second: 40470\n",
      "SLIM_BPR_Recommender: Epoch 283 of 650. Elapsed time 58.14 sec\n",
      "Processed 41629 (100.0%) in 0.23 sec. BPR loss is 6.04E+00. Sample per second: 183396\n",
      "SLIM_BPR_Recommender: Epoch 284 of 650. Elapsed time 58.34 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 6.15E+00. Sample per second: 97115\n",
      "SLIM_BPR_Recommender: Epoch 285 of 650. Elapsed time 58.54 sec\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 6.02E+00. Sample per second: 66512\n",
      "SLIM_BPR_Recommender: Epoch 286 of 650. Elapsed time 58.74 sec\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 6.23E+00. Sample per second: 50656\n",
      "SLIM_BPR_Recommender: Epoch 287 of 650. Elapsed time 58.94 sec\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 6.05E+00. Sample per second: 41062\n",
      "SLIM_BPR_Recommender: Epoch 288 of 650. Elapsed time 59.13 sec\n",
      "Processed 41629 (100.0%) in 0.21 sec. BPR loss is 5.83E+00. Sample per second: 196717\n",
      "SLIM_BPR_Recommender: Epoch 289 of 650. Elapsed time 59.33 sec\n",
      "Processed 41629 (100.0%) in 0.41 sec. BPR loss is 5.85E+00. Sample per second: 102119\n",
      "SLIM_BPR_Recommender: Epoch 290 of 650. Elapsed time 59.52 sec\n",
      "Processed 41629 (100.0%) in 0.61 sec. BPR loss is 6.28E+00. Sample per second: 68179\n",
      "SLIM_BPR_Recommender: Epoch 291 of 650. Elapsed time 59.73 sec\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 6.10E+00. Sample per second: 51535\n",
      "SLIM_BPR_Recommender: Epoch 292 of 650. Elapsed time 59.92 sec\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 6.13E+00. Sample per second: 41403\n",
      "SLIM_BPR_Recommender: Epoch 293 of 650. Elapsed time 1.00 min\n",
      "Processed 41629 (100.0%) in 0.21 sec. BPR loss is 6.19E+00. Sample per second: 201140\n",
      "SLIM_BPR_Recommender: Epoch 294 of 650. Elapsed time 1.01 min\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 6.23E+00. Sample per second: 103072\n",
      "SLIM_BPR_Recommender: Epoch 295 of 650. Elapsed time 1.01 min\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 6.38E+00. Sample per second: 69230\n",
      "SLIM_BPR_Recommender: Epoch 296 of 650. Elapsed time 1.01 min\n",
      "Processed 41629 (100.0%) in 0.80 sec. BPR loss is 6.12E+00. Sample per second: 52177\n",
      "SLIM_BPR_Recommender: Epoch 297 of 650. Elapsed time 1.02 min\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 6.21E+00. Sample per second: 41889\n",
      "SLIM_BPR_Recommender: Epoch 298 of 650. Elapsed time 1.02 min\n",
      "Processed 41629 (100.0%) in 1.19 sec. BPR loss is 6.23E+00. Sample per second: 35104\n",
      "SLIM_BPR_Recommender: Epoch 299 of 650. Elapsed time 1.02 min\n",
      "Processed 41629 (100.0%) in 0.38 sec. BPR loss is 6.69E+00. Sample per second: 108934\n",
      "SLIM_BPR_Recommender: Epoch 300 of 650. Elapsed time 1.02 min\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 6.15E+00. Sample per second: 71819\n",
      "SLIM_BPR_Recommender: Epoch 301 of 650. Elapsed time 1.03 min\n",
      "Processed 41629 (100.0%) in 0.77 sec. BPR loss is 6.31E+00. Sample per second: 53725\n",
      "SLIM_BPR_Recommender: Epoch 302 of 650. Elapsed time 1.03 min\n",
      "Processed 41629 (100.0%) in 0.97 sec. BPR loss is 6.38E+00. Sample per second: 42891\n",
      "SLIM_BPR_Recommender: Epoch 303 of 650. Elapsed time 1.03 min\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 6.02E+00. Sample per second: 35792\n",
      "SLIM_BPR_Recommender: Epoch 304 of 650. Elapsed time 1.04 min\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 6.14E+00. Sample per second: 115090\n",
      "SLIM_BPR_Recommender: Epoch 305 of 650. Elapsed time 1.04 min\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 6.06E+00. Sample per second: 73166\n",
      "SLIM_BPR_Recommender: Epoch 306 of 650. Elapsed time 1.04 min\n",
      "Processed 41629 (100.0%) in 0.77 sec. BPR loss is 6.20E+00. Sample per second: 53859\n",
      "SLIM_BPR_Recommender: Epoch 307 of 650. Elapsed time 1.05 min\n",
      "Processed 41629 (100.0%) in 0.97 sec. BPR loss is 6.20E+00. Sample per second: 42844\n",
      "SLIM_BPR_Recommender: Epoch 308 of 650. Elapsed time 1.05 min\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 6.47E+00. Sample per second: 35575\n",
      "SLIM_BPR_Recommender: Epoch 309 of 650. Elapsed time 1.05 min\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 6.64E+00. Sample per second: 114280\n",
      "SLIM_BPR_Recommender: Epoch 310 of 650. Elapsed time 1.06 min\n",
      "Processed 41629 (100.0%) in 0.56 sec. BPR loss is 6.50E+00. Sample per second: 74389\n",
      "SLIM_BPR_Recommender: Epoch 311 of 650. Elapsed time 1.06 min\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 6.28E+00. Sample per second: 55001\n",
      "SLIM_BPR_Recommender: Epoch 312 of 650. Elapsed time 1.06 min\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 6.15E+00. Sample per second: 43857\n",
      "SLIM_BPR_Recommender: Epoch 313 of 650. Elapsed time 1.07 min\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 6.44E+00. Sample per second: 35431\n",
      "SLIM_BPR_Recommender: Epoch 314 of 650. Elapsed time 1.07 min\n",
      "Processed 41629 (100.0%) in 0.37 sec. BPR loss is 6.73E+00. Sample per second: 113819\n",
      "SLIM_BPR_Recommender: Epoch 315 of 650. Elapsed time 1.07 min\n",
      "Processed 41629 (100.0%) in 0.56 sec. BPR loss is 6.41E+00. Sample per second: 74325\n",
      "SLIM_BPR_Recommender: Epoch 316 of 650. Elapsed time 1.08 min\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 6.45E+00. Sample per second: 55271\n",
      "SLIM_BPR_Recommender: Epoch 317 of 650. Elapsed time 1.08 min\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 6.41E+00. Sample per second: 43992\n",
      "SLIM_BPR_Recommender: Epoch 318 of 650. Elapsed time 1.08 min\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 6.60E+00. Sample per second: 36569\n",
      "SLIM_BPR_Recommender: Epoch 319 of 650. Elapsed time 1.09 min\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 6.38E+00. Sample per second: 126858\n",
      "SLIM_BPR_Recommender: Epoch 320 of 650. Elapsed time 1.09 min\n",
      "Processed 41629 (100.0%) in 0.52 sec. BPR loss is 6.33E+00. Sample per second: 80397\n",
      "SLIM_BPR_Recommender: Epoch 321 of 650. Elapsed time 1.09 min\n",
      "Processed 41629 (100.0%) in 0.71 sec. BPR loss is 6.32E+00. Sample per second: 58647\n",
      "SLIM_BPR_Recommender: Epoch 322 of 650. Elapsed time 1.10 min\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 6.48E+00. Sample per second: 46001\n",
      "SLIM_BPR_Recommender: Epoch 323 of 650. Elapsed time 1.10 min\n",
      "Processed 41629 (100.0%) in 1.10 sec. BPR loss is 6.54E+00. Sample per second: 37851\n",
      "SLIM_BPR_Recommender: Epoch 324 of 650. Elapsed time 1.10 min\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 6.36E+00. Sample per second: 140249\n",
      "SLIM_BPR_Recommender: Epoch 325 of 650. Elapsed time 1.11 min\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 6.33E+00. Sample per second: 84624\n",
      "SLIM_BPR_Recommender: Epoch 326 of 650. Elapsed time 1.11 min\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 6.86E+00. Sample per second: 60308\n",
      "SLIM_BPR_Recommender: Epoch 327 of 650. Elapsed time 1.11 min\n",
      "Processed 41629 (100.0%) in 0.88 sec. BPR loss is 6.89E+00. Sample per second: 47172\n",
      "SLIM_BPR_Recommender: Epoch 328 of 650. Elapsed time 1.12 min\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 6.65E+00. Sample per second: 38753\n",
      "SLIM_BPR_Recommender: Epoch 329 of 650. Elapsed time 1.12 min\n",
      "Processed 41629 (100.0%) in 0.26 sec. BPR loss is 6.86E+00. Sample per second: 157283\n",
      "SLIM_BPR_Recommender: Epoch 330 of 650. Elapsed time 1.12 min\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 6.63E+00. Sample per second: 91560\n",
      "SLIM_BPR_Recommender: Epoch 331 of 650. Elapsed time 1.13 min\n",
      "Processed 41629 (100.0%) in 0.65 sec. BPR loss is 6.59E+00. Sample per second: 64403\n",
      "SLIM_BPR_Recommender: Epoch 332 of 650. Elapsed time 1.13 min\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 6.79E+00. Sample per second: 49814\n",
      "SLIM_BPR_Recommender: Epoch 333 of 650. Elapsed time 1.13 min\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 6.37E+00. Sample per second: 40396\n",
      "SLIM_BPR_Recommender: Epoch 334 of 650. Elapsed time 1.14 min\n",
      "Processed 41629 (100.0%) in 0.23 sec. BPR loss is 6.54E+00. Sample per second: 182967\n",
      "SLIM_BPR_Recommender: Epoch 335 of 650. Elapsed time 1.14 min\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 6.63E+00. Sample per second: 90658\n",
      "SLIM_BPR_Recommender: Epoch 336 of 650. Elapsed time 1.14 min\n",
      "Processed 41629 (100.0%) in 0.68 sec. BPR loss is 6.65E+00. Sample per second: 61544\n",
      "SLIM_BPR_Recommender: Epoch 337 of 650. Elapsed time 1.15 min\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 6.79E+00. Sample per second: 47820\n",
      "SLIM_BPR_Recommender: Epoch 338 of 650. Elapsed time 1.15 min\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 6.67E+00. Sample per second: 38665\n",
      "SLIM_BPR_Recommender: Epoch 339 of 650. Elapsed time 1.15 min\n",
      "Processed 41629 (100.0%) in 0.28 sec. BPR loss is 6.63E+00. Sample per second: 150116\n",
      "SLIM_BPR_Recommender: Epoch 340 of 650. Elapsed time 1.16 min\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 6.72E+00. Sample per second: 88086\n",
      "SLIM_BPR_Recommender: Epoch 341 of 650. Elapsed time 1.16 min\n",
      "Processed 41629 (100.0%) in 0.67 sec. BPR loss is 6.80E+00. Sample per second: 62062\n",
      "SLIM_BPR_Recommender: Epoch 342 of 650. Elapsed time 1.16 min\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 6.51E+00. Sample per second: 47875\n",
      "SLIM_BPR_Recommender: Epoch 343 of 650. Elapsed time 1.17 min\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 6.62E+00. Sample per second: 39013\n",
      "SLIM_BPR_Recommender: Epoch 344 of 650. Elapsed time 1.17 min\n",
      "Processed 41629 (100.0%) in 0.26 sec. BPR loss is 6.84E+00. Sample per second: 157255\n",
      "SLIM_BPR_Recommender: Epoch 345 of 650. Elapsed time 1.17 min\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 6.58E+00. Sample per second: 90662\n",
      "SLIM_BPR_Recommender: Epoch 346 of 650. Elapsed time 1.18 min\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 6.97E+00. Sample per second: 62853\n",
      "SLIM_BPR_Recommender: Epoch 347 of 650. Elapsed time 1.18 min\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 6.75E+00. Sample per second: 48353\n",
      "SLIM_BPR_Recommender: Epoch 348 of 650. Elapsed time 1.18 min\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 6.89E+00. Sample per second: 39240\n",
      "SLIM_BPR_Recommender: Epoch 349 of 650. Elapsed time 1.19 min\n",
      "Processed 41629 (100.0%) in 0.26 sec. BPR loss is 6.99E+00. Sample per second: 159848\n",
      "SLIM_BPR_Recommender: Epoch 350 of 650. Elapsed time 1.19 min\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 6.63E+00. Sample per second: 90906\n",
      "SLIM_BPR_Recommender: Epoch 351 of 650. Elapsed time 1.19 min\n",
      "Processed 41629 (100.0%) in 0.65 sec. BPR loss is 7.14E+00. Sample per second: 63560\n",
      "SLIM_BPR_Recommender: Epoch 352 of 650. Elapsed time 1.20 min\n",
      "Processed 41629 (100.0%) in 0.85 sec. BPR loss is 6.90E+00. Sample per second: 48965\n",
      "SLIM_BPR_Recommender: Epoch 353 of 650. Elapsed time 1.20 min\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 6.71E+00. Sample per second: 39652\n",
      "SLIM_BPR_Recommender: Epoch 354 of 650. Elapsed time 1.20 min\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 6.90E+00. Sample per second: 165154\n",
      "SLIM_BPR_Recommender: Epoch 355 of 650. Elapsed time 1.21 min\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 6.91E+00. Sample per second: 91654\n",
      "SLIM_BPR_Recommender: Epoch 356 of 650. Elapsed time 1.21 min\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 6.83E+00. Sample per second: 63395\n",
      "SLIM_BPR_Recommender: Epoch 357 of 650. Elapsed time 1.21 min\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 7.03E+00. Sample per second: 48482\n",
      "SLIM_BPR_Recommender: Epoch 358 of 650. Elapsed time 1.22 min\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 7.11E+00. Sample per second: 39407\n",
      "SLIM_BPR_Recommender: Epoch 359 of 650. Elapsed time 1.22 min\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 6.99E+00. Sample per second: 165355\n",
      "SLIM_BPR_Recommender: Epoch 360 of 650. Elapsed time 1.22 min\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 7.19E+00. Sample per second: 93341\n",
      "SLIM_BPR_Recommender: Epoch 361 of 650. Elapsed time 1.23 min\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 6.95E+00. Sample per second: 64865\n",
      "SLIM_BPR_Recommender: Epoch 362 of 650. Elapsed time 1.23 min\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 7.03E+00. Sample per second: 49562\n",
      "SLIM_BPR_Recommender: Epoch 363 of 650. Elapsed time 1.23 min\n",
      "Processed 41629 (100.0%) in 1.04 sec. BPR loss is 6.82E+00. Sample per second: 40133\n",
      "SLIM_BPR_Recommender: Epoch 364 of 650. Elapsed time 1.24 min\n",
      "Processed 41629 (100.0%) in 0.24 sec. BPR loss is 6.73E+00. Sample per second: 172342\n",
      "SLIM_BPR_Recommender: Epoch 365 of 650. Elapsed time 1.24 min\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 7.12E+00. Sample per second: 94995\n",
      "SLIM_BPR_Recommender: Epoch 366 of 650. Elapsed time 1.24 min\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 7.08E+00. Sample per second: 65522\n",
      "SLIM_BPR_Recommender: Epoch 367 of 650. Elapsed time 1.25 min\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 7.08E+00. Sample per second: 49729\n",
      "SLIM_BPR_Recommender: Epoch 368 of 650. Elapsed time 1.25 min\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 6.95E+00. Sample per second: 40230\n",
      "SLIM_BPR_Recommender: Epoch 369 of 650. Elapsed time 1.25 min\n",
      "Processed 41629 (100.0%) in 0.27 sec. BPR loss is 7.43E+00. Sample per second: 155879\n",
      "SLIM_BPR_Recommender: Epoch 370 of 650. Elapsed time 1.26 min\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 6.85E+00. Sample per second: 89698\n",
      "SLIM_BPR_Recommender: Epoch 371 of 650. Elapsed time 1.26 min\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 7.24E+00. Sample per second: 62914\n",
      "SLIM_BPR_Recommender: Epoch 372 of 650. Elapsed time 1.26 min\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 6.95E+00. Sample per second: 48364\n",
      "SLIM_BPR_Recommender: Epoch 373 of 650. Elapsed time 1.27 min\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 6.92E+00. Sample per second: 39138\n",
      "SLIM_BPR_Recommender: Epoch 374 of 650. Elapsed time 1.27 min\n",
      "Processed 41629 (100.0%) in 0.27 sec. BPR loss is 7.14E+00. Sample per second: 156774\n",
      "SLIM_BPR_Recommender: Epoch 375 of 650. Elapsed time 1.27 min\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 7.23E+00. Sample per second: 90370\n",
      "SLIM_BPR_Recommender: Epoch 376 of 650. Elapsed time 1.28 min\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 7.06E+00. Sample per second: 62780\n",
      "SLIM_BPR_Recommender: Epoch 377 of 650. Elapsed time 1.28 min\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 7.19E+00. Sample per second: 48465\n",
      "SLIM_BPR_Recommender: Epoch 378 of 650. Elapsed time 1.28 min\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 7.25E+00. Sample per second: 39360\n",
      "SLIM_BPR_Recommender: Epoch 379 of 650. Elapsed time 1.29 min\n",
      "Processed 41629 (100.0%) in 0.26 sec. BPR loss is 7.16E+00. Sample per second: 159689\n",
      "SLIM_BPR_Recommender: Epoch 380 of 650. Elapsed time 1.29 min\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 6.95E+00. Sample per second: 90790\n",
      "SLIM_BPR_Recommender: Epoch 381 of 650. Elapsed time 1.29 min\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 7.03E+00. Sample per second: 63497\n",
      "SLIM_BPR_Recommender: Epoch 382 of 650. Elapsed time 1.30 min\n",
      "Processed 41629 (100.0%) in 0.85 sec. BPR loss is 7.29E+00. Sample per second: 48903\n",
      "SLIM_BPR_Recommender: Epoch 383 of 650. Elapsed time 1.30 min\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 7.08E+00. Sample per second: 39524\n",
      "SLIM_BPR_Recommender: Epoch 384 of 650. Elapsed time 1.30 min\n",
      "Processed 41629 (100.0%) in 0.26 sec. BPR loss is 7.23E+00. Sample per second: 162502\n",
      "SLIM_BPR_Recommender: Epoch 385 of 650. Elapsed time 1.31 min\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 6.95E+00. Sample per second: 93055\n",
      "SLIM_BPR_Recommender: Epoch 386 of 650. Elapsed time 1.31 min\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 7.30E+00. Sample per second: 64989\n",
      "SLIM_BPR_Recommender: Epoch 387 of 650. Elapsed time 1.31 min\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 7.49E+00. Sample per second: 50046\n",
      "SLIM_BPR_Recommender: Epoch 388 of 650. Elapsed time 1.32 min\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 7.12E+00. Sample per second: 40274\n",
      "SLIM_BPR_Recommender: Epoch 389 of 650. Elapsed time 1.32 min\n",
      "Processed 41629 (100.0%) in 0.24 sec. BPR loss is 7.01E+00. Sample per second: 174468\n",
      "SLIM_BPR_Recommender: Epoch 390 of 650. Elapsed time 1.32 min\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 7.08E+00. Sample per second: 94698\n",
      "SLIM_BPR_Recommender: Epoch 391 of 650. Elapsed time 1.33 min\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 7.17E+00. Sample per second: 65235\n",
      "SLIM_BPR_Recommender: Epoch 392 of 650. Elapsed time 1.33 min\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 7.24E+00. Sample per second: 50170\n",
      "SLIM_BPR_Recommender: Epoch 393 of 650. Elapsed time 1.33 min\n",
      "Processed 41629 (100.0%) in 1.02 sec. BPR loss is 7.30E+00. Sample per second: 40857\n",
      "SLIM_BPR_Recommender: Epoch 394 of 650. Elapsed time 1.34 min\n",
      "Processed 41629 (100.0%) in 0.22 sec. BPR loss is 7.30E+00. Sample per second: 191832\n",
      "SLIM_BPR_Recommender: Epoch 395 of 650. Elapsed time 1.34 min\n",
      "Processed 41629 (100.0%) in 0.41 sec. BPR loss is 7.36E+00. Sample per second: 102420\n",
      "SLIM_BPR_Recommender: Epoch 396 of 650. Elapsed time 1.34 min\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 7.60E+00. Sample per second: 69616\n",
      "SLIM_BPR_Recommender: Epoch 397 of 650. Elapsed time 1.35 min\n",
      "Processed 41629 (100.0%) in 0.79 sec. BPR loss is 7.57E+00. Sample per second: 52612\n",
      "SLIM_BPR_Recommender: Epoch 398 of 650. Elapsed time 1.35 min\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 7.26E+00. Sample per second: 42301\n",
      "SLIM_BPR_Recommender: Epoch 399 of 650. Elapsed time 1.35 min\n",
      "Processed 41629 (100.0%) in 1.18 sec. BPR loss is 7.54E+00. Sample per second: 35334\n",
      "SLIM_BPR_Recommender: Epoch 400 of 650. Elapsed time 1.35 min\n",
      "Processed 41629 (100.0%) in 0.37 sec. BPR loss is 7.33E+00. Sample per second: 111617\n",
      "SLIM_BPR_Recommender: Epoch 401 of 650. Elapsed time 1.36 min\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 7.90E+00. Sample per second: 73311\n",
      "SLIM_BPR_Recommender: Epoch 402 of 650. Elapsed time 1.36 min\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 7.24E+00. Sample per second: 54929\n",
      "SLIM_BPR_Recommender: Epoch 403 of 650. Elapsed time 1.36 min\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 7.30E+00. Sample per second: 43885\n",
      "SLIM_BPR_Recommender: Epoch 404 of 650. Elapsed time 1.37 min\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 7.16E+00. Sample per second: 36452\n",
      "SLIM_BPR_Recommender: Epoch 405 of 650. Elapsed time 1.37 min\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 7.36E+00. Sample per second: 122845\n",
      "SLIM_BPR_Recommender: Epoch 406 of 650. Elapsed time 1.37 min\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 7.43E+00. Sample per second: 77632\n",
      "SLIM_BPR_Recommender: Epoch 407 of 650. Elapsed time 1.38 min\n",
      "Processed 41629 (100.0%) in 0.73 sec. BPR loss is 7.65E+00. Sample per second: 56923\n",
      "SLIM_BPR_Recommender: Epoch 408 of 650. Elapsed time 1.38 min\n",
      "Processed 41629 (100.0%) in 0.92 sec. BPR loss is 7.51E+00. Sample per second: 45002\n",
      "SLIM_BPR_Recommender: Epoch 409 of 650. Elapsed time 1.38 min\n",
      "Processed 41629 (100.0%) in 1.12 sec. BPR loss is 7.26E+00. Sample per second: 37205\n",
      "SLIM_BPR_Recommender: Epoch 410 of 650. Elapsed time 1.39 min\n",
      "Processed 41629 (100.0%) in 0.31 sec. BPR loss is 7.57E+00. Sample per second: 132881\n",
      "SLIM_BPR_Recommender: Epoch 411 of 650. Elapsed time 1.39 min\n",
      "Processed 41629 (100.0%) in 0.50 sec. BPR loss is 7.55E+00. Sample per second: 82746\n",
      "SLIM_BPR_Recommender: Epoch 412 of 650. Elapsed time 1.39 min\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 7.64E+00. Sample per second: 59961\n",
      "SLIM_BPR_Recommender: Epoch 413 of 650. Elapsed time 1.40 min\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 7.48E+00. Sample per second: 46858\n",
      "SLIM_BPR_Recommender: Epoch 414 of 650. Elapsed time 1.40 min\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 7.72E+00. Sample per second: 38527\n",
      "SLIM_BPR_Recommender: Epoch 415 of 650. Elapsed time 1.40 min\n",
      "Processed 41629 (100.0%) in 0.27 sec. BPR loss is 7.52E+00. Sample per second: 152562\n",
      "SLIM_BPR_Recommender: Epoch 416 of 650. Elapsed time 1.41 min\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 7.56E+00. Sample per second: 89271\n",
      "SLIM_BPR_Recommender: Epoch 417 of 650. Elapsed time 1.41 min\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 7.64E+00. Sample per second: 63177\n",
      "SLIM_BPR_Recommender: Epoch 418 of 650. Elapsed time 1.41 min\n",
      "Processed 41629 (100.0%) in 0.85 sec. BPR loss is 7.49E+00. Sample per second: 48926\n",
      "SLIM_BPR_Recommender: Epoch 419 of 650. Elapsed time 1.42 min\n",
      "Processed 41629 (100.0%) in 1.04 sec. BPR loss is 7.55E+00. Sample per second: 39880\n",
      "SLIM_BPR_Recommender: Epoch 420 of 650. Elapsed time 1.42 min\n",
      "Processed 41629 (100.0%) in 0.24 sec. BPR loss is 7.69E+00. Sample per second: 175428\n",
      "SLIM_BPR_Recommender: Epoch 421 of 650. Elapsed time 1.42 min\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 7.60E+00. Sample per second: 97087\n",
      "SLIM_BPR_Recommender: Epoch 422 of 650. Elapsed time 1.43 min\n",
      "Processed 41629 (100.0%) in 0.62 sec. BPR loss is 7.66E+00. Sample per second: 67022\n",
      "SLIM_BPR_Recommender: Epoch 423 of 650. Elapsed time 1.43 min\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 7.78E+00. Sample per second: 51019\n",
      "SLIM_BPR_Recommender: Epoch 424 of 650. Elapsed time 1.43 min\n",
      "Processed 41629 (100.0%) in 1.02 sec. BPR loss is 7.47E+00. Sample per second: 41003\n",
      "SLIM_BPR_Recommender: Epoch 425 of 650. Elapsed time 1.44 min\n",
      "Processed 41629 (100.0%) in 0.24 sec. BPR loss is 7.79E+00. Sample per second: 176854\n",
      "SLIM_BPR_Recommender: Epoch 426 of 650. Elapsed time 1.44 min\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 7.51E+00. Sample per second: 97481\n",
      "SLIM_BPR_Recommender: Epoch 427 of 650. Elapsed time 1.44 min\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 7.67E+00. Sample per second: 66140\n",
      "SLIM_BPR_Recommender: Epoch 428 of 650. Elapsed time 1.45 min\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 7.54E+00. Sample per second: 50215\n",
      "SLIM_BPR_Recommender: Epoch 429 of 650. Elapsed time 1.45 min\n",
      "Processed 41629 (100.0%) in 1.02 sec. BPR loss is 7.66E+00. Sample per second: 40628\n",
      "SLIM_BPR_Recommender: Epoch 430 of 650. Elapsed time 1.45 min\n",
      "Processed 41629 (100.0%) in 0.22 sec. BPR loss is 7.60E+00. Sample per second: 190019\n",
      "SLIM_BPR_Recommender: Epoch 431 of 650. Elapsed time 1.46 min\n",
      "Processed 41629 (100.0%) in 0.41 sec. BPR loss is 7.57E+00. Sample per second: 101460\n",
      "SLIM_BPR_Recommender: Epoch 432 of 650. Elapsed time 1.46 min\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 7.78E+00. Sample per second: 68862\n",
      "SLIM_BPR_Recommender: Epoch 433 of 650. Elapsed time 1.46 min\n",
      "Processed 41629 (100.0%) in 0.80 sec. BPR loss is 7.80E+00. Sample per second: 52157\n",
      "SLIM_BPR_Recommender: Epoch 434 of 650. Elapsed time 1.47 min\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 7.89E+00. Sample per second: 41862\n",
      "SLIM_BPR_Recommender: Epoch 435 of 650. Elapsed time 1.47 min\n",
      "Processed 41629 (100.0%) in 1.19 sec. BPR loss is 7.51E+00. Sample per second: 34958\n",
      "SLIM_BPR_Recommender: Epoch 436 of 650. Elapsed time 1.47 min\n",
      "Processed 41629 (100.0%) in 0.38 sec. BPR loss is 7.71E+00. Sample per second: 108178\n",
      "SLIM_BPR_Recommender: Epoch 437 of 650. Elapsed time 1.47 min\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 7.81E+00. Sample per second: 71165\n",
      "SLIM_BPR_Recommender: Epoch 438 of 650. Elapsed time 1.48 min\n",
      "Processed 41629 (100.0%) in 0.78 sec. BPR loss is 7.96E+00. Sample per second: 53317\n",
      "SLIM_BPR_Recommender: Epoch 439 of 650. Elapsed time 1.48 min\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 7.49E+00. Sample per second: 42675\n",
      "SLIM_BPR_Recommender: Epoch 440 of 650. Elapsed time 1.48 min\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 7.95E+00. Sample per second: 35551\n",
      "SLIM_BPR_Recommender: Epoch 441 of 650. Elapsed time 1.49 min\n",
      "Processed 41629 (100.0%) in 0.37 sec. BPR loss is 7.90E+00. Sample per second: 113286\n",
      "SLIM_BPR_Recommender: Epoch 442 of 650. Elapsed time 1.49 min\n",
      "Processed 41629 (100.0%) in 0.56 sec. BPR loss is 7.92E+00. Sample per second: 74453\n",
      "SLIM_BPR_Recommender: Epoch 443 of 650. Elapsed time 1.49 min\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 7.79E+00. Sample per second: 55473\n",
      "SLIM_BPR_Recommender: Epoch 444 of 650. Elapsed time 1.50 min\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 7.79E+00. Sample per second: 44009\n",
      "SLIM_BPR_Recommender: Epoch 445 of 650. Elapsed time 1.50 min\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 7.87E+00. Sample per second: 36535\n",
      "SLIM_BPR_Recommender: Epoch 446 of 650. Elapsed time 1.50 min\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 7.72E+00. Sample per second: 125841\n",
      "SLIM_BPR_Recommender: Epoch 447 of 650. Elapsed time 1.51 min\n",
      "Processed 41629 (100.0%) in 0.52 sec. BPR loss is 7.80E+00. Sample per second: 79502\n",
      "SLIM_BPR_Recommender: Epoch 448 of 650. Elapsed time 1.51 min\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 7.68E+00. Sample per second: 58097\n",
      "SLIM_BPR_Recommender: Epoch 449 of 650. Elapsed time 1.51 min\n",
      "Processed 41629 (100.0%) in 0.91 sec. BPR loss is 7.86E+00. Sample per second: 45787\n",
      "SLIM_BPR_Recommender: Epoch 450 of 650. Elapsed time 1.52 min\n",
      "Processed 41629 (100.0%) in 1.10 sec. BPR loss is 7.97E+00. Sample per second: 37730\n",
      "SLIM_BPR_Recommender: Epoch 451 of 650. Elapsed time 1.52 min\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 8.03E+00. Sample per second: 139019\n",
      "SLIM_BPR_Recommender: Epoch 452 of 650. Elapsed time 1.52 min\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 7.69E+00. Sample per second: 84636\n",
      "SLIM_BPR_Recommender: Epoch 453 of 650. Elapsed time 1.53 min\n",
      "Processed 41629 (100.0%) in 0.68 sec. BPR loss is 8.03E+00. Sample per second: 61017\n",
      "SLIM_BPR_Recommender: Epoch 454 of 650. Elapsed time 1.53 min\n",
      "Processed 41629 (100.0%) in 0.88 sec. BPR loss is 7.89E+00. Sample per second: 47492\n",
      "SLIM_BPR_Recommender: Epoch 455 of 650. Elapsed time 1.53 min\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 8.01E+00. Sample per second: 38843\n",
      "SLIM_BPR_Recommender: Epoch 456 of 650. Elapsed time 1.54 min\n",
      "Processed 41629 (100.0%) in 0.26 sec. BPR loss is 7.95E+00. Sample per second: 157075\n",
      "SLIM_BPR_Recommender: Epoch 457 of 650. Elapsed time 1.54 min\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 8.18E+00. Sample per second: 89964\n",
      "SLIM_BPR_Recommender: Epoch 458 of 650. Elapsed time 1.54 min\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 8.41E+00. Sample per second: 62955\n",
      "SLIM_BPR_Recommender: Epoch 459 of 650. Elapsed time 1.55 min\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 7.91E+00. Sample per second: 48464\n",
      "SLIM_BPR_Recommender: Epoch 460 of 650. Elapsed time 1.55 min\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 7.72E+00. Sample per second: 39227\n",
      "SLIM_BPR_Recommender: Epoch 461 of 650. Elapsed time 1.55 min\n",
      "Processed 41629 (100.0%) in 0.26 sec. BPR loss is 8.30E+00. Sample per second: 160908\n",
      "SLIM_BPR_Recommender: Epoch 462 of 650. Elapsed time 1.56 min\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 8.13E+00. Sample per second: 92911\n",
      "SLIM_BPR_Recommender: Epoch 463 of 650. Elapsed time 1.56 min\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 8.03E+00. Sample per second: 65383\n",
      "SLIM_BPR_Recommender: Epoch 464 of 650. Elapsed time 1.56 min\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 7.77E+00. Sample per second: 50171\n",
      "SLIM_BPR_Recommender: Epoch 465 of 650. Elapsed time 1.57 min\n",
      "Processed 41629 (100.0%) in 1.02 sec. BPR loss is 7.80E+00. Sample per second: 40781\n",
      "SLIM_BPR_Recommender: Epoch 466 of 650. Elapsed time 1.57 min\n",
      "Processed 41629 (100.0%) in 0.21 sec. BPR loss is 8.21E+00. Sample per second: 197484\n",
      "SLIM_BPR_Recommender: Epoch 467 of 650. Elapsed time 1.57 min\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 8.19E+00. Sample per second: 102833\n",
      "SLIM_BPR_Recommender: Epoch 468 of 650. Elapsed time 1.58 min\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 8.18E+00. Sample per second: 69842\n",
      "SLIM_BPR_Recommender: Epoch 469 of 650. Elapsed time 1.58 min\n",
      "Processed 41629 (100.0%) in 0.79 sec. BPR loss is 8.03E+00. Sample per second: 53009\n",
      "SLIM_BPR_Recommender: Epoch 470 of 650. Elapsed time 1.58 min\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 8.33E+00. Sample per second: 42668\n",
      "SLIM_BPR_Recommender: Epoch 471 of 650. Elapsed time 1.58 min\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 7.87E+00. Sample per second: 35589\n",
      "SLIM_BPR_Recommender: Epoch 472 of 650. Elapsed time 1.59 min\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 8.28E+00. Sample per second: 114872\n",
      "SLIM_BPR_Recommender: Epoch 473 of 650. Elapsed time 1.59 min\n",
      "Processed 41629 (100.0%) in 0.56 sec. BPR loss is 8.14E+00. Sample per second: 74189\n",
      "SLIM_BPR_Recommender: Epoch 474 of 650. Elapsed time 1.59 min\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 8.00E+00. Sample per second: 55167\n",
      "SLIM_BPR_Recommender: Epoch 475 of 650. Elapsed time 1.60 min\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 8.31E+00. Sample per second: 43763\n",
      "SLIM_BPR_Recommender: Epoch 476 of 650. Elapsed time 1.60 min\n",
      "Processed 41629 (100.0%) in 1.15 sec. BPR loss is 8.30E+00. Sample per second: 36343\n",
      "SLIM_BPR_Recommender: Epoch 477 of 650. Elapsed time 1.60 min\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 7.95E+00. Sample per second: 118548\n",
      "SLIM_BPR_Recommender: Epoch 478 of 650. Elapsed time 1.61 min\n",
      "Processed 41629 (100.0%) in 0.55 sec. BPR loss is 8.38E+00. Sample per second: 75125\n",
      "SLIM_BPR_Recommender: Epoch 479 of 650. Elapsed time 1.61 min\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 8.14E+00. Sample per second: 55534\n",
      "SLIM_BPR_Recommender: Epoch 480 of 650. Elapsed time 1.61 min\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 8.07E+00. Sample per second: 43911\n",
      "SLIM_BPR_Recommender: Epoch 481 of 650. Elapsed time 1.62 min\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 8.20E+00. Sample per second: 35586\n",
      "SLIM_BPR_Recommender: Epoch 482 of 650. Elapsed time 1.62 min\n",
      "Processed 41629 (100.0%) in 0.37 sec. BPR loss is 8.45E+00. Sample per second: 113129\n",
      "SLIM_BPR_Recommender: Epoch 483 of 650. Elapsed time 1.62 min\n",
      "Processed 41629 (100.0%) in 0.56 sec. BPR loss is 8.27E+00. Sample per second: 73818\n",
      "SLIM_BPR_Recommender: Epoch 484 of 650. Elapsed time 1.63 min\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 8.23E+00. Sample per second: 54582\n",
      "SLIM_BPR_Recommender: Epoch 485 of 650. Elapsed time 1.63 min\n",
      "Processed 41629 (100.0%) in 0.96 sec. BPR loss is 8.05E+00. Sample per second: 43365\n",
      "SLIM_BPR_Recommender: Epoch 486 of 650. Elapsed time 1.63 min\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 8.37E+00. Sample per second: 35987\n",
      "SLIM_BPR_Recommender: Epoch 487 of 650. Elapsed time 1.64 min\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 8.61E+00. Sample per second: 118653\n",
      "SLIM_BPR_Recommender: Epoch 488 of 650. Elapsed time 1.64 min\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 8.19E+00. Sample per second: 76722\n",
      "SLIM_BPR_Recommender: Epoch 489 of 650. Elapsed time 1.64 min\n",
      "Processed 41629 (100.0%) in 0.74 sec. BPR loss is 8.14E+00. Sample per second: 56399\n",
      "SLIM_BPR_Recommender: Epoch 490 of 650. Elapsed time 1.65 min\n",
      "Processed 41629 (100.0%) in 0.94 sec. BPR loss is 8.47E+00. Sample per second: 44393\n",
      "SLIM_BPR_Recommender: Epoch 491 of 650. Elapsed time 1.65 min\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 8.36E+00. Sample per second: 36540\n",
      "SLIM_BPR_Recommender: Epoch 492 of 650. Elapsed time 1.65 min\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 8.12E+00. Sample per second: 124311\n",
      "SLIM_BPR_Recommender: Epoch 493 of 650. Elapsed time 1.66 min\n",
      "Processed 41629 (100.0%) in 0.55 sec. BPR loss is 8.09E+00. Sample per second: 75440\n",
      "SLIM_BPR_Recommender: Epoch 494 of 650. Elapsed time 1.66 min\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 8.07E+00. Sample per second: 54526\n",
      "SLIM_BPR_Recommender: Epoch 495 of 650. Elapsed time 1.66 min\n",
      "Processed 41629 (100.0%) in 1.00 sec. BPR loss is 8.31E+00. Sample per second: 41809\n",
      "SLIM_BPR_Recommender: Epoch 496 of 650. Elapsed time 1.67 min\n",
      "Processed 41629 (100.0%) in 0.20 sec. BPR loss is 8.22E+00. Sample per second: 212953\n",
      "SLIM_BPR_Recommender: Epoch 497 of 650. Elapsed time 1.67 min\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 8.03E+00. Sample per second: 105037\n",
      "SLIM_BPR_Recommender: Epoch 498 of 650. Elapsed time 1.68 min\n",
      "Processed 41629 (100.0%) in 0.59 sec. BPR loss is 8.31E+00. Sample per second: 70326\n",
      "SLIM_BPR_Recommender: Epoch 499 of 650. Elapsed time 1.68 min\n",
      "Processed 41629 (100.0%) in 0.79 sec. BPR loss is 8.43E+00. Sample per second: 52985\n",
      "SLIM_BPR_Recommender: Epoch 500 of 650. Elapsed time 1.68 min\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 8.50E+00. Sample per second: 42398\n",
      "SLIM_BPR_Recommender: Epoch 501 of 650. Elapsed time 1.68 min\n",
      "Processed 41629 (100.0%) in 1.18 sec. BPR loss is 8.19E+00. Sample per second: 35260\n",
      "SLIM_BPR_Recommender: Epoch 502 of 650. Elapsed time 1.69 min\n",
      "Processed 41629 (100.0%) in 0.37 sec. BPR loss is 8.26E+00. Sample per second: 110955\n",
      "SLIM_BPR_Recommender: Epoch 503 of 650. Elapsed time 1.69 min\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 8.15E+00. Sample per second: 72995\n",
      "SLIM_BPR_Recommender: Epoch 504 of 650. Elapsed time 1.69 min\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 8.37E+00. Sample per second: 54529\n",
      "SLIM_BPR_Recommender: Epoch 505 of 650. Elapsed time 1.70 min\n",
      "Processed 41629 (100.0%) in 0.96 sec. BPR loss is 8.43E+00. Sample per second: 43399\n",
      "SLIM_BPR_Recommender: Epoch 506 of 650. Elapsed time 1.70 min\n",
      "Processed 41629 (100.0%) in 1.15 sec. BPR loss is 8.17E+00. Sample per second: 36097\n",
      "SLIM_BPR_Recommender: Epoch 507 of 650. Elapsed time 1.70 min\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 8.75E+00. Sample per second: 117967\n",
      "SLIM_BPR_Recommender: Epoch 508 of 650. Elapsed time 1.71 min\n",
      "Processed 41629 (100.0%) in 0.55 sec. BPR loss is 8.68E+00. Sample per second: 75185\n",
      "SLIM_BPR_Recommender: Epoch 509 of 650. Elapsed time 1.71 min\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 8.44E+00. Sample per second: 55240\n",
      "SLIM_BPR_Recommender: Epoch 510 of 650. Elapsed time 1.71 min\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 8.51E+00. Sample per second: 43748\n",
      "SLIM_BPR_Recommender: Epoch 511 of 650. Elapsed time 1.72 min\n",
      "Processed 41629 (100.0%) in 1.15 sec. BPR loss is 8.40E+00. Sample per second: 36192\n",
      "SLIM_BPR_Recommender: Epoch 512 of 650. Elapsed time 1.72 min\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 8.29E+00. Sample per second: 120959\n",
      "SLIM_BPR_Recommender: Epoch 513 of 650. Elapsed time 1.72 min\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 8.43E+00. Sample per second: 77204\n",
      "SLIM_BPR_Recommender: Epoch 514 of 650. Elapsed time 1.73 min\n",
      "Processed 41629 (100.0%) in 0.73 sec. BPR loss is 8.87E+00. Sample per second: 56789\n",
      "SLIM_BPR_Recommender: Epoch 515 of 650. Elapsed time 1.73 min\n",
      "Processed 41629 (100.0%) in 0.93 sec. BPR loss is 8.33E+00. Sample per second: 44745\n",
      "SLIM_BPR_Recommender: Epoch 516 of 650. Elapsed time 1.73 min\n",
      "Processed 41629 (100.0%) in 1.13 sec. BPR loss is 8.64E+00. Sample per second: 36832\n",
      "SLIM_BPR_Recommender: Epoch 517 of 650. Elapsed time 1.74 min\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 8.41E+00. Sample per second: 127931\n",
      "SLIM_BPR_Recommender: Epoch 518 of 650. Elapsed time 1.74 min\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 8.58E+00. Sample per second: 79197\n",
      "SLIM_BPR_Recommender: Epoch 519 of 650. Elapsed time 1.74 min\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 8.61E+00. Sample per second: 57693\n",
      "SLIM_BPR_Recommender: Epoch 520 of 650. Elapsed time 1.75 min\n",
      "Processed 41629 (100.0%) in 0.92 sec. BPR loss is 8.53E+00. Sample per second: 45191\n",
      "SLIM_BPR_Recommender: Epoch 521 of 650. Elapsed time 1.75 min\n",
      "Processed 41629 (100.0%) in 1.12 sec. BPR loss is 8.57E+00. Sample per second: 37241\n",
      "SLIM_BPR_Recommender: Epoch 522 of 650. Elapsed time 1.75 min\n",
      "Processed 41629 (100.0%) in 0.32 sec. BPR loss is 8.44E+00. Sample per second: 131483\n",
      "SLIM_BPR_Recommender: Epoch 523 of 650. Elapsed time 1.76 min\n",
      "Processed 41629 (100.0%) in 0.51 sec. BPR loss is 8.78E+00. Sample per second: 81438\n",
      "SLIM_BPR_Recommender: Epoch 524 of 650. Elapsed time 1.76 min\n",
      "Processed 41629 (100.0%) in 0.70 sec. BPR loss is 8.37E+00. Sample per second: 59042\n",
      "SLIM_BPR_Recommender: Epoch 525 of 650. Elapsed time 1.76 min\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 8.54E+00. Sample per second: 46323\n",
      "SLIM_BPR_Recommender: Epoch 526 of 650. Elapsed time 1.77 min\n",
      "Processed 41629 (100.0%) in 1.10 sec. BPR loss is 8.79E+00. Sample per second: 37960\n",
      "SLIM_BPR_Recommender: Epoch 527 of 650. Elapsed time 1.77 min\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 8.53E+00. Sample per second: 141052\n",
      "SLIM_BPR_Recommender: Epoch 528 of 650. Elapsed time 1.77 min\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 8.90E+00. Sample per second: 84219\n",
      "SLIM_BPR_Recommender: Epoch 529 of 650. Elapsed time 1.78 min\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 8.42E+00. Sample per second: 60083\n",
      "SLIM_BPR_Recommender: Epoch 530 of 650. Elapsed time 1.78 min\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 8.55E+00. Sample per second: 46915\n",
      "SLIM_BPR_Recommender: Epoch 531 of 650. Elapsed time 1.78 min\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 8.92E+00. Sample per second: 38437\n",
      "SLIM_BPR_Recommender: Epoch 532 of 650. Elapsed time 1.79 min\n",
      "Processed 41629 (100.0%) in 0.28 sec. BPR loss is 8.84E+00. Sample per second: 149080\n",
      "SLIM_BPR_Recommender: Epoch 533 of 650. Elapsed time 1.79 min\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 9.06E+00. Sample per second: 87825\n",
      "SLIM_BPR_Recommender: Epoch 534 of 650. Elapsed time 1.79 min\n",
      "Processed 41629 (100.0%) in 0.67 sec. BPR loss is 8.61E+00. Sample per second: 61787\n",
      "SLIM_BPR_Recommender: Epoch 535 of 650. Elapsed time 1.80 min\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 8.78E+00. Sample per second: 47982\n",
      "SLIM_BPR_Recommender: Epoch 536 of 650. Elapsed time 1.80 min\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 8.71E+00. Sample per second: 38988\n",
      "SLIM_BPR_Recommender: Epoch 537 of 650. Elapsed time 1.80 min\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 8.87E+00. Sample per second: 142899\n",
      "SLIM_BPR_Recommender: Epoch 538 of 650. Elapsed time 1.81 min\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 8.65E+00. Sample per second: 85634\n",
      "SLIM_BPR_Recommender: Epoch 539 of 650. Elapsed time 1.81 min\n",
      "Processed 41629 (100.0%) in 0.68 sec. BPR loss is 8.66E+00. Sample per second: 61255\n",
      "SLIM_BPR_Recommender: Epoch 540 of 650. Elapsed time 1.81 min\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 8.60E+00. Sample per second: 47583\n",
      "SLIM_BPR_Recommender: Epoch 541 of 650. Elapsed time 1.82 min\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 8.79E+00. Sample per second: 38838\n",
      "SLIM_BPR_Recommender: Epoch 542 of 650. Elapsed time 1.82 min\n",
      "Processed 41629 (100.0%) in 0.28 sec. BPR loss is 8.56E+00. Sample per second: 151176\n",
      "SLIM_BPR_Recommender: Epoch 543 of 650. Elapsed time 1.82 min\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 8.74E+00. Sample per second: 88696\n",
      "SLIM_BPR_Recommender: Epoch 544 of 650. Elapsed time 1.83 min\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 8.58E+00. Sample per second: 62694\n",
      "SLIM_BPR_Recommender: Epoch 545 of 650. Elapsed time 1.83 min\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 8.72E+00. Sample per second: 48448\n",
      "SLIM_BPR_Recommender: Epoch 546 of 650. Elapsed time 1.83 min\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 8.83E+00. Sample per second: 39503\n",
      "SLIM_BPR_Recommender: Epoch 547 of 650. Elapsed time 1.84 min\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 8.81E+00. Sample per second: 167333\n",
      "SLIM_BPR_Recommender: Epoch 548 of 650. Elapsed time 1.84 min\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 8.84E+00. Sample per second: 94095\n",
      "SLIM_BPR_Recommender: Epoch 549 of 650. Elapsed time 1.84 min\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 8.45E+00. Sample per second: 64972\n",
      "SLIM_BPR_Recommender: Epoch 550 of 650. Elapsed time 1.85 min\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 8.87E+00. Sample per second: 49774\n",
      "SLIM_BPR_Recommender: Epoch 551 of 650. Elapsed time 1.85 min\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 8.79E+00. Sample per second: 40337\n",
      "SLIM_BPR_Recommender: Epoch 552 of 650. Elapsed time 1.85 min\n",
      "Processed 41629 (100.0%) in 0.23 sec. BPR loss is 8.75E+00. Sample per second: 180650\n",
      "SLIM_BPR_Recommender: Epoch 553 of 650. Elapsed time 1.86 min\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 8.36E+00. Sample per second: 97603\n",
      "SLIM_BPR_Recommender: Epoch 554 of 650. Elapsed time 1.86 min\n",
      "Processed 41629 (100.0%) in 0.62 sec. BPR loss is 8.76E+00. Sample per second: 66670\n",
      "SLIM_BPR_Recommender: Epoch 555 of 650. Elapsed time 1.86 min\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 8.56E+00. Sample per second: 50730\n",
      "SLIM_BPR_Recommender: Epoch 556 of 650. Elapsed time 1.87 min\n",
      "Processed 41629 (100.0%) in 1.02 sec. BPR loss is 8.75E+00. Sample per second: 40889\n",
      "SLIM_BPR_Recommender: Epoch 557 of 650. Elapsed time 1.87 min\n",
      "Processed 41629 (100.0%) in 0.22 sec. BPR loss is 9.24E+00. Sample per second: 192507\n",
      "SLIM_BPR_Recommender: Epoch 558 of 650. Elapsed time 1.87 min\n",
      "Processed 41629 (100.0%) in 0.41 sec. BPR loss is 9.05E+00. Sample per second: 100661\n",
      "SLIM_BPR_Recommender: Epoch 559 of 650. Elapsed time 1.88 min\n",
      "Processed 41629 (100.0%) in 0.61 sec. BPR loss is 8.68E+00. Sample per second: 67890\n",
      "SLIM_BPR_Recommender: Epoch 560 of 650. Elapsed time 1.88 min\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 8.96E+00. Sample per second: 51177\n",
      "SLIM_BPR_Recommender: Epoch 561 of 650. Elapsed time 1.88 min\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 8.71E+00. Sample per second: 41167\n",
      "SLIM_BPR_Recommender: Epoch 562 of 650. Elapsed time 1.89 min\n",
      "Processed 41629 (100.0%) in 0.21 sec. BPR loss is 8.92E+00. Sample per second: 197354\n",
      "SLIM_BPR_Recommender: Epoch 563 of 650. Elapsed time 1.89 min\n",
      "Processed 41629 (100.0%) in 0.41 sec. BPR loss is 8.98E+00. Sample per second: 101259\n",
      "SLIM_BPR_Recommender: Epoch 564 of 650. Elapsed time 1.89 min\n",
      "Processed 41629 (100.0%) in 0.61 sec. BPR loss is 8.88E+00. Sample per second: 68323\n",
      "SLIM_BPR_Recommender: Epoch 565 of 650. Elapsed time 1.90 min\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 8.98E+00. Sample per second: 51359\n",
      "SLIM_BPR_Recommender: Epoch 566 of 650. Elapsed time 1.90 min\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 9.00E+00. Sample per second: 41250\n",
      "SLIM_BPR_Recommender: Epoch 567 of 650. Elapsed time 1.90 min\n",
      "Processed 41629 (100.0%) in 0.21 sec. BPR loss is 8.66E+00. Sample per second: 200370\n",
      "SLIM_BPR_Recommender: Epoch 568 of 650. Elapsed time 1.91 min\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 9.22E+00. Sample per second: 102974\n",
      "SLIM_BPR_Recommender: Epoch 569 of 650. Elapsed time 1.91 min\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 8.86E+00. Sample per second: 69303\n",
      "SLIM_BPR_Recommender: Epoch 570 of 650. Elapsed time 1.91 min\n",
      "Processed 41629 (100.0%) in 0.80 sec. BPR loss is 8.69E+00. Sample per second: 52275\n",
      "SLIM_BPR_Recommender: Epoch 571 of 650. Elapsed time 1.92 min\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 8.93E+00. Sample per second: 42045\n",
      "SLIM_BPR_Recommender: Epoch 572 of 650. Elapsed time 1.92 min\n",
      "Processed 41629 (100.0%) in 1.18 sec. BPR loss is 9.16E+00. Sample per second: 35124\n",
      "SLIM_BPR_Recommender: Epoch 573 of 650. Elapsed time 1.92 min\n",
      "Processed 41629 (100.0%) in 0.38 sec. BPR loss is 8.98E+00. Sample per second: 109567\n",
      "SLIM_BPR_Recommender: Epoch 574 of 650. Elapsed time 1.92 min\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 8.89E+00. Sample per second: 72226\n",
      "SLIM_BPR_Recommender: Epoch 575 of 650. Elapsed time 1.93 min\n",
      "Processed 41629 (100.0%) in 0.77 sec. BPR loss is 9.33E+00. Sample per second: 53766\n",
      "SLIM_BPR_Recommender: Epoch 576 of 650. Elapsed time 1.93 min\n",
      "Processed 41629 (100.0%) in 0.97 sec. BPR loss is 9.03E+00. Sample per second: 42864\n",
      "SLIM_BPR_Recommender: Epoch 577 of 650. Elapsed time 1.93 min\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 9.24E+00. Sample per second: 35659\n",
      "SLIM_BPR_Recommender: Epoch 578 of 650. Elapsed time 1.94 min\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 9.08E+00. Sample per second: 115480\n",
      "SLIM_BPR_Recommender: Epoch 579 of 650. Elapsed time 1.94 min\n",
      "Processed 41629 (100.0%) in 0.56 sec. BPR loss is 9.17E+00. Sample per second: 74824\n",
      "SLIM_BPR_Recommender: Epoch 580 of 650. Elapsed time 1.94 min\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 9.26E+00. Sample per second: 55429\n",
      "SLIM_BPR_Recommender: Epoch 581 of 650. Elapsed time 1.95 min\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 9.00E+00. Sample per second: 43827\n",
      "SLIM_BPR_Recommender: Epoch 582 of 650. Elapsed time 1.95 min\n",
      "Processed 41629 (100.0%) in 1.15 sec. BPR loss is 8.98E+00. Sample per second: 36342\n",
      "SLIM_BPR_Recommender: Epoch 583 of 650. Elapsed time 1.95 min\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 9.34E+00. Sample per second: 122497\n",
      "SLIM_BPR_Recommender: Epoch 584 of 650. Elapsed time 1.96 min\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 9.04E+00. Sample per second: 77966\n",
      "SLIM_BPR_Recommender: Epoch 585 of 650. Elapsed time 1.96 min\n",
      "Processed 41629 (100.0%) in 0.73 sec. BPR loss is 9.34E+00. Sample per second: 57002\n",
      "SLIM_BPR_Recommender: Epoch 586 of 650. Elapsed time 1.96 min\n",
      "Processed 41629 (100.0%) in 0.92 sec. BPR loss is 9.14E+00. Sample per second: 45053\n",
      "SLIM_BPR_Recommender: Epoch 587 of 650. Elapsed time 1.97 min\n",
      "Processed 41629 (100.0%) in 1.12 sec. BPR loss is 9.08E+00. Sample per second: 37161\n",
      "SLIM_BPR_Recommender: Epoch 588 of 650. Elapsed time 1.97 min\n",
      "Processed 41629 (100.0%) in 0.31 sec. BPR loss is 9.29E+00. Sample per second: 133448\n",
      "SLIM_BPR_Recommender: Epoch 589 of 650. Elapsed time 1.97 min\n",
      "Processed 41629 (100.0%) in 0.51 sec. BPR loss is 8.94E+00. Sample per second: 81610\n",
      "SLIM_BPR_Recommender: Epoch 590 of 650. Elapsed time 1.98 min\n",
      "Processed 41629 (100.0%) in 0.70 sec. BPR loss is 8.93E+00. Sample per second: 59133\n",
      "SLIM_BPR_Recommender: Epoch 591 of 650. Elapsed time 1.98 min\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 9.13E+00. Sample per second: 46292\n",
      "SLIM_BPR_Recommender: Epoch 592 of 650. Elapsed time 1.98 min\n",
      "Processed 41629 (100.0%) in 1.11 sec. BPR loss is 9.16E+00. Sample per second: 37428\n",
      "SLIM_BPR_Recommender: Epoch 593 of 650. Elapsed time 1.99 min\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 9.12E+00. Sample per second: 127878\n",
      "SLIM_BPR_Recommender: Epoch 594 of 650. Elapsed time 1.99 min\n",
      "Processed 41629 (100.0%) in 0.52 sec. BPR loss is 9.18E+00. Sample per second: 79645\n",
      "SLIM_BPR_Recommender: Epoch 595 of 650. Elapsed time 1.99 min\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 9.02E+00. Sample per second: 58022\n",
      "SLIM_BPR_Recommender: Epoch 596 of 650. Elapsed time 2.00 min\n",
      "Processed 41629 (100.0%) in 0.91 sec. BPR loss is 8.95E+00. Sample per second: 45704\n",
      "SLIM_BPR_Recommender: Epoch 597 of 650. Elapsed time 2.00 min\n",
      "Processed 41629 (100.0%) in 1.11 sec. BPR loss is 9.06E+00. Sample per second: 37589\n",
      "SLIM_BPR_Recommender: Epoch 598 of 650. Elapsed time 2.00 min\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 9.20E+00. Sample per second: 137492\n",
      "SLIM_BPR_Recommender: Epoch 599 of 650. Elapsed time 2.01 min\n",
      "Processed 41629 (100.0%) in 0.50 sec. BPR loss is 9.07E+00. Sample per second: 83411\n",
      "SLIM_BPR_Recommender: Epoch 600 of 650. Elapsed time 2.01 min\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 9.22E+00. Sample per second: 59903\n",
      "SLIM_BPR_Recommender: Epoch 601 of 650. Elapsed time 2.01 min\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 9.11E+00. Sample per second: 46678\n",
      "SLIM_BPR_Recommender: Epoch 602 of 650. Elapsed time 2.02 min\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 9.14E+00. Sample per second: 38204\n",
      "SLIM_BPR_Recommender: Epoch 603 of 650. Elapsed time 2.02 min\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 9.02E+00. Sample per second: 145302\n",
      "SLIM_BPR_Recommender: Epoch 604 of 650. Elapsed time 2.02 min\n",
      "Processed 41629 (100.0%) in 0.48 sec. BPR loss is 9.37E+00. Sample per second: 86295\n",
      "SLIM_BPR_Recommender: Epoch 605 of 650. Elapsed time 2.03 min\n",
      "Processed 41629 (100.0%) in 0.68 sec. BPR loss is 9.15E+00. Sample per second: 61105\n",
      "SLIM_BPR_Recommender: Epoch 606 of 650. Elapsed time 2.03 min\n",
      "Processed 41629 (100.0%) in 0.88 sec. BPR loss is 9.61E+00. Sample per second: 47559\n",
      "SLIM_BPR_Recommender: Epoch 607 of 650. Elapsed time 2.03 min\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 9.25E+00. Sample per second: 38760\n",
      "SLIM_BPR_Recommender: Epoch 608 of 650. Elapsed time 2.04 min\n",
      "Processed 41629 (100.0%) in 0.27 sec. BPR loss is 9.36E+00. Sample per second: 153044\n",
      "SLIM_BPR_Recommender: Epoch 609 of 650. Elapsed time 2.04 min\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 9.32E+00. Sample per second: 88650\n",
      "SLIM_BPR_Recommender: Epoch 610 of 650. Elapsed time 2.04 min\n",
      "Processed 41629 (100.0%) in 0.67 sec. BPR loss is 9.18E+00. Sample per second: 61864\n",
      "SLIM_BPR_Recommender: Epoch 611 of 650. Elapsed time 2.05 min\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 9.23E+00. Sample per second: 47646\n",
      "SLIM_BPR_Recommender: Epoch 612 of 650. Elapsed time 2.05 min\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 9.51E+00. Sample per second: 38716\n",
      "SLIM_BPR_Recommender: Epoch 613 of 650. Elapsed time 2.05 min\n",
      "Processed 41629 (100.0%) in 0.28 sec. BPR loss is 9.42E+00. Sample per second: 149867\n",
      "SLIM_BPR_Recommender: Epoch 614 of 650. Elapsed time 2.06 min\n",
      "Processed 41629 (100.0%) in 0.48 sec. BPR loss is 9.28E+00. Sample per second: 86872\n",
      "SLIM_BPR_Recommender: Epoch 615 of 650. Elapsed time 2.06 min\n",
      "Processed 41629 (100.0%) in 0.67 sec. BPR loss is 9.28E+00. Sample per second: 61732\n",
      "SLIM_BPR_Recommender: Epoch 616 of 650. Elapsed time 2.06 min\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 9.42E+00. Sample per second: 47803\n",
      "SLIM_BPR_Recommender: Epoch 617 of 650. Elapsed time 2.07 min\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 9.62E+00. Sample per second: 38908\n",
      "SLIM_BPR_Recommender: Epoch 618 of 650. Elapsed time 2.07 min\n",
      "Processed 41629 (100.0%) in 0.27 sec. BPR loss is 9.28E+00. Sample per second: 155781\n",
      "SLIM_BPR_Recommender: Epoch 619 of 650. Elapsed time 2.07 min\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 9.38E+00. Sample per second: 89564\n",
      "SLIM_BPR_Recommender: Epoch 620 of 650. Elapsed time 2.08 min\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 9.07E+00. Sample per second: 63200\n",
      "SLIM_BPR_Recommender: Epoch 621 of 650. Elapsed time 2.08 min\n",
      "Processed 41629 (100.0%) in 0.85 sec. BPR loss is 9.29E+00. Sample per second: 48758\n",
      "SLIM_BPR_Recommender: Epoch 622 of 650. Elapsed time 2.08 min\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 9.24E+00. Sample per second: 39579\n",
      "SLIM_BPR_Recommender: Epoch 623 of 650. Elapsed time 2.09 min\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 9.29E+00. Sample per second: 168067\n",
      "SLIM_BPR_Recommender: Epoch 624 of 650. Elapsed time 2.09 min\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 9.70E+00. Sample per second: 93701\n",
      "SLIM_BPR_Recommender: Epoch 625 of 650. Elapsed time 2.09 min\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 9.62E+00. Sample per second: 65144\n",
      "SLIM_BPR_Recommender: Epoch 626 of 650. Elapsed time 2.10 min\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 9.61E+00. Sample per second: 49752\n",
      "SLIM_BPR_Recommender: Epoch 627 of 650. Elapsed time 2.10 min\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 9.63E+00. Sample per second: 40345\n",
      "SLIM_BPR_Recommender: Epoch 628 of 650. Elapsed time 2.10 min\n",
      "Processed 41629 (100.0%) in 0.23 sec. BPR loss is 9.54E+00. Sample per second: 181932\n",
      "SLIM_BPR_Recommender: Epoch 629 of 650. Elapsed time 2.11 min\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 9.53E+00. Sample per second: 97587\n",
      "SLIM_BPR_Recommender: Epoch 630 of 650. Elapsed time 2.11 min\n",
      "Processed 41629 (100.0%) in 0.62 sec. BPR loss is 9.44E+00. Sample per second: 67052\n",
      "SLIM_BPR_Recommender: Epoch 631 of 650. Elapsed time 2.11 min\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 9.58E+00. Sample per second: 51009\n",
      "SLIM_BPR_Recommender: Epoch 632 of 650. Elapsed time 2.12 min\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 9.20E+00. Sample per second: 41031\n",
      "SLIM_BPR_Recommender: Epoch 633 of 650. Elapsed time 2.12 min\n",
      "Processed 41629 (100.0%) in 0.21 sec. BPR loss is 9.29E+00. Sample per second: 198119\n",
      "SLIM_BPR_Recommender: Epoch 634 of 650. Elapsed time 2.12 min\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 9.76E+00. Sample per second: 102996\n",
      "SLIM_BPR_Recommender: Epoch 635 of 650. Elapsed time 2.13 min\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 9.39E+00. Sample per second: 69806\n",
      "SLIM_BPR_Recommender: Epoch 636 of 650. Elapsed time 2.13 min\n",
      "Processed 41629 (100.0%) in 0.79 sec. BPR loss is 9.72E+00. Sample per second: 52617\n",
      "SLIM_BPR_Recommender: Epoch 637 of 650. Elapsed time 2.13 min\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 9.43E+00. Sample per second: 42109\n",
      "SLIM_BPR_Recommender: Epoch 638 of 650. Elapsed time 2.14 min\n",
      "Processed 41629 (100.0%) in 1.19 sec. BPR loss is 9.59E+00. Sample per second: 35078\n",
      "SLIM_BPR_Recommender: Epoch 639 of 650. Elapsed time 2.14 min\n",
      "Processed 41629 (100.0%) in 0.38 sec. BPR loss is 9.57E+00. Sample per second: 108465\n",
      "SLIM_BPR_Recommender: Epoch 640 of 650. Elapsed time 2.14 min\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 9.23E+00. Sample per second: 71626\n",
      "SLIM_BPR_Recommender: Epoch 641 of 650. Elapsed time 2.14 min\n",
      "Processed 41629 (100.0%) in 0.78 sec. BPR loss is 9.71E+00. Sample per second: 53516\n",
      "SLIM_BPR_Recommender: Epoch 642 of 650. Elapsed time 2.15 min\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 9.68E+00. Sample per second: 42617\n",
      "SLIM_BPR_Recommender: Epoch 643 of 650. Elapsed time 2.15 min\n",
      "Processed 41629 (100.0%) in 1.18 sec. BPR loss is 9.61E+00. Sample per second: 35261\n",
      "SLIM_BPR_Recommender: Epoch 644 of 650. Elapsed time 2.15 min\n",
      "Processed 41629 (100.0%) in 0.38 sec. BPR loss is 9.62E+00. Sample per second: 109076\n",
      "SLIM_BPR_Recommender: Epoch 645 of 650. Elapsed time 2.16 min\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 9.38E+00. Sample per second: 71934\n",
      "SLIM_BPR_Recommender: Epoch 646 of 650. Elapsed time 2.16 min\n",
      "Processed 41629 (100.0%) in 0.78 sec. BPR loss is 9.27E+00. Sample per second: 53525\n",
      "SLIM_BPR_Recommender: Epoch 647 of 650. Elapsed time 2.16 min\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 9.72E+00. Sample per second: 42594\n",
      "SLIM_BPR_Recommender: Epoch 648 of 650. Elapsed time 2.17 min\n",
      "Processed 41629 (100.0%) in 1.21 sec. BPR loss is 9.70E+00. Sample per second: 34512\n",
      "SLIM_BPR_Recommender: Epoch 649 of 650. Elapsed time 2.17 min\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 9.48E+00. Sample per second: 103211\n",
      "SLIM_BPR_Recommender: Epoch 650 of 650. Elapsed time 2.18 min\n",
      "SLIM_BPR_Recommender: Terminating at epoch 650. Elapsed time 2.74 min\n",
      "Deallocating Cython objects\n"
     ]
    }
   ],
   "source": [
    "from Recommenders.MatrixFactorization.Cython.MatrixFactorization_Cython_Epoch import MatrixFactorization_Cython_Epoch\n",
    "from Recommenders.SLIM.Cython.SLIM_BPR_Cython import SLIM_BPR_Cython\n",
    "\n",
    "slim_bpr = SLIM_BPR_Cython(URM_train)\n",
    "slim_bpr.fit(epochs=650, sgd_mode = \"sgd\", topK = 483, lambda_i = 0.0006712905081189398, lambda_j = 0.06584150350451998, learning_rate = 0.0036482363905043207)\n",
    "recommender_object_dict[\"SLIM_BPR\"] = slim_bpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c72b6cd4",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T23:18:09.713169Z",
     "iopub.status.busy": "2022-12-26T23:18:09.712471Z",
     "iopub.status.idle": "2022-12-26T23:18:09.771868Z",
     "shell.execute_reply": "2022-12-26T23:18:09.770727Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.158844,
     "end_time": "2022-12-26T23:18:09.774563",
     "exception": false,
     "start_time": "2022-12-26T23:18:09.615719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Recommenders.NonPersonalizedRecommender import TopPop\n",
    "\n",
    "top_pop = TopPop(URM_train)\n",
    "top_pop.fit()\n",
    "recommender_object_dict[\"TOP_POP\"] = top_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d40537e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T23:18:09.964571Z",
     "iopub.status.busy": "2022-12-26T23:18:09.964177Z",
     "iopub.status.idle": "2022-12-26T23:29:21.198352Z",
     "shell.execute_reply": "2022-12-26T23:29:21.196826Z"
    },
    "papermill": {
     "duration": 671.333018,
     "end_time": "2022-12-26T23:29:21.201838",
     "exception": false,
     "start_time": "2022-12-26T23:18:09.868820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EASE_R_Recommender: Fitting model... \n",
      "EASE_R_Recommender: Fitting model... done in 10.50 min\n"
     ]
    }
   ],
   "source": [
    "from Recommenders.EASE_R.EASE_R_Recommender import EASE_R_Recommender\n",
    "\n",
    "EASE_R = EASE_R_Recommender(URM_train)\n",
    "#%%\n",
    "EASE_R.fit(topK = 416, l2_norm = 115.67139771839786, normalize_matrix = False)\n",
    "recommender_object_dict[\"Ease_R\"] = EASE_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4ed7a81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T23:29:21.399950Z",
     "iopub.status.busy": "2022-12-26T23:29:21.399521Z",
     "iopub.status.idle": "2022-12-26T23:29:34.468841Z",
     "shell.execute_reply": "2022-12-26T23:29:34.467707Z"
    },
    "papermill": {
     "duration": 13.174228,
     "end_time": "2022-12-26T23:29:34.472032",
     "exception": false,
     "start_time": "2022-12-26T23:29:21.297804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RP3betaRecommender: Similarity column 24507 (100.0%), 2305.96 column/sec. Elapsed time 10.63 sec\n"
     ]
    }
   ],
   "source": [
    "from Recommenders.GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "from Recommenders.GraphBased.P3alphaRecommender import P3alphaRecommender\n",
    "\n",
    "RP3beta_all = RP3betaRecommender(URM_train)\n",
    "RP3beta_all.fit(alpha= 1.0, beta= 0.28666076265452467, topK= 57, implicit= True)\n",
    "recommender_object_dict[\"RP3\"] = RP3beta_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0987dee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T23:29:34.663564Z",
     "iopub.status.busy": "2022-12-26T23:29:34.663158Z",
     "iopub.status.idle": "2022-12-26T23:29:34.675694Z",
     "shell.execute_reply": "2022-12-26T23:29:34.674491Z"
    },
    "papermill": {
     "duration": 0.111323,
     "end_time": "2022-12-26T23:29:34.678181",
     "exception": false,
     "start_time": "2022-12-26T23:29:34.566858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "\n",
    "class DifferentLossScoresHybridRecommender(BaseRecommender):\n",
    "    \"\"\" ScoresHybridRecommender\n",
    "    Hybrid of four predictions scores\n",
    "    R = R1*alpha + R2*beta + R3*theta + R3*(1-alpha-beta-theta)\n",
    "    \n",
    "    Class from Dacrema exercise modified by Antonio Ercolani\n",
    "    The original took as input 2 recommender\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"DifferentLossScoresHybridRecommender\"\n",
    "\n",
    "\n",
    "    def __init__(self, URM_train, recommender_1, recommender_2, recommender_3):\n",
    "        super(DifferentLossScoresHybridRecommender, self).__init__(URM_train)\n",
    "\n",
    "        self.URM_train = sps.csr_matrix(URM_train)\n",
    "        self.recommender_1 = recommender_1\n",
    "        self.recommender_2 = recommender_2\n",
    "        self.recommender_3 = recommender_3\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self, norm, alpha = 0.5, beta = 0):\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.norm = norm\n",
    "\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute):\n",
    "        \n",
    "        item_weights_1 = self.recommender_1._compute_item_score(user_id_array)\n",
    "        item_weights_2 = self.recommender_2._compute_item_score(user_id_array)\n",
    "        item_weights_3 = self.recommender_3._compute_item_score(user_id_array)\n",
    "\n",
    "        norm_item_weights_1 = LA.norm(item_weights_1, self.norm)\n",
    "        norm_item_weights_2 = LA.norm(item_weights_2, self.norm)\n",
    "        norm_item_weights_3 = LA.norm(item_weights_3, self.norm)\n",
    "        \n",
    "        \n",
    "        if norm_item_weights_1 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 1 is zero. Avoiding division by zero\".format(self.norm))\n",
    "        \n",
    "        if norm_item_weights_2 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 2 is zero. Avoiding division by zero\".format(self.norm))\n",
    "            \n",
    "        if norm_item_weights_3 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 3 is zero. Avoiding division by zero\".format(self.norm))\n",
    "          \n",
    "        item_weights = item_weights_1 / norm_item_weights_1 * self.alpha + item_weights_2 / norm_item_weights_2 * self.beta + item_weights_3 / norm_item_weights_3 * (1-(self.alpha+ self.beta))\n",
    "\n",
    "        return item_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8698a777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T23:29:34.869389Z",
     "iopub.status.busy": "2022-12-26T23:29:34.868239Z",
     "iopub.status.idle": "2022-12-26T23:29:34.913478Z",
     "shell.execute_reply": "2022-12-26T23:29:34.912625Z"
    },
    "papermill": {
     "duration": 0.144279,
     "end_time": "2022-12-26T23:29:34.916097",
     "exception": false,
     "start_time": "2022-12-26T23:29:34.771818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hybridDiffLoss = DifferentLossScoresHybridRecommender(URM_all, slim_en, RP3beta_all, EASE_R)\n",
    "hybridDiffLoss.fit(1, 0.6, 0.35)\n",
    "recommender_object_dict[\"HybridDiffLoss\"] = hybridDiffLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fffaa80f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T23:29:35.110218Z",
     "iopub.status.busy": "2022-12-26T23:29:35.109559Z",
     "iopub.status.idle": "2022-12-26T23:29:35.269871Z",
     "shell.execute_reply": "2022-12-26T23:29:35.268457Z"
    },
    "papermill": {
     "duration": 0.259402,
     "end_time": "2022-12-26T23:29:35.272199",
     "exception": true,
     "start_time": "2022-12-26T23:29:35.012797",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ItemKNNCustomSimilarityRecommender' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/970980930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnew_similarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslim_matrix\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrp3_matrix\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mSlim_rp3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mItemKNNCustomSimilarityRecommender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURM_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mSlim_rp3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_similarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ItemKNNCustomSimilarityRecommender' is not defined"
     ]
    }
   ],
   "source": [
    "slim_matrix = slim_en.W_sparse\n",
    "rp3_matrix = RP3beta_all.W_sparse\n",
    "\n",
    "alpha = 0.6\n",
    "new_similarity = slim_matrix * alpha + rp3_matrix * (1-alpha)\n",
    "Slim_rp3 = ItemKNNCustomSimilarityRecommender(URM_train)\n",
    "Slim_rp3.fit(new_similarity)\n",
    "\n",
    "recommender_object_dict[\"Slim_rp3\"] = Slim_rp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94653a66",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T19:59:58.942509Z",
     "iopub.status.busy": "2022-12-26T19:59:58.942065Z",
     "iopub.status.idle": "2022-12-26T20:06:36.894742Z",
     "shell.execute_reply": "2022-12-26T20:06:36.893353Z",
     "shell.execute_reply.started": "2022-12-26T19:59:58.942464Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot results of models for different users groups\n",
    "#%%\n",
    "# here we perform validation over different user groups for each model\n",
    "# then we plot a graph to compare them\n",
    "cutoff = 10\n",
    "\n",
    "for group_id in range(0, 20):\n",
    "    \n",
    "    start_pos = group_id*block_size\n",
    "    end_pos = min((group_id+1)*block_size, len(profile_length))\n",
    "    \n",
    "    users_in_group = sorted_users[start_pos:end_pos]\n",
    "    \n",
    "    users_in_group_p_len = profile_length[users_in_group]\n",
    "    \n",
    "    print(\"Group {}, #users in group {}, average p.len {:.2f}, median {}, min {}, max {}\".format(\n",
    "        group_id, \n",
    "        users_in_group.shape[0],\n",
    "        users_in_group_p_len.mean(),\n",
    "        np.median(users_in_group_p_len),\n",
    "        users_in_group_p_len.min(),\n",
    "        users_in_group_p_len.max()))\n",
    "    \n",
    "    \n",
    "    users_not_in_group_flag = np.isin(sorted_users, users_in_group, invert=True)\n",
    "    users_not_in_group = sorted_users[users_not_in_group_flag]\n",
    "    \n",
    "    evaluator_validation = EvaluatorHoldout(URM_valid, cutoff_list=[cutoff], ignore_users=users_not_in_group)\n",
    "    \n",
    "    for label, recommender in recommender_object_dict.items():\n",
    "        result_df, _ = evaluator_validation.evaluateRecommender(recommender)\n",
    "        if label in MAP_recommender_per_group:\n",
    "            MAP_recommender_per_group[label].append(result_df.loc[cutoff][\"MAP\"])\n",
    "        else:\n",
    "            MAP_recommender_per_group[label] = [result_df.loc[cutoff][\"MAP\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc12cad",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-26T20:06:36.897229Z",
     "iopub.status.busy": "2022-12-26T20:06:36.896835Z",
     "iopub.status.idle": "2022-12-26T20:06:37.335329Z",
     "shell.execute_reply": "2022-12-26T20:06:37.333996Z",
     "shell.execute_reply.started": "2022-12-26T20:06:36.897194Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "_ = plt.figure(figsize=(16, 9))\n",
    "for label, recommender in recommender_object_dict.items():\n",
    "    results = MAP_recommender_per_group[label]\n",
    "    plt.scatter(x=np.arange(0,len(results)), y=results, label=label)\n",
    "plt.ylabel('MAP')\n",
    "plt.xlabel('User Group')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b637366",
   "metadata": {
    "_cell_guid": "e98ba16c-c11e-42e3-af3d-f3ecd2ac648e",
    "_uuid": "aabe8041-dd4a-46f4-92a8-9daa4432e6cc",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2022-12-26T19:52:53.439211Z",
     "iopub.status.idle": "2022-12-26T19:52:53.439880Z",
     "shell.execute_reply": "2022-12-26T19:52:53.439696Z",
     "shell.execute_reply.started": "2022-12-26T19:52:53.439676Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%% md\n",
    "# Create final recommandations\n",
    "#%%\n",
    "#test_users = pd.read_csv('../input/recommender-system-2021-challenge-polimi/data_target_users_test.csv')\n",
    "#test_users\n",
    "#%%\n",
    "#user_id = test_users['user_id']\n",
    "#recommendations = []\n",
    "#for user in user_id:\n",
    "    #recommendations.append(recommender.recommend(user,cutoff = 10))\n",
    "#%%\n",
    "#for index in range(len(recommendations)):\n",
    "    #recommendations[index]=np.array(recommendations[index])\n",
    "    \n",
    "#test_users['item_list']= recommendations\n",
    "#test_users['item_list'] = pd.DataFrame([str(line).strip('[').strip(']').replace(\"'\",\"\") for line in test_users['item_list']])\n",
    "#test_users.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3727.150969,
   "end_time": "2022-12-26T23:29:38.098488",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-26T22:27:30.947519",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "093b3e4e88014c37bb781d427005d7e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_eb2042253e3b4a9ab8cc60239cec2586",
       "placeholder": "​",
       "style": "IPY_MODEL_656ac0a2c2314d31894ffef3f469330c",
       "value": "100%"
      }
     },
     "117aa5736a82456ea484f35d3dcf8595": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5caea53319b942c7a3648c0652671d20",
       "max": 70.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_53ba4d05c48d4af79ffa6aa5a6c54fb7",
       "value": 70.0
      }
     },
     "15678965689743ae8ee55ae9393a5804": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2310a85c22734916a64c359516afc851": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "43eb1c0b1e1947d1a99157870980400c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d49f8925b53640cb8b8218c80267c6e5",
       "placeholder": "​",
       "style": "IPY_MODEL_2310a85c22734916a64c359516afc851",
       "value": " 70/70 [08:20&lt;00:00,  7.20s/it]"
      }
     },
     "53ba4d05c48d4af79ffa6aa5a6c54fb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5caea53319b942c7a3648c0652671d20": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "656ac0a2c2314d31894ffef3f469330c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bf763e49f61e47a1992b91a34e06d7e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_093b3e4e88014c37bb781d427005d7e4",
        "IPY_MODEL_117aa5736a82456ea484f35d3dcf8595",
        "IPY_MODEL_43eb1c0b1e1947d1a99157870980400c"
       ],
       "layout": "IPY_MODEL_15678965689743ae8ee55ae9393a5804"
      }
     },
     "d49f8925b53640cb8b8218c80267c6e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eb2042253e3b4a9ab8cc60239cec2586": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
