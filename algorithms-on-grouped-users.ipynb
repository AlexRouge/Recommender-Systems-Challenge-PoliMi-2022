{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c68de45",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-26T23:01:35.447644Z",
     "iopub.status.busy": "2022-11-26T23:01:35.446992Z",
     "iopub.status.idle": "2022-11-26T23:01:41.231638Z",
     "shell.execute_reply": "2022-11-26T23:01:41.230080Z"
    },
    "papermill": {
     "duration": 5.796082,
     "end_time": "2022-11-26T23:01:41.234936",
     "exception": false,
     "start_time": "2022-11-26T23:01:35.438854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r ../input/recsys-repo/RecSys_Course_AT_PoliMi-master/* ./\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile, os\n",
    "import scipy.sparse as sps\n",
    "import matplotlib.pyplot as pyplot\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "## In order to evaluate put it in a recommender class\n",
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "from Recommenders.Recommender_utils import check_matrix\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from Recommenders.BaseSimilarityMatrixRecommender import BaseItemSimilarityMatrixRecommender\n",
    "from Utils.seconds_to_biggest_unit import seconds_to_biggest_unit\n",
    "import time, sys\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from lightfm import LightFM\n",
    "URM_path = \"../input/urm-true-binary/URM_True_Binary.csv\"\n",
    "URM_all_dataframe = pd.read_csv(filepath_or_buffer=URM_path, \n",
    "                                sep=\",\",\n",
    "                                dtype={0:int, 1:int, 2:float},\n",
    "                                header=0)\n",
    "URM_all_dataframe.columns = [\"UserID\", \"ItemID\", \"Data\"]\n",
    "URM_all = sps.coo_matrix((URM_all_dataframe[\"Data\"].values, \n",
    "                          (URM_all_dataframe[\"UserID\"].values, URM_all_dataframe[\"ItemID\"].values)))\n",
    "URM_all = URM_all.tocsr() # to obtain fast access to rows (users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e0e7592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T23:01:41.247959Z",
     "iopub.status.busy": "2022-11-26T23:01:41.247184Z",
     "iopub.status.idle": "2022-11-26T23:04:35.663158Z",
     "shell.execute_reply": "2022-11-26T23:04:35.661523Z"
    },
    "papermill": {
     "duration": 174.425818,
     "end_time": "2022-11-26T23:04:35.666242",
     "exception": false,
     "start_time": "2022-11-26T23:01:41.240424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_compile_all_cython: Found 10 Cython files in 4 folders...\r\n",
      "run_compile_all_cython: All files will be compiled using your current python environment: '/opt/conda/bin/python'\r\n",
      "Compiling [1/10]: MatrixFactorization_Cython_Epoch.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KMatrixFactorization_Cython_Epoch.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorization_Cython_Epoch.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_32MatrixFactorization_Cython_Epoch_32MatrixFactorization_Cython_Epoch_10epochIteration_Cython_ASY_SVD_SGD\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KMatrixFactorization_Cython_Epoch.c:8669:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_end_pos_seen_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 8669 |         \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K (__pyx_t_19 = __pyx_v_start_pos_seen_items; __pyx_t_19 < __pyx_t_18; __pyx_t_19+=1) {\r\n",
      "      |         \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorization_Cython_Epoch.c:8669:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_start_pos_seen_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/MatrixFactorization/Cython/MatrixFactorization_Cython_Epoch.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [1/10]: MatrixFactorization_Cython_Epoch.pyx... PASS\r\n",
      "\r\n",
      "Compiling [2/10]: MatrixFactorizationImpressions_Cython_Epoch.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_f_43MatrixFactorizationImpressions_Cython_Epoch_32MatrixFactorization_Cython_Epoch_sampleBPR_Cython\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:12758:17:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_start_pos_impression_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      "12758 |       \u001b[01;35m\u001b[K__pyx_t_4 = (__pyx_v_start_pos_impression_items + __pyx_v_index)\u001b[m\u001b[K;\r\n",
      "      |       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_43MatrixFactorizationImpressions_Cython_Epoch_32MatrixFactorization_Cython_Epoch_10epochIteration_Cython_ASY_SVD_SGD\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:8736:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_end_pos_seen_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 8736 |       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K (__pyx_t_19 = __pyx_v_start_pos_seen_items; __pyx_t_19 < __pyx_t_18; __pyx_t_19+=1) {\r\n",
      "      |       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:8736:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_start_pos_seen_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/MatrixFactorization/Cython/MatrixFactorizationImpressions_Cython_Epoch.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [2/10]: MatrixFactorizationImpressions_Cython_Epoch.pyx... PASS\r\n",
      "\r\n",
      "Compiling [3/10]: Compute_Similarity_Cython.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KCompute_Similarity_Cython.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/Similarity/Cython/Compute_Similarity_Cython.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [3/10]: Compute_Similarity_Cython.pyx... PASS\r\n",
      "\r\n",
      "Compiling [4/10]: SLIM_BPR_Cython_Epoch.pyx... \r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KSLIM_BPR_Cython_Epoch.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KSLIM_BPR_Cython_Epoch.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_f_21SLIM_BPR_Cython_Epoch_22Sparse_Matrix_Tree_CSR_test_list_tee_conversion\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KSLIM_BPR_Cython_Epoch.c:10848:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_previous_element\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      "10848 |     \u001b[01;35m\u001b[K__pyx_t_7 = __pyx_v_current_element->lower\u001b[m\u001b[K;\r\n",
      "      |     \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/SLIM/Cython/SLIM_BPR_Cython_Epoch.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "Compiling [4/10]: SLIM_BPR_Cython_Epoch.pyx... PASS\r\n",
      "\r\n",
      "Compiling [5/10]: Sparse_Matrix_Tree_CSR.pyx... \r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KSparse_Matrix_Tree_CSR.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KSparse_Matrix_Tree_CSR.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_f_22Sparse_Matrix_Tree_CSR_22Sparse_Matrix_Tree_CSR_test_list_tree_conversion\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KSparse_Matrix_Tree_CSR.c:5844:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_previous_element\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 5844 |     \u001b[01;35m\u001b[K__pyx_t_7 = __pyx_v_current_element->lower\u001b[m\u001b[K;\r\n",
      "      |     \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/SLIM/Cython/Sparse_Matrix_Tree_CSR.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "Compiling [5/10]: Sparse_Matrix_Tree_CSR.pyx... PASS\r\n",
      "\r\n",
      "Compiling [6/10]: Triangular_Matrix.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KTriangular_Matrix.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/SLIM/Cython/Triangular_Matrix.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [6/10]: Triangular_Matrix.pyx... PASS\r\n",
      "\r\n",
      "Compiling [7/10]: HP3_Similarity_Cython_SGD.pyx... \r\n",
      "warning: HP3_Similarity_Cython_SGD.pyx:113:40: Index should be typed for more efficient access\r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KHP3_Similarity_Cython_SGD.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KHP3_Similarity_Cython_SGD.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_25HP3_Similarity_Cython_SGD_25HP3_Similarity_Cython_SGD_4fit\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KHP3_Similarity_Cython_SGD.c:6303:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_sample_num\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 6303 |   __pyx_t_1 = PyFloat_FromDouble((__pyx_v_cum_loss / \u001b[01;35m\u001b[K((double)__pyx_v_sample_num)\u001b[m\u001b[K)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 291, __pyx_L1_error)\r\n",
      "      |                                                      \u001b[01;35m\u001b[K~^~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/HP3_Similarity_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "warning: HP3_Similarity_Cython_SGD.pyx:113:40: Index should be typed for more efficient access\r\n",
      "Compiling [7/10]: HP3_Similarity_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "Compiling [8/10]: CFW_DVV_Similarity_Cython_SGD.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KCFW_DVV_Similarity_Cython_SGD.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/CFW_DVV_Similarity_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [8/10]: CFW_DVV_Similarity_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "Compiling [9/10]: FBSM_Rating_Cython_SGD.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KFBSM_Rating_Cython_SGD.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KFBSM_Rating_Cython_SGD.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_22FBSM_Rating_Cython_SGD_22FBSM_Rating_Cython_SGD_2fit\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KFBSM_Rating_Cython_SGD.c:9031:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_num_sample\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 9031 |   __pyx_t_5 = PyFloat_FromDouble((__pyx_v_cum_loss / \u001b[01;35m\u001b[K((double)__pyx_v_num_sample)\u001b[m\u001b[K)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 551, __pyx_L1_error)\r\n",
      "      |                                                      \u001b[01;35m\u001b[K~^~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/FBSM_Rating_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [9/10]: FBSM_Rating_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "Compiling [10/10]: CFW_D_Similarity_Cython_SGD.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KCFW_D_Similarity_Cython_SGD.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KCFW_D_Similarity_Cython_SGD.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_27CFW_D_Similarity_Cython_SGD_27CFW_D_Similarity_Cython_SGD_6fit\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KCFW_D_Similarity_Cython_SGD.c:6056:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_sample_num\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 6056 |   __pyx_t_3 = PyFloat_FromDouble((__pyx_v_cum_loss / \u001b[01;35m\u001b[K((double)__pyx_v_sample_num)\u001b[m\u001b[K)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 290, __pyx_L1_error)\r\n",
      "      |                                                      \u001b[01;35m\u001b[K~^~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/CFW_D_Similarity_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [10/10]: CFW_D_Similarity_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "run_compile_all_cython: Compilation finished. SUCCESS.\r\n",
      "Compilation log can be found here: './result_experiments/run_compile_all_cython.txt'\r\n"
     ]
    }
   ],
   "source": [
    "!python run_compile_all_cython.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2657708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T23:04:35.685609Z",
     "iopub.status.busy": "2022-11-26T23:04:35.685121Z",
     "iopub.status.idle": "2022-11-26T23:04:38.831741Z",
     "shell.execute_reply": "2022-11-26T23:04:38.830179Z"
    },
    "papermill": {
     "duration": 3.159807,
     "end_time": "2022-11-26T23:04:38.834669",
     "exception": false,
     "start_time": "2022-11-26T23:04:35.674862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: W_sparse.npz (deflated 0%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r -j /kaggle/working/SLIMElasticNetRecommender.zip /kaggle/input/slimurmbinary/W_sparse.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74bba6db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T23:04:38.853497Z",
     "iopub.status.busy": "2022-11-26T23:04:38.852771Z",
     "iopub.status.idle": "2022-11-26T23:04:43.912617Z",
     "shell.execute_reply": "2022-11-26T23:04:43.911619Z"
    },
    "papermill": {
     "duration": 5.072407,
     "end_time": "2022-11-26T23:04:43.915366",
     "exception": false,
     "start_time": "2022-11-26T23:04:38.842959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 317 (0.76 %) of 41629 users have no sampled items\n",
      "Warning: 780 (1.87 %) of 41629 users have no sampled items\n",
      "EvaluatorHoldout: Ignoring 780 ( 1.9%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n"
     ]
    }
   ],
   "source": [
    "URM_train_validation, URM_test = split_train_in_two_percentage_global_sample(URM_all, train_percentage = 0.8)\n",
    "URM_train, URM_validation = split_train_in_two_percentage_global_sample(URM_train_validation, train_percentage = 0.8)\n",
    "\n",
    "evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=[10])\n",
    "evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=[10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b89b1710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T23:04:43.934258Z",
     "iopub.status.busy": "2022-11-26T23:04:43.933195Z",
     "iopub.status.idle": "2022-11-26T23:04:43.943226Z",
     "shell.execute_reply": "2022-11-26T23:04:43.942170Z"
    },
    "papermill": {
     "duration": 0.021825,
     "end_time": "2022-11-26T23:04:43.945591",
     "exception": false,
     "start_time": "2022-11-26T23:04:43.923766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<41629x24507 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 994970 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4dc8894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T23:04:43.964413Z",
     "iopub.status.busy": "2022-11-26T23:04:43.964000Z",
     "iopub.status.idle": "2022-11-26T23:04:43.970993Z",
     "shell.execute_reply": "2022-11-26T23:04:43.970165Z"
    },
    "papermill": {
     "duration": 0.01893,
     "end_time": "2022-11-26T23:04:43.973120",
     "exception": false,
     "start_time": "2022-11-26T23:04:43.954190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<41629x24507 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 994970 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sps.csr_matrix(URM_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04a2319c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T23:04:43.992946Z",
     "iopub.status.busy": "2022-11-26T23:04:43.991916Z",
     "iopub.status.idle": "2022-11-26T23:04:43.998673Z",
     "shell.execute_reply": "2022-11-26T23:04:43.997824Z"
    },
    "papermill": {
     "duration": 0.018701,
     "end_time": "2022-11-26T23:04:44.000693",
     "exception": false,
     "start_time": "2022-11-26T23:04:43.981992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,     39,     54, ..., 994916, 994951, 994970], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sps.csr_matrix(URM_train).indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46067fa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T23:04:44.021699Z",
     "iopub.status.busy": "2022-11-26T23:04:44.020901Z",
     "iopub.status.idle": "2022-11-26T23:04:44.029849Z",
     "shell.execute_reply": "2022-11-26T23:04:44.028937Z"
    },
    "papermill": {
     "duration": 0.021409,
     "end_time": "2022-11-26T23:04:44.032255",
     "exception": false,
     "start_time": "2022-11-26T23:04:44.010846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([39, 15, 67, ..., 13, 35, 19], dtype=int32), (41629,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_length = np.ediff1d(sps.csr_matrix(URM_train).indptr)\n",
    "profile_length, profile_length.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42d22f1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T23:04:44.052429Z",
     "iopub.status.busy": "2022-11-26T23:04:44.051670Z",
     "iopub.status.idle": "2022-11-26T23:04:44.059291Z",
     "shell.execute_reply": "2022-11-26T23:04:44.057951Z"
    },
    "papermill": {
     "duration": 0.020473,
     "end_time": "2022-11-26T23:04:44.061778",
     "exception": false,
     "start_time": "2022-11-26T23:04:44.041305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2081"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = int(len(profile_length)*0.05)\n",
    "block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c90b9e30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T23:04:44.081247Z",
     "iopub.status.busy": "2022-11-26T23:04:44.080855Z",
     "iopub.status.idle": "2022-11-26T23:04:44.089703Z",
     "shell.execute_reply": "2022-11-26T23:04:44.088763Z"
    },
    "papermill": {
     "duration": 0.021106,
     "end_time": "2022-11-26T23:04:44.091884",
     "exception": false,
     "start_time": "2022-11-26T23:04:44.070778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28014, 12070, 38033, ..., 19407,  8693, 12454])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_users = np.argsort(profile_length)\n",
    "sorted_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82145e02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T23:04:44.111619Z",
     "iopub.status.busy": "2022-11-26T23:04:44.111161Z",
     "iopub.status.idle": "2022-11-26T23:04:44.122949Z",
     "shell.execute_reply": "2022-11-26T23:04:44.121622Z"
    },
    "papermill": {
     "duration": 0.024648,
     "end_time": "2022-11-26T23:04:44.125492",
     "exception": false,
     "start_time": "2022-11-26T23:04:44.100844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0, #users in group 2081, average p.len 7.31, median 8.0, min 2, max 9\n",
      "Group 1, #users in group 2081, average p.len 9.64, median 10.0, min 9, max 10\n",
      "Group 2, #users in group 2081, average p.len 10.92, median 11.0, min 10, max 12\n",
      "Group 3, #users in group 2081, average p.len 12.05, median 12.0, min 12, max 13\n",
      "Group 4, #users in group 2081, average p.len 13.00, median 13.0, min 13, max 13\n",
      "Group 5, #users in group 2081, average p.len 13.96, median 14.0, min 13, max 14\n",
      "Group 6, #users in group 2081, average p.len 14.91, median 15.0, min 14, max 15\n",
      "Group 7, #users in group 2081, average p.len 15.81, median 16.0, min 15, max 16\n",
      "Group 8, #users in group 2081, average p.len 16.81, median 17.0, min 16, max 17\n",
      "Group 9, #users in group 2081, average p.len 17.83, median 18.0, min 17, max 18\n",
      "Group 10, #users in group 2081, average p.len 19.07, median 19.0, min 18, max 20\n",
      "Group 11, #users in group 2081, average p.len 20.40, median 20.0, min 20, max 21\n",
      "Group 12, #users in group 2081, average p.len 21.93, median 22.0, min 21, max 23\n",
      "Group 13, #users in group 2081, average p.len 23.76, median 24.0, min 23, max 25\n",
      "Group 14, #users in group 2081, average p.len 25.99, median 26.0, min 25, max 27\n",
      "Group 15, #users in group 2081, average p.len 28.91, median 29.0, min 27, max 31\n",
      "Group 16, #users in group 2081, average p.len 32.71, median 33.0, min 31, max 35\n",
      "Group 17, #users in group 2081, average p.len 38.28, median 38.0, min 35, max 42\n",
      "Group 18, #users in group 2081, average p.len 47.56, median 47.0, min 42, max 55\n",
      "Group 19, #users in group 2081, average p.len 84.97, median 71.0, min 55, max 358\n"
     ]
    }
   ],
   "source": [
    "for group_id in range(0, 20):\n",
    "    start_pos = group_id * block_size\n",
    "    end_pos = min((group_id+1) * block_size, len(profile_length))\n",
    "    \n",
    "    users_in_group = sorted_users[start_pos:end_pos]\n",
    "    \n",
    "    users_in_group_p_len = profile_length[users_in_group]\n",
    "    \n",
    "    print(\"Group {}, #users in group {}, average p.len {:.2f}, median {}, min {}, max {}\".format(\n",
    "        group_id, \n",
    "        users_in_group.shape[0],\n",
    "        users_in_group_p_len.mean(),\n",
    "        np.median(users_in_group_p_len),\n",
    "        users_in_group_p_len.min(),\n",
    "        users_in_group_p_len.max()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc7b6f30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T23:04:44.145669Z",
     "iopub.status.busy": "2022-11-26T23:04:44.144973Z",
     "iopub.status.idle": "2022-11-26T23:04:44.167750Z",
     "shell.execute_reply": "2022-11-26T23:04:44.166617Z"
    },
    "papermill": {
     "duration": 0.035958,
     "end_time": "2022-11-26T23:04:44.170367",
     "exception": false,
     "start_time": "2022-11-26T23:04:44.134409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SLIMElasticNetRecommender(BaseItemSimilarityMatrixRecommender):\n",
    "    \"\"\"\n",
    "    Train a Sparse Linear Methods (SLIM) item similarity model.\n",
    "    NOTE: ElasticNet solver is parallel, a single intance of SLIM_ElasticNet will\n",
    "          make use of half the cores available\n",
    "    See:\n",
    "        Efficient Top-N Recommendation by Linear Regression,\n",
    "        M. Levy and K. Jack, LSRS workshop at RecSys 2013.\n",
    "        SLIM: Sparse linear methods for top-n recommender systems,\n",
    "        X. Ning and G. Karypis, ICDM 2011.\n",
    "        http://glaros.dtc.umn.edu/gkhome/fetch/papers/SLIM2011icdm.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"SLIMElasticNetRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, verbose = True):\n",
    "        super(SLIMElasticNetRecommender, self).__init__(URM_train, verbose = verbose)\n",
    "\n",
    "    @ignore_warnings(category=ConvergenceWarning)\n",
    "    def fit(self, l1_ratio=0.1, alpha = 1.0, positive_only=True, topK = 100,**earlystopping_kwargs):\n",
    "\n",
    "        assert l1_ratio>= 0 and l1_ratio<=1, \"{}: l1_ratio must be between 0 and 1, provided value was {}\".format(self.RECOMMENDER_NAME, l1_ratio)\n",
    "\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.positive_only = positive_only\n",
    "        self.topK = topK\n",
    "\n",
    "\n",
    "        # initialize the ElasticNet model\n",
    "        self.model = ElasticNet(alpha=alpha,\n",
    "                                l1_ratio=self.l1_ratio,\n",
    "                                positive=self.positive_only,\n",
    "                                fit_intercept=False,\n",
    "                                copy_X=False,\n",
    "                                precompute=True,\n",
    "                                selection='random',\n",
    "                                max_iter=100,\n",
    "                                tol=1e-4)\n",
    "\n",
    "        URM_train = check_matrix(self.URM_train, 'csc', dtype=np.float32)\n",
    "\n",
    "        n_items = URM_train.shape[1]\n",
    "\n",
    "        # Use array as it reduces memory requirements compared to lists\n",
    "        dataBlock = 10000000\n",
    "\n",
    "        rows = np.zeros(dataBlock, dtype=np.int32)\n",
    "        cols = np.zeros(dataBlock, dtype=np.int32)\n",
    "        values = np.zeros(dataBlock, dtype=np.float32)\n",
    "\n",
    "        numCells = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        start_time_printBatch = start_time\n",
    "\n",
    "        # fit each item's factors sequentially (not in parallel)\n",
    "        for currentItem in range(n_items):\n",
    "\n",
    "            # get the target column\n",
    "            y = URM_train[:, currentItem].toarray()\n",
    "\n",
    "            # set the j-th column of X to zero\n",
    "            start_pos = URM_train.indptr[currentItem]\n",
    "            end_pos = URM_train.indptr[currentItem + 1]\n",
    "\n",
    "            current_item_data_backup = URM_train.data[start_pos: end_pos].copy()\n",
    "            URM_train.data[start_pos: end_pos] = 0.0\n",
    "\n",
    "            # fit one ElasticNet model per column\n",
    "            self.model.fit(URM_train, y)\n",
    "\n",
    "            # self.model.coef_ contains the coefficient of the ElasticNet model\n",
    "            # let's keep only the non-zero values\n",
    "\n",
    "            # Select topK values\n",
    "            # Sorting is done in three steps. Faster then plain np.argsort for higher number of items\n",
    "            # - Partition the data to extract the set of relevant items\n",
    "            # - Sort only the relevant items\n",
    "            # - Get the original item index\n",
    "\n",
    "            nonzero_model_coef_index = self.model.sparse_coef_.indices\n",
    "            nonzero_model_coef_value = self.model.sparse_coef_.data\n",
    "\n",
    "            local_topK = min(len(nonzero_model_coef_value)-1, self.topK)\n",
    "\n",
    "            relevant_items_partition = (-nonzero_model_coef_value).argpartition(local_topK)[0:local_topK]\n",
    "            relevant_items_partition_sorting = np.argsort(-nonzero_model_coef_value[relevant_items_partition])\n",
    "            ranking = relevant_items_partition[relevant_items_partition_sorting]\n",
    "\n",
    "            for index in range(len(ranking)):\n",
    "\n",
    "                if numCells == len(rows):\n",
    "                    rows = np.concatenate((rows, np.zeros(dataBlock, dtype=np.int32)))\n",
    "                    cols = np.concatenate((cols, np.zeros(dataBlock, dtype=np.int32)))\n",
    "                    values = np.concatenate((values, np.zeros(dataBlock, dtype=np.float32)))\n",
    "\n",
    "\n",
    "                rows[numCells] = nonzero_model_coef_index[ranking[index]]\n",
    "                cols[numCells] = currentItem\n",
    "                values[numCells] = nonzero_model_coef_value[ranking[index]]\n",
    "\n",
    "                numCells += 1\n",
    "\n",
    "            # finally, replace the original values of the j-th column\n",
    "            URM_train.data[start_pos:end_pos] = current_item_data_backup\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "            new_time_value, new_time_unit = seconds_to_biggest_unit(elapsed_time)\n",
    "\n",
    "\n",
    "            if time.time() - start_time_printBatch > 300 or currentItem == n_items-1:\n",
    "                self._print(\"Processed {} ({:4.1f}%) in {:.2f} {}. Items per second: {:.2f}\".format(\n",
    "                    currentItem+1,\n",
    "                    100.0* float(currentItem+1)/n_items,\n",
    "                    new_time_value,\n",
    "                    new_time_unit,\n",
    "                    float(currentItem)/elapsed_time))\n",
    "\n",
    "                sys.stdout.flush()\n",
    "                sys.stderr.flush()\n",
    "\n",
    "                start_time_printBatch = time.time()\n",
    "\n",
    "        # generate the sparse weight matrix\n",
    "        self.W_sparse = sps.csr_matrix((values[:numCells], (rows[:numCells], cols[:numCells])),\n",
    "                                       shape=(n_items, n_items), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a047b4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T23:04:44.190654Z",
     "iopub.status.busy": "2022-11-26T23:04:44.190000Z",
     "iopub.status.idle": "2022-11-26T23:17:00.680637Z",
     "shell.execute_reply": "2022-11-26T23:17:00.679125Z"
    },
    "papermill": {
     "duration": 736.584561,
     "end_time": "2022-11-26T23:17:00.763992",
     "exception": false,
     "start_time": "2022-11-26T23:04:44.179431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: Loading model from file '/kaggle/workingSLIMElasticNetRecommender'\n",
      "SLIMElasticNetRecommender: Loading complete\n",
      "Similarity column 41629 (100.0%), 1984.05 column/sec. Elapsed time 20.98 sec\n",
      "Similarity column 24507 (100.0%), 4597.58 column/sec. Elapsed time 5.33 sec\n",
      "P3alphaRecommender: Similarity column 24507 (100.0%), 2581.70 column/sec. Elapsed time 9.49 sec\n",
      "RP3betaRecommender: Similarity column 24507 (100.0%), 2341.96 column/sec. Elapsed time 10.46 sec\n",
      "PureSVDRecommender: Computing SVD decomposition...\n",
      "PureSVDRecommender: Computing SVD decomposition... done in 3.53 sec\n",
      "NMFRecommender: Computing NMF decomposition...\n",
      "NMFRecommender: Computing NMF decomposition... done in 1.74 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.75 sec. MSE loss 4.35E-01. Sample per second: 568026\n",
      "FUNK_SVD: Epoch 1 of 300. Elapsed time 1.52 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.27 sec. MSE loss 6.02E-02. Sample per second: 437857\n",
      "FUNK_SVD: Epoch 2 of 300. Elapsed time 3.04 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.81 sec. MSE loss 9.09E-03. Sample per second: 548884\n",
      "FUNK_SVD: Epoch 3 of 300. Elapsed time 4.58 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.38 sec. MSE loss 2.10E-03. Sample per second: 417670\n",
      "FUNK_SVD: Epoch 4 of 300. Elapsed time 6.15 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.90 sec. MSE loss 1.15E-03. Sample per second: 523341\n",
      "FUNK_SVD: Epoch 5 of 300. Elapsed time 7.67 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.41 sec. MSE loss 1.02E-03. Sample per second: 413461\n",
      "FUNK_SVD: Epoch 6 of 300. Elapsed time 9.17 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.95 sec. MSE loss 1.00E-03. Sample per second: 511085\n",
      "FUNK_SVD: Epoch 7 of 300. Elapsed time 10.71 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.55 sec. MSE loss 1.00E-03. Sample per second: 390053\n",
      "FUNK_SVD: Epoch 8 of 300. Elapsed time 12.32 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.09 sec. MSE loss 1.00E-03. Sample per second: 475298\n",
      "FUNK_SVD: Epoch 9 of 300. Elapsed time 13.86 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.63 sec. MSE loss 9.99E-04. Sample per second: 611864\n",
      "FUNK_SVD: Epoch 10 of 300. Elapsed time 15.39 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.17 sec. MSE loss 1.00E-03. Sample per second: 458783\n",
      "FUNK_SVD: Epoch 11 of 300. Elapsed time 16.94 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.73 sec. MSE loss 9.99E-04. Sample per second: 574584\n",
      "FUNK_SVD: Epoch 12 of 300. Elapsed time 18.50 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.25 sec. MSE loss 9.97E-04. Sample per second: 441576\n",
      "FUNK_SVD: Epoch 13 of 300. Elapsed time 20.02 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.82 sec. MSE loss 9.98E-04. Sample per second: 547912\n",
      "FUNK_SVD: Epoch 14 of 300. Elapsed time 21.58 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.34 sec. MSE loss 1.00E-03. Sample per second: 425356\n",
      "FUNK_SVD: Epoch 15 of 300. Elapsed time 23.10 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.86 sec. MSE loss 1.00E-03. Sample per second: 534141\n",
      "FUNK_SVD: Epoch 16 of 300. Elapsed time 24.63 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.40 sec. MSE loss 1.00E-03. Sample per second: 414900\n",
      "FUNK_SVD: Epoch 17 of 300. Elapsed time 26.16 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.97 sec. MSE loss 9.99E-04. Sample per second: 504236\n",
      "FUNK_SVD: Epoch 18 of 300. Elapsed time 27.74 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.52 sec. MSE loss 9.99E-04. Sample per second: 394584\n",
      "FUNK_SVD: Epoch 19 of 300. Elapsed time 29.29 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.07 sec. MSE loss 9.99E-04. Sample per second: 481144\n",
      "FUNK_SVD: Epoch 20 of 300. Elapsed time 30.83 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.58 sec. MSE loss 9.97E-04. Sample per second: 627811\n",
      "FUNK_SVD: Epoch 21 of 300. Elapsed time 32.35 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.10 sec. MSE loss 1.00E-03. Sample per second: 473859\n",
      "FUNK_SVD: Epoch 22 of 300. Elapsed time 33.87 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.63 sec. MSE loss 1.00E-03. Sample per second: 611404\n",
      "FUNK_SVD: Epoch 23 of 300. Elapsed time 35.39 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.15 sec. MSE loss 9.99E-04. Sample per second: 462119\n",
      "FUNK_SVD: Epoch 24 of 300. Elapsed time 36.92 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.73 sec. MSE loss 9.98E-04. Sample per second: 576578\n",
      "FUNK_SVD: Epoch 25 of 300. Elapsed time 38.49 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.28 sec. MSE loss 9.98E-04. Sample per second: 436774\n",
      "FUNK_SVD: Epoch 26 of 300. Elapsed time 40.05 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.83 sec. MSE loss 9.97E-04. Sample per second: 543259\n",
      "FUNK_SVD: Epoch 27 of 300. Elapsed time 41.60 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.39 sec. MSE loss 9.96E-04. Sample per second: 416880\n",
      "FUNK_SVD: Epoch 28 of 300. Elapsed time 43.15 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.97 sec. MSE loss 1.00E-03. Sample per second: 504271\n",
      "FUNK_SVD: Epoch 29 of 300. Elapsed time 44.74 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.52 sec. MSE loss 9.95E-04. Sample per second: 394810\n",
      "FUNK_SVD: Epoch 30 of 300. Elapsed time 46.29 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.06 sec. MSE loss 9.96E-04. Sample per second: 482806\n",
      "FUNK_SVD: Epoch 31 of 300. Elapsed time 47.83 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.64 sec. MSE loss 9.98E-04. Sample per second: 608473\n",
      "FUNK_SVD: Epoch 32 of 300. Elapsed time 49.40 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.18 sec. MSE loss 9.97E-04. Sample per second: 456387\n",
      "FUNK_SVD: Epoch 33 of 300. Elapsed time 50.95 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.71 sec. MSE loss 1.00E-03. Sample per second: 581771\n",
      "FUNK_SVD: Epoch 34 of 300. Elapsed time 52.48 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.23 sec. MSE loss 9.99E-04. Sample per second: 446702\n",
      "FUNK_SVD: Epoch 35 of 300. Elapsed time 53.99 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.75 sec. MSE loss 9.97E-04. Sample per second: 568016\n",
      "FUNK_SVD: Epoch 36 of 300. Elapsed time 55.52 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.30 sec. MSE loss 9.99E-04. Sample per second: 431674\n",
      "FUNK_SVD: Epoch 37 of 300. Elapsed time 57.07 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.83 sec. MSE loss 1.00E-03. Sample per second: 543085\n",
      "FUNK_SVD: Epoch 38 of 300. Elapsed time 58.60 sec\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.40 sec. MSE loss 1.00E-03. Sample per second: 414586\n",
      "FUNK_SVD: Epoch 39 of 300. Elapsed time 1.00 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.95 sec. MSE loss 9.97E-04. Sample per second: 509273\n",
      "FUNK_SVD: Epoch 40 of 300. Elapsed time 1.03 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.49 sec. MSE loss 9.99E-04. Sample per second: 399839\n",
      "FUNK_SVD: Epoch 41 of 300. Elapsed time 1.05 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.06 sec. MSE loss 9.99E-04. Sample per second: 483710\n",
      "FUNK_SVD: Epoch 42 of 300. Elapsed time 1.08 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.62 sec. MSE loss 1.00E-03. Sample per second: 614467\n",
      "FUNK_SVD: Epoch 43 of 300. Elapsed time 1.11 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.22 sec. MSE loss 9.98E-04. Sample per second: 448805\n",
      "FUNK_SVD: Epoch 44 of 300. Elapsed time 1.13 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.81 sec. MSE loss 9.98E-04. Sample per second: 550582\n",
      "FUNK_SVD: Epoch 45 of 300. Elapsed time 1.16 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.39 sec. MSE loss 9.97E-04. Sample per second: 416077\n",
      "FUNK_SVD: Epoch 46 of 300. Elapsed time 1.19 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.95 sec. MSE loss 9.98E-04. Sample per second: 509661\n",
      "FUNK_SVD: Epoch 47 of 300. Elapsed time 1.21 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.48 sec. MSE loss 1.00E-03. Sample per second: 401296\n",
      "FUNK_SVD: Epoch 48 of 300. Elapsed time 1.24 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.06 sec. MSE loss 1.00E-03. Sample per second: 481963\n",
      "FUNK_SVD: Epoch 49 of 300. Elapsed time 1.26 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.63 sec. MSE loss 9.99E-04. Sample per second: 611720\n",
      "FUNK_SVD: Epoch 50 of 300. Elapsed time 1.29 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.20 sec. MSE loss 1.00E-03. Sample per second: 451210\n",
      "FUNK_SVD: Epoch 51 of 300. Elapsed time 1.32 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.78 sec. MSE loss 9.99E-04. Sample per second: 558811\n",
      "FUNK_SVD: Epoch 52 of 300. Elapsed time 1.34 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.34 sec. MSE loss 1.00E-03. Sample per second: 425234\n",
      "FUNK_SVD: Epoch 53 of 300. Elapsed time 1.37 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.88 sec. MSE loss 9.98E-04. Sample per second: 528510\n",
      "FUNK_SVD: Epoch 54 of 300. Elapsed time 1.39 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.41 sec. MSE loss 9.98E-04. Sample per second: 412194\n",
      "FUNK_SVD: Epoch 55 of 300. Elapsed time 1.42 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.95 sec. MSE loss 9.98E-04. Sample per second: 509257\n",
      "FUNK_SVD: Epoch 56 of 300. Elapsed time 1.45 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.48 sec. MSE loss 1.00E-03. Sample per second: 400593\n",
      "FUNK_SVD: Epoch 57 of 300. Elapsed time 1.47 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.04 sec. MSE loss 9.98E-04. Sample per second: 488174\n",
      "FUNK_SVD: Epoch 58 of 300. Elapsed time 1.50 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.59 sec. MSE loss 9.98E-04. Sample per second: 625782\n",
      "FUNK_SVD: Epoch 59 of 300. Elapsed time 1.52 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.16 sec. MSE loss 9.97E-04. Sample per second: 460400\n",
      "FUNK_SVD: Epoch 60 of 300. Elapsed time 1.55 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.71 sec. MSE loss 9.98E-04. Sample per second: 582328\n",
      "FUNK_SVD: Epoch 61 of 300. Elapsed time 1.57 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.27 sec. MSE loss 9.97E-04. Sample per second: 438663\n",
      "FUNK_SVD: Epoch 62 of 300. Elapsed time 1.60 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.91 sec. MSE loss 9.98E-04. Sample per second: 520620\n",
      "FUNK_SVD: Epoch 63 of 300. Elapsed time 1.63 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.58 sec. MSE loss 9.99E-04. Sample per second: 385118\n",
      "FUNK_SVD: Epoch 64 of 300. Elapsed time 1.66 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.15 sec. MSE loss 9.98E-04. Sample per second: 462077\n",
      "FUNK_SVD: Epoch 65 of 300. Elapsed time 1.68 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.73 sec. MSE loss 9.97E-04. Sample per second: 574551\n",
      "FUNK_SVD: Epoch 66 of 300. Elapsed time 1.71 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.32 sec. MSE loss 9.99E-04. Sample per second: 428785\n",
      "FUNK_SVD: Epoch 67 of 300. Elapsed time 1.73 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.89 sec. MSE loss 9.98E-04. Sample per second: 527627\n",
      "FUNK_SVD: Epoch 68 of 300. Elapsed time 1.76 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.52 sec. MSE loss 9.99E-04. Sample per second: 394702\n",
      "FUNK_SVD: Epoch 69 of 300. Elapsed time 1.79 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.12 sec. MSE loss 1.00E-03. Sample per second: 468235\n",
      "FUNK_SVD: Epoch 70 of 300. Elapsed time 1.81 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.70 sec. MSE loss 9.94E-04. Sample per second: 585119\n",
      "FUNK_SVD: Epoch 71 of 300. Elapsed time 1.84 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.29 sec. MSE loss 9.99E-04. Sample per second: 435275\n",
      "FUNK_SVD: Epoch 72 of 300. Elapsed time 1.87 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.84 sec. MSE loss 9.98E-04. Sample per second: 540722\n",
      "FUNK_SVD: Epoch 73 of 300. Elapsed time 1.89 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.42 sec. MSE loss 9.95E-04. Sample per second: 410639\n",
      "FUNK_SVD: Epoch 74 of 300. Elapsed time 1.92 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.00 sec. MSE loss 9.98E-04. Sample per second: 497292\n",
      "FUNK_SVD: Epoch 75 of 300. Elapsed time 1.95 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.56 sec. MSE loss 9.99E-04. Sample per second: 637382\n",
      "FUNK_SVD: Epoch 76 of 300. Elapsed time 1.97 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.14 sec. MSE loss 9.98E-04. Sample per second: 465365\n",
      "FUNK_SVD: Epoch 77 of 300. Elapsed time 2.00 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.71 sec. MSE loss 9.95E-04. Sample per second: 582570\n",
      "FUNK_SVD: Epoch 78 of 300. Elapsed time 2.02 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.28 sec. MSE loss 9.99E-04. Sample per second: 436849\n",
      "FUNK_SVD: Epoch 79 of 300. Elapsed time 2.05 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.87 sec. MSE loss 9.96E-04. Sample per second: 532003\n",
      "FUNK_SVD: Epoch 80 of 300. Elapsed time 2.08 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.45 sec. MSE loss 9.99E-04. Sample per second: 406791\n",
      "FUNK_SVD: Epoch 81 of 300. Elapsed time 2.10 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.01 sec. MSE loss 1.00E-03. Sample per second: 496114\n",
      "FUNK_SVD: Epoch 82 of 300. Elapsed time 2.13 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.57 sec. MSE loss 9.98E-04. Sample per second: 633554\n",
      "FUNK_SVD: Epoch 83 of 300. Elapsed time 2.16 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.11 sec. MSE loss 9.99E-04. Sample per second: 470528\n",
      "FUNK_SVD: Epoch 84 of 300. Elapsed time 2.18 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.66 sec. MSE loss 9.99E-04. Sample per second: 600509\n",
      "FUNK_SVD: Epoch 85 of 300. Elapsed time 2.21 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.22 sec. MSE loss 9.98E-04. Sample per second: 448114\n",
      "FUNK_SVD: Epoch 86 of 300. Elapsed time 2.23 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.79 sec. MSE loss 9.98E-04. Sample per second: 554944\n",
      "FUNK_SVD: Epoch 87 of 300. Elapsed time 2.26 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.38 sec. MSE loss 1.00E-03. Sample per second: 418589\n",
      "FUNK_SVD: Epoch 88 of 300. Elapsed time 2.29 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.00 sec. MSE loss 9.98E-04. Sample per second: 497523\n",
      "FUNK_SVD: Epoch 89 of 300. Elapsed time 2.31 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.55 sec. MSE loss 9.98E-04. Sample per second: 642090\n",
      "FUNK_SVD: Epoch 90 of 300. Elapsed time 2.34 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.09 sec. MSE loss 9.96E-04. Sample per second: 476922\n",
      "FUNK_SVD: Epoch 91 of 300. Elapsed time 2.36 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.60 sec. MSE loss 1.00E-03. Sample per second: 619841\n",
      "FUNK_SVD: Epoch 92 of 300. Elapsed time 2.39 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.14 sec. MSE loss 1.00E-03. Sample per second: 464040\n",
      "FUNK_SVD: Epoch 93 of 300. Elapsed time 2.42 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.70 sec. MSE loss 1.00E-03. Sample per second: 586643\n",
      "FUNK_SVD: Epoch 94 of 300. Elapsed time 2.44 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.26 sec. MSE loss 9.97E-04. Sample per second: 439652\n",
      "FUNK_SVD: Epoch 95 of 300. Elapsed time 2.47 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.79 sec. MSE loss 9.98E-04. Sample per second: 555557\n",
      "FUNK_SVD: Epoch 96 of 300. Elapsed time 2.49 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.35 sec. MSE loss 9.99E-04. Sample per second: 423801\n",
      "FUNK_SVD: Epoch 97 of 300. Elapsed time 2.52 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.90 sec. MSE loss 9.97E-04. Sample per second: 524411\n",
      "FUNK_SVD: Epoch 98 of 300. Elapsed time 2.54 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.48 sec. MSE loss 9.98E-04. Sample per second: 401347\n",
      "FUNK_SVD: Epoch 99 of 300. Elapsed time 2.57 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.05 sec. MSE loss 1.00E-03. Sample per second: 484737\n",
      "FUNK_SVD: Epoch 100 of 300. Elapsed time 2.60 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.64 sec. MSE loss 1.00E-03. Sample per second: 608070\n",
      "FUNK_SVD: Epoch 101 of 300. Elapsed time 2.62 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.25 sec. MSE loss 9.96E-04. Sample per second: 441837\n",
      "FUNK_SVD: Epoch 102 of 300. Elapsed time 2.65 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.82 sec. MSE loss 9.97E-04. Sample per second: 546426\n",
      "FUNK_SVD: Epoch 103 of 300. Elapsed time 2.68 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.39 sec. MSE loss 1.00E-03. Sample per second: 416752\n",
      "FUNK_SVD: Epoch 104 of 300. Elapsed time 2.70 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.95 sec. MSE loss 1.00E-03. Sample per second: 509513\n",
      "FUNK_SVD: Epoch 105 of 300. Elapsed time 2.73 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.51 sec. MSE loss 9.99E-04. Sample per second: 395954\n",
      "FUNK_SVD: Epoch 106 of 300. Elapsed time 2.75 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.06 sec. MSE loss 9.98E-04. Sample per second: 482868\n",
      "FUNK_SVD: Epoch 107 of 300. Elapsed time 2.78 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.62 sec. MSE loss 9.99E-04. Sample per second: 615824\n",
      "FUNK_SVD: Epoch 108 of 300. Elapsed time 2.81 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.29 sec. MSE loss 9.96E-04. Sample per second: 434372\n",
      "FUNK_SVD: Epoch 109 of 300. Elapsed time 2.83 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.86 sec. MSE loss 9.97E-04. Sample per second: 533695\n",
      "FUNK_SVD: Epoch 110 of 300. Elapsed time 2.86 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.43 sec. MSE loss 9.98E-04. Sample per second: 409768\n",
      "FUNK_SVD: Epoch 111 of 300. Elapsed time 2.89 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.97 sec. MSE loss 9.97E-04. Sample per second: 505352\n",
      "FUNK_SVD: Epoch 112 of 300. Elapsed time 2.91 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.51 sec. MSE loss 1.00E-03. Sample per second: 396579\n",
      "FUNK_SVD: Epoch 113 of 300. Elapsed time 2.94 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.06 sec. MSE loss 9.94E-04. Sample per second: 481869\n",
      "FUNK_SVD: Epoch 114 of 300. Elapsed time 2.96 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.63 sec. MSE loss 9.98E-04. Sample per second: 610374\n",
      "FUNK_SVD: Epoch 115 of 300. Elapsed time 2.99 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.20 sec. MSE loss 9.97E-04. Sample per second: 452406\n",
      "FUNK_SVD: Epoch 116 of 300. Elapsed time 3.02 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.81 sec. MSE loss 9.99E-04. Sample per second: 550136\n",
      "FUNK_SVD: Epoch 117 of 300. Elapsed time 3.04 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.38 sec. MSE loss 1.00E-03. Sample per second: 418811\n",
      "FUNK_SVD: Epoch 118 of 300. Elapsed time 3.07 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.92 sec. MSE loss 9.99E-04. Sample per second: 518987\n",
      "FUNK_SVD: Epoch 119 of 300. Elapsed time 3.09 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.48 sec. MSE loss 1.00E-03. Sample per second: 401081\n",
      "FUNK_SVD: Epoch 120 of 300. Elapsed time 3.12 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.03 sec. MSE loss 9.99E-04. Sample per second: 489086\n",
      "FUNK_SVD: Epoch 121 of 300. Elapsed time 3.15 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.58 sec. MSE loss 9.99E-04. Sample per second: 630520\n",
      "FUNK_SVD: Epoch 122 of 300. Elapsed time 3.17 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.16 sec. MSE loss 9.98E-04. Sample per second: 460218\n",
      "FUNK_SVD: Epoch 123 of 300. Elapsed time 3.20 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.71 sec. MSE loss 9.99E-04. Sample per second: 582453\n",
      "FUNK_SVD: Epoch 124 of 300. Elapsed time 3.22 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.26 sec. MSE loss 9.96E-04. Sample per second: 440693\n",
      "FUNK_SVD: Epoch 125 of 300. Elapsed time 3.25 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.82 sec. MSE loss 9.98E-04. Sample per second: 547262\n",
      "FUNK_SVD: Epoch 126 of 300. Elapsed time 3.28 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.39 sec. MSE loss 9.97E-04. Sample per second: 416594\n",
      "FUNK_SVD: Epoch 127 of 300. Elapsed time 3.30 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.93 sec. MSE loss 9.96E-04. Sample per second: 515503\n",
      "FUNK_SVD: Epoch 128 of 300. Elapsed time 3.33 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.55 sec. MSE loss 9.96E-04. Sample per second: 390212\n",
      "FUNK_SVD: Epoch 129 of 300. Elapsed time 3.36 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.14 sec. MSE loss 9.94E-04. Sample per second: 464832\n",
      "FUNK_SVD: Epoch 130 of 300. Elapsed time 3.38 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.74 sec. MSE loss 9.99E-04. Sample per second: 573434\n",
      "FUNK_SVD: Epoch 131 of 300. Elapsed time 3.41 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.35 sec. MSE loss 9.98E-04. Sample per second: 422923\n",
      "FUNK_SVD: Epoch 132 of 300. Elapsed time 3.44 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.92 sec. MSE loss 1.00E-03. Sample per second: 517471\n",
      "FUNK_SVD: Epoch 133 of 300. Elapsed time 3.46 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.47 sec. MSE loss 9.96E-04. Sample per second: 402651\n",
      "FUNK_SVD: Epoch 134 of 300. Elapsed time 3.49 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.01 sec. MSE loss 9.99E-04. Sample per second: 494462\n",
      "FUNK_SVD: Epoch 135 of 300. Elapsed time 3.51 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.56 sec. MSE loss 9.96E-04. Sample per second: 636514\n",
      "FUNK_SVD: Epoch 136 of 300. Elapsed time 3.54 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.13 sec. MSE loss 9.96E-04. Sample per second: 466995\n",
      "FUNK_SVD: Epoch 137 of 300. Elapsed time 3.56 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.69 sec. MSE loss 9.97E-04. Sample per second: 587974\n",
      "FUNK_SVD: Epoch 138 of 300. Elapsed time 3.59 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.24 sec. MSE loss 1.00E-03. Sample per second: 444075\n",
      "FUNK_SVD: Epoch 139 of 300. Elapsed time 3.62 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.83 sec. MSE loss 9.97E-04. Sample per second: 543083\n",
      "FUNK_SVD: Epoch 140 of 300. Elapsed time 3.64 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.38 sec. MSE loss 9.98E-04. Sample per second: 417379\n",
      "FUNK_SVD: Epoch 141 of 300. Elapsed time 3.67 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.96 sec. MSE loss 9.97E-04. Sample per second: 508788\n",
      "FUNK_SVD: Epoch 142 of 300. Elapsed time 3.70 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.51 sec. MSE loss 9.97E-04. Sample per second: 396083\n",
      "FUNK_SVD: Epoch 143 of 300. Elapsed time 3.72 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.12 sec. MSE loss 9.99E-04. Sample per second: 469096\n",
      "FUNK_SVD: Epoch 144 of 300. Elapsed time 3.75 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.70 sec. MSE loss 9.96E-04. Sample per second: 586882\n",
      "FUNK_SVD: Epoch 145 of 300. Elapsed time 3.77 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.28 sec. MSE loss 9.97E-04. Sample per second: 436988\n",
      "FUNK_SVD: Epoch 146 of 300. Elapsed time 3.80 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.85 sec. MSE loss 9.94E-04. Sample per second: 537553\n",
      "FUNK_SVD: Epoch 147 of 300. Elapsed time 3.83 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.42 sec. MSE loss 9.98E-04. Sample per second: 410782\n",
      "FUNK_SVD: Epoch 148 of 300. Elapsed time 3.85 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.06 sec. MSE loss 9.96E-04. Sample per second: 481850\n",
      "FUNK_SVD: Epoch 149 of 300. Elapsed time 3.88 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.62 sec. MSE loss 9.98E-04. Sample per second: 612418\n",
      "FUNK_SVD: Epoch 150 of 300. Elapsed time 3.91 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.19 sec. MSE loss 9.97E-04. Sample per second: 454981\n",
      "FUNK_SVD: Epoch 151 of 300. Elapsed time 3.93 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.73 sec. MSE loss 9.98E-04. Sample per second: 574032\n",
      "FUNK_SVD: Epoch 152 of 300. Elapsed time 3.96 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.31 sec. MSE loss 9.98E-04. Sample per second: 430513\n",
      "FUNK_SVD: Epoch 153 of 300. Elapsed time 3.98 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.87 sec. MSE loss 9.97E-04. Sample per second: 531168\n",
      "FUNK_SVD: Epoch 154 of 300. Elapsed time 4.01 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.42 sec. MSE loss 9.98E-04. Sample per second: 411252\n",
      "FUNK_SVD: Epoch 155 of 300. Elapsed time 4.04 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.95 sec. MSE loss 9.98E-04. Sample per second: 510881\n",
      "FUNK_SVD: Epoch 156 of 300. Elapsed time 4.06 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.51 sec. MSE loss 9.97E-04. Sample per second: 395852\n",
      "FUNK_SVD: Epoch 157 of 300. Elapsed time 4.09 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.06 sec. MSE loss 9.97E-04. Sample per second: 482048\n",
      "FUNK_SVD: Epoch 158 of 300. Elapsed time 4.11 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.60 sec. MSE loss 9.94E-04. Sample per second: 620494\n",
      "FUNK_SVD: Epoch 159 of 300. Elapsed time 4.14 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.14 sec. MSE loss 9.97E-04. Sample per second: 465270\n",
      "FUNK_SVD: Epoch 160 of 300. Elapsed time 4.17 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.66 sec. MSE loss 9.96E-04. Sample per second: 597665\n",
      "FUNK_SVD: Epoch 161 of 300. Elapsed time 4.19 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.20 sec. MSE loss 9.96E-04. Sample per second: 452647\n",
      "FUNK_SVD: Epoch 162 of 300. Elapsed time 4.22 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.75 sec. MSE loss 9.95E-04. Sample per second: 567964\n",
      "FUNK_SVD: Epoch 163 of 300. Elapsed time 4.24 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.27 sec. MSE loss 9.97E-04. Sample per second: 438187\n",
      "FUNK_SVD: Epoch 164 of 300. Elapsed time 4.27 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.83 sec. MSE loss 9.98E-04. Sample per second: 543956\n",
      "FUNK_SVD: Epoch 165 of 300. Elapsed time 4.29 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.38 sec. MSE loss 9.96E-04. Sample per second: 418363\n",
      "FUNK_SVD: Epoch 166 of 300. Elapsed time 4.32 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.92 sec. MSE loss 9.95E-04. Sample per second: 517386\n",
      "FUNK_SVD: Epoch 167 of 300. Elapsed time 4.34 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.47 sec. MSE loss 9.98E-04. Sample per second: 403060\n",
      "FUNK_SVD: Epoch 168 of 300. Elapsed time 4.37 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.02 sec. MSE loss 9.98E-04. Sample per second: 492913\n",
      "FUNK_SVD: Epoch 169 of 300. Elapsed time 4.40 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.66 sec. MSE loss 9.95E-04. Sample per second: 597726\n",
      "FUNK_SVD: Epoch 170 of 300. Elapsed time 4.42 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.21 sec. MSE loss 9.95E-04. Sample per second: 450591\n",
      "FUNK_SVD: Epoch 171 of 300. Elapsed time 4.45 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.74 sec. MSE loss 9.94E-04. Sample per second: 572031\n",
      "FUNK_SVD: Epoch 172 of 300. Elapsed time 4.48 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.37 sec. MSE loss 9.96E-04. Sample per second: 420691\n",
      "FUNK_SVD: Epoch 173 of 300. Elapsed time 4.50 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.98 sec. MSE loss 9.98E-04. Sample per second: 503202\n",
      "FUNK_SVD: Epoch 174 of 300. Elapsed time 4.53 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.62 sec. MSE loss 9.96E-04. Sample per second: 380275\n",
      "FUNK_SVD: Epoch 175 of 300. Elapsed time 4.56 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.21 sec. MSE loss 9.98E-04. Sample per second: 449963\n",
      "FUNK_SVD: Epoch 176 of 300. Elapsed time 4.58 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.80 sec. MSE loss 9.97E-04. Sample per second: 551795\n",
      "FUNK_SVD: Epoch 177 of 300. Elapsed time 4.61 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.40 sec. MSE loss 9.95E-04. Sample per second: 414583\n",
      "FUNK_SVD: Epoch 178 of 300. Elapsed time 4.64 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.98 sec. MSE loss 9.97E-04. Sample per second: 502551\n",
      "FUNK_SVD: Epoch 179 of 300. Elapsed time 4.66 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.56 sec. MSE loss 9.96E-04. Sample per second: 388887\n",
      "FUNK_SVD: Epoch 180 of 300. Elapsed time 4.69 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.11 sec. MSE loss 9.97E-04. Sample per second: 471827\n",
      "FUNK_SVD: Epoch 181 of 300. Elapsed time 4.71 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.64 sec. MSE loss 9.94E-04. Sample per second: 606241\n",
      "FUNK_SVD: Epoch 182 of 300. Elapsed time 4.74 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.18 sec. MSE loss 9.99E-04. Sample per second: 456798\n",
      "FUNK_SVD: Epoch 183 of 300. Elapsed time 4.77 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.76 sec. MSE loss 9.99E-04. Sample per second: 566459\n",
      "FUNK_SVD: Epoch 184 of 300. Elapsed time 4.79 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.30 sec. MSE loss 9.92E-04. Sample per second: 432885\n",
      "FUNK_SVD: Epoch 185 of 300. Elapsed time 4.82 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.85 sec. MSE loss 9.95E-04. Sample per second: 538069\n",
      "FUNK_SVD: Epoch 186 of 300. Elapsed time 4.84 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.39 sec. MSE loss 9.97E-04. Sample per second: 416646\n",
      "FUNK_SVD: Epoch 187 of 300. Elapsed time 4.87 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.91 sec. MSE loss 9.97E-04. Sample per second: 520623\n",
      "FUNK_SVD: Epoch 188 of 300. Elapsed time 4.89 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.44 sec. MSE loss 9.93E-04. Sample per second: 408215\n",
      "FUNK_SVD: Epoch 189 of 300. Elapsed time 4.92 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.13 sec. MSE loss 9.97E-04. Sample per second: 465976\n",
      "FUNK_SVD: Epoch 190 of 300. Elapsed time 4.95 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.73 sec. MSE loss 9.95E-04. Sample per second: 576664\n",
      "FUNK_SVD: Epoch 191 of 300. Elapsed time 4.97 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.33 sec. MSE loss 9.96E-04. Sample per second: 426414\n",
      "FUNK_SVD: Epoch 192 of 300. Elapsed time 5.00 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.87 sec. MSE loss 9.97E-04. Sample per second: 530950\n",
      "FUNK_SVD: Epoch 193 of 300. Elapsed time 5.03 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.40 sec. MSE loss 9.97E-04. Sample per second: 415326\n",
      "FUNK_SVD: Epoch 194 of 300. Elapsed time 5.05 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.93 sec. MSE loss 9.97E-04. Sample per second: 514716\n",
      "FUNK_SVD: Epoch 195 of 300. Elapsed time 5.08 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.45 sec. MSE loss 9.95E-04. Sample per second: 405743\n",
      "FUNK_SVD: Epoch 196 of 300. Elapsed time 5.10 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.00 sec. MSE loss 9.98E-04. Sample per second: 496544\n",
      "FUNK_SVD: Epoch 197 of 300. Elapsed time 5.13 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.54 sec. MSE loss 9.95E-04. Sample per second: 645093\n",
      "FUNK_SVD: Epoch 198 of 300. Elapsed time 5.16 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.05 sec. MSE loss 9.97E-04. Sample per second: 485898\n",
      "FUNK_SVD: Epoch 199 of 300. Elapsed time 5.18 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.56 sec. MSE loss 9.94E-04. Sample per second: 637510\n",
      "FUNK_SVD: Epoch 200 of 300. Elapsed time 5.21 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.11 sec. MSE loss 9.97E-04. Sample per second: 471281\n",
      "FUNK_SVD: Epoch 201 of 300. Elapsed time 5.23 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.63 sec. MSE loss 9.99E-04. Sample per second: 612055\n",
      "FUNK_SVD: Epoch 202 of 300. Elapsed time 5.26 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.17 sec. MSE loss 9.97E-04. Sample per second: 458777\n",
      "FUNK_SVD: Epoch 203 of 300. Elapsed time 5.28 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.73 sec. MSE loss 9.97E-04. Sample per second: 575484\n",
      "FUNK_SVD: Epoch 204 of 300. Elapsed time 5.31 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.27 sec. MSE loss 9.96E-04. Sample per second: 439054\n",
      "FUNK_SVD: Epoch 205 of 300. Elapsed time 5.33 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.83 sec. MSE loss 9.97E-04. Sample per second: 543129\n",
      "FUNK_SVD: Epoch 206 of 300. Elapsed time 5.36 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.37 sec. MSE loss 9.98E-04. Sample per second: 419287\n",
      "FUNK_SVD: Epoch 207 of 300. Elapsed time 5.39 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.92 sec. MSE loss 9.98E-04. Sample per second: 517940\n",
      "FUNK_SVD: Epoch 208 of 300. Elapsed time 5.41 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.48 sec. MSE loss 9.97E-04. Sample per second: 401058\n",
      "FUNK_SVD: Epoch 209 of 300. Elapsed time 5.44 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.11 sec. MSE loss 9.96E-04. Sample per second: 472168\n",
      "FUNK_SVD: Epoch 210 of 300. Elapsed time 5.46 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.67 sec. MSE loss 9.98E-04. Sample per second: 597241\n",
      "FUNK_SVD: Epoch 211 of 300. Elapsed time 5.49 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.21 sec. MSE loss 9.97E-04. Sample per second: 450794\n",
      "FUNK_SVD: Epoch 212 of 300. Elapsed time 5.52 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.73 sec. MSE loss 9.98E-04. Sample per second: 573942\n",
      "FUNK_SVD: Epoch 213 of 300. Elapsed time 5.54 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.28 sec. MSE loss 9.94E-04. Sample per second: 435494\n",
      "FUNK_SVD: Epoch 214 of 300. Elapsed time 5.57 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.87 sec. MSE loss 9.97E-04. Sample per second: 532074\n",
      "FUNK_SVD: Epoch 215 of 300. Elapsed time 5.59 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.46 sec. MSE loss 9.96E-04. Sample per second: 404198\n",
      "FUNK_SVD: Epoch 216 of 300. Elapsed time 5.62 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.04 sec. MSE loss 9.97E-04. Sample per second: 487794\n",
      "FUNK_SVD: Epoch 217 of 300. Elapsed time 5.65 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.61 sec. MSE loss 9.93E-04. Sample per second: 618912\n",
      "FUNK_SVD: Epoch 218 of 300. Elapsed time 5.67 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.17 sec. MSE loss 9.97E-04. Sample per second: 459426\n",
      "FUNK_SVD: Epoch 219 of 300. Elapsed time 5.70 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.70 sec. MSE loss 9.93E-04. Sample per second: 585581\n",
      "FUNK_SVD: Epoch 220 of 300. Elapsed time 5.72 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.25 sec. MSE loss 9.99E-04. Sample per second: 441678\n",
      "FUNK_SVD: Epoch 221 of 300. Elapsed time 5.75 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.84 sec. MSE loss 9.98E-04. Sample per second: 539271\n",
      "FUNK_SVD: Epoch 222 of 300. Elapsed time 5.78 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.41 sec. MSE loss 9.98E-04. Sample per second: 413428\n",
      "FUNK_SVD: Epoch 223 of 300. Elapsed time 5.80 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.95 sec. MSE loss 9.98E-04. Sample per second: 511046\n",
      "FUNK_SVD: Epoch 224 of 300. Elapsed time 5.83 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.49 sec. MSE loss 9.96E-04. Sample per second: 399237\n",
      "FUNK_SVD: Epoch 225 of 300. Elapsed time 5.85 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.05 sec. MSE loss 9.94E-04. Sample per second: 485185\n",
      "FUNK_SVD: Epoch 226 of 300. Elapsed time 5.88 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.59 sec. MSE loss 9.94E-04. Sample per second: 624388\n",
      "FUNK_SVD: Epoch 227 of 300. Elapsed time 5.91 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.13 sec. MSE loss 9.97E-04. Sample per second: 468157\n",
      "FUNK_SVD: Epoch 228 of 300. Elapsed time 5.93 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.70 sec. MSE loss 9.96E-04. Sample per second: 583513\n",
      "FUNK_SVD: Epoch 229 of 300. Elapsed time 5.96 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.34 sec. MSE loss 9.97E-04. Sample per second: 425104\n",
      "FUNK_SVD: Epoch 230 of 300. Elapsed time 5.99 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.97 sec. MSE loss 9.97E-04. Sample per second: 504602\n",
      "FUNK_SVD: Epoch 231 of 300. Elapsed time 6.01 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.57 sec. MSE loss 9.96E-04. Sample per second: 386721\n",
      "FUNK_SVD: Epoch 232 of 300. Elapsed time 6.04 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.16 sec. MSE loss 9.96E-04. Sample per second: 459880\n",
      "FUNK_SVD: Epoch 233 of 300. Elapsed time 6.07 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.79 sec. MSE loss 9.97E-04. Sample per second: 556162\n",
      "FUNK_SVD: Epoch 234 of 300. Elapsed time 6.09 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.34 sec. MSE loss 9.97E-04. Sample per second: 424369\n",
      "FUNK_SVD: Epoch 235 of 300. Elapsed time 6.12 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.90 sec. MSE loss 9.96E-04. Sample per second: 524145\n",
      "FUNK_SVD: Epoch 236 of 300. Elapsed time 6.14 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.43 sec. MSE loss 9.95E-04. Sample per second: 409782\n",
      "FUNK_SVD: Epoch 237 of 300. Elapsed time 6.17 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.97 sec. MSE loss 9.95E-04. Sample per second: 504957\n",
      "FUNK_SVD: Epoch 238 of 300. Elapsed time 6.20 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.49 sec. MSE loss 9.97E-04. Sample per second: 400027\n",
      "FUNK_SVD: Epoch 239 of 300. Elapsed time 6.22 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.02 sec. MSE loss 9.95E-04. Sample per second: 493287\n",
      "FUNK_SVD: Epoch 240 of 300. Elapsed time 6.25 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.58 sec. MSE loss 9.97E-04. Sample per second: 630639\n",
      "FUNK_SVD: Epoch 241 of 300. Elapsed time 6.27 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.13 sec. MSE loss 9.96E-04. Sample per second: 467935\n",
      "FUNK_SVD: Epoch 242 of 300. Elapsed time 6.30 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.71 sec. MSE loss 9.94E-04. Sample per second: 581123\n",
      "FUNK_SVD: Epoch 243 of 300. Elapsed time 6.32 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.27 sec. MSE loss 9.94E-04. Sample per second: 438495\n",
      "FUNK_SVD: Epoch 244 of 300. Elapsed time 6.35 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.81 sec. MSE loss 9.96E-04. Sample per second: 550551\n",
      "FUNK_SVD: Epoch 245 of 300. Elapsed time 6.38 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.34 sec. MSE loss 9.96E-04. Sample per second: 424290\n",
      "FUNK_SVD: Epoch 246 of 300. Elapsed time 6.40 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.89 sec. MSE loss 9.93E-04. Sample per second: 526942\n",
      "FUNK_SVD: Epoch 247 of 300. Elapsed time 6.43 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.43 sec. MSE loss 9.95E-04. Sample per second: 410168\n",
      "FUNK_SVD: Epoch 248 of 300. Elapsed time 6.45 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.97 sec. MSE loss 9.97E-04. Sample per second: 505412\n",
      "FUNK_SVD: Epoch 249 of 300. Elapsed time 6.48 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.59 sec. MSE loss 9.96E-04. Sample per second: 384529\n",
      "FUNK_SVD: Epoch 250 of 300. Elapsed time 6.51 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.21 sec. MSE loss 9.93E-04. Sample per second: 449841\n",
      "FUNK_SVD: Epoch 251 of 300. Elapsed time 6.53 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.81 sec. MSE loss 9.96E-04. Sample per second: 550214\n",
      "FUNK_SVD: Epoch 252 of 300. Elapsed time 6.56 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.42 sec. MSE loss 9.95E-04. Sample per second: 411469\n",
      "FUNK_SVD: Epoch 253 of 300. Elapsed time 6.59 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.97 sec. MSE loss 9.96E-04. Sample per second: 503966\n",
      "FUNK_SVD: Epoch 254 of 300. Elapsed time 6.61 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.56 sec. MSE loss 9.99E-04. Sample per second: 389120\n",
      "FUNK_SVD: Epoch 255 of 300. Elapsed time 6.64 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.09 sec. MSE loss 9.96E-04. Sample per second: 476799\n",
      "FUNK_SVD: Epoch 256 of 300. Elapsed time 6.66 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.68 sec. MSE loss 9.94E-04. Sample per second: 593878\n",
      "FUNK_SVD: Epoch 257 of 300. Elapsed time 6.69 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.23 sec. MSE loss 9.96E-04. Sample per second: 446522\n",
      "FUNK_SVD: Epoch 258 of 300. Elapsed time 6.72 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.76 sec. MSE loss 9.96E-04. Sample per second: 564420\n",
      "FUNK_SVD: Epoch 259 of 300. Elapsed time 6.74 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.30 sec. MSE loss 9.97E-04. Sample per second: 431642\n",
      "FUNK_SVD: Epoch 260 of 300. Elapsed time 6.77 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.85 sec. MSE loss 9.94E-04. Sample per second: 538110\n",
      "FUNK_SVD: Epoch 261 of 300. Elapsed time 6.79 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.42 sec. MSE loss 9.97E-04. Sample per second: 411151\n",
      "FUNK_SVD: Epoch 262 of 300. Elapsed time 6.82 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.02 sec. MSE loss 9.93E-04. Sample per second: 493491\n",
      "FUNK_SVD: Epoch 263 of 300. Elapsed time 6.85 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.57 sec. MSE loss 1.00E-03. Sample per second: 633381\n",
      "FUNK_SVD: Epoch 264 of 300. Elapsed time 6.87 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.11 sec. MSE loss 9.94E-04. Sample per second: 470939\n",
      "FUNK_SVD: Epoch 265 of 300. Elapsed time 6.90 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.62 sec. MSE loss 9.94E-04. Sample per second: 615177\n",
      "FUNK_SVD: Epoch 266 of 300. Elapsed time 6.92 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.16 sec. MSE loss 9.97E-04. Sample per second: 461181\n",
      "FUNK_SVD: Epoch 267 of 300. Elapsed time 6.95 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.69 sec. MSE loss 9.95E-04. Sample per second: 587654\n",
      "FUNK_SVD: Epoch 268 of 300. Elapsed time 6.97 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.22 sec. MSE loss 9.94E-04. Sample per second: 447486\n",
      "FUNK_SVD: Epoch 269 of 300. Elapsed time 7.00 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.77 sec. MSE loss 9.95E-04. Sample per second: 562139\n",
      "FUNK_SVD: Epoch 270 of 300. Elapsed time 7.03 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.43 sec. MSE loss 9.96E-04. Sample per second: 409899\n",
      "FUNK_SVD: Epoch 271 of 300. Elapsed time 7.05 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.03 sec. MSE loss 9.97E-04. Sample per second: 489970\n",
      "FUNK_SVD: Epoch 272 of 300. Elapsed time 7.08 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.66 sec. MSE loss 9.99E-04. Sample per second: 598190\n",
      "FUNK_SVD: Epoch 273 of 300. Elapsed time 7.11 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.18 sec. MSE loss 9.97E-04. Sample per second: 455588\n",
      "FUNK_SVD: Epoch 274 of 300. Elapsed time 7.13 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.73 sec. MSE loss 9.95E-04. Sample per second: 576155\n",
      "FUNK_SVD: Epoch 275 of 300. Elapsed time 7.16 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.27 sec. MSE loss 9.98E-04. Sample per second: 438425\n",
      "FUNK_SVD: Epoch 276 of 300. Elapsed time 7.18 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.81 sec. MSE loss 9.98E-04. Sample per second: 548627\n",
      "FUNK_SVD: Epoch 277 of 300. Elapsed time 7.21 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.36 sec. MSE loss 9.95E-04. Sample per second: 421215\n",
      "FUNK_SVD: Epoch 278 of 300. Elapsed time 7.24 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.90 sec. MSE loss 9.95E-04. Sample per second: 524334\n",
      "FUNK_SVD: Epoch 279 of 300. Elapsed time 7.26 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.45 sec. MSE loss 9.98E-04. Sample per second: 406087\n",
      "FUNK_SVD: Epoch 280 of 300. Elapsed time 7.29 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.98 sec. MSE loss 9.97E-04. Sample per second: 502585\n",
      "FUNK_SVD: Epoch 281 of 300. Elapsed time 7.31 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.50 sec. MSE loss 9.99E-04. Sample per second: 397846\n",
      "FUNK_SVD: Epoch 282 of 300. Elapsed time 7.34 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.04 sec. MSE loss 9.97E-04. Sample per second: 487417\n",
      "FUNK_SVD: Epoch 283 of 300. Elapsed time 7.36 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.58 sec. MSE loss 9.99E-04. Sample per second: 631283\n",
      "FUNK_SVD: Epoch 284 of 300. Elapsed time 7.39 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.13 sec. MSE loss 9.95E-04. Sample per second: 467824\n",
      "FUNK_SVD: Epoch 285 of 300. Elapsed time 7.41 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.67 sec. MSE loss 9.95E-04. Sample per second: 594026\n",
      "FUNK_SVD: Epoch 286 of 300. Elapsed time 7.44 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.20 sec. MSE loss 9.95E-04. Sample per second: 452403\n",
      "FUNK_SVD: Epoch 287 of 300. Elapsed time 7.47 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.71 sec. MSE loss 9.93E-04. Sample per second: 580841\n",
      "FUNK_SVD: Epoch 288 of 300. Elapsed time 7.49 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.23 sec. MSE loss 9.93E-04. Sample per second: 446244\n",
      "FUNK_SVD: Epoch 289 of 300. Elapsed time 7.52 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.74 sec. MSE loss 9.98E-04. Sample per second: 570162\n",
      "FUNK_SVD: Epoch 290 of 300. Elapsed time 7.54 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.32 sec. MSE loss 9.93E-04. Sample per second: 428269\n",
      "FUNK_SVD: Epoch 291 of 300. Elapsed time 7.57 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.95 sec. MSE loss 9.95E-04. Sample per second: 511308\n",
      "FUNK_SVD: Epoch 292 of 300. Elapsed time 7.60 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.56 sec. MSE loss 9.97E-04. Sample per second: 388714\n",
      "FUNK_SVD: Epoch 293 of 300. Elapsed time 7.62 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.20 sec. MSE loss 9.97E-04. Sample per second: 452246\n",
      "FUNK_SVD: Epoch 294 of 300. Elapsed time 7.65 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.75 sec. MSE loss 9.96E-04. Sample per second: 567554\n",
      "FUNK_SVD: Epoch 295 of 300. Elapsed time 7.68 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.34 sec. MSE loss 9.95E-04. Sample per second: 425328\n",
      "FUNK_SVD: Epoch 296 of 300. Elapsed time 7.70 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.91 sec. MSE loss 9.93E-04. Sample per second: 521110\n",
      "FUNK_SVD: Epoch 297 of 300. Elapsed time 7.73 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.45 sec. MSE loss 9.93E-04. Sample per second: 405393\n",
      "FUNK_SVD: Epoch 298 of 300. Elapsed time 7.75 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 2.04 sec. MSE loss 9.97E-04. Sample per second: 487859\n",
      "FUNK_SVD: Epoch 299 of 300. Elapsed time 7.78 min\n",
      "FUNK_SVD: Processed 995000 (100.0%) in 1.60 sec. MSE loss 9.97E-04. Sample per second: 620325\n",
      "FUNK_SVD: Epoch 300 of 300. Elapsed time 7.81 min\n",
      "FUNK_SVD: Terminating at epoch 300. Elapsed time 7.81 min\n",
      "SLIM_BPR_Recommender: Automatic selection of fastest train mode. Available RAM is 30616.00 MB (95.35%) of 32110.00 MB, required is 2402.37 MB. Using dense matrix.\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 2.96E-07. Sample per second: 42392\n",
      "SLIM_BPR_Recommender: Epoch 1 of 300. Elapsed time 0.17 sec\n",
      "Processed 41629 (100.0%) in 1.15 sec. BPR loss is 9.51E-07. Sample per second: 36165\n",
      "SLIM_BPR_Recommender: Epoch 2 of 300. Elapsed time 0.34 sec\n",
      "Processed 41629 (100.0%) in 0.32 sec. BPR loss is 1.58E-06. Sample per second: 131905\n",
      "SLIM_BPR_Recommender: Epoch 3 of 300. Elapsed time 0.50 sec\n",
      "Processed 41629 (100.0%) in 0.48 sec. BPR loss is 2.25E-06. Sample per second: 85937\n",
      "SLIM_BPR_Recommender: Epoch 4 of 300. Elapsed time 0.67 sec\n",
      "Processed 41629 (100.0%) in 0.65 sec. BPR loss is 2.99E-06. Sample per second: 63855\n",
      "SLIM_BPR_Recommender: Epoch 5 of 300. Elapsed time 0.84 sec\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 3.52E-06. Sample per second: 50631\n",
      "SLIM_BPR_Recommender: Epoch 6 of 300. Elapsed time 1.01 sec\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 4.20E-06. Sample per second: 41967\n",
      "SLIM_BPR_Recommender: Epoch 7 of 300. Elapsed time 1.18 sec\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 5.02E-06. Sample per second: 35906\n",
      "SLIM_BPR_Recommender: Epoch 8 of 300. Elapsed time 1.35 sec\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 5.51E-06. Sample per second: 127379\n",
      "SLIM_BPR_Recommender: Epoch 9 of 300. Elapsed time 1.51 sec\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 6.47E-06. Sample per second: 84570\n",
      "SLIM_BPR_Recommender: Epoch 10 of 300. Elapsed time 1.68 sec\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 7.10E-06. Sample per second: 63143\n",
      "SLIM_BPR_Recommender: Epoch 11 of 300. Elapsed time 1.85 sec\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 7.65E-06. Sample per second: 50428\n",
      "SLIM_BPR_Recommender: Epoch 12 of 300. Elapsed time 2.01 sec\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 8.06E-06. Sample per second: 41938\n",
      "SLIM_BPR_Recommender: Epoch 13 of 300. Elapsed time 2.18 sec\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 9.07E-06. Sample per second: 35737\n",
      "SLIM_BPR_Recommender: Epoch 14 of 300. Elapsed time 2.35 sec\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 9.71E-06. Sample per second: 124936\n",
      "SLIM_BPR_Recommender: Epoch 15 of 300. Elapsed time 2.52 sec\n",
      "Processed 41629 (100.0%) in 0.50 sec. BPR loss is 1.07E-05. Sample per second: 83336\n",
      "SLIM_BPR_Recommender: Epoch 16 of 300. Elapsed time 2.69 sec\n",
      "Processed 41629 (100.0%) in 0.67 sec. BPR loss is 1.10E-05. Sample per second: 62295\n",
      "SLIM_BPR_Recommender: Epoch 17 of 300. Elapsed time 2.86 sec\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 1.16E-05. Sample per second: 49556\n",
      "SLIM_BPR_Recommender: Epoch 18 of 300. Elapsed time 3.03 sec\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 1.25E-05. Sample per second: 41185\n",
      "SLIM_BPR_Recommender: Epoch 19 of 300. Elapsed time 3.20 sec\n",
      "Processed 41629 (100.0%) in 0.18 sec. BPR loss is 1.30E-05. Sample per second: 226695\n",
      "SLIM_BPR_Recommender: Epoch 20 of 300. Elapsed time 3.37 sec\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 1.38E-05. Sample per second: 116085\n",
      "SLIM_BPR_Recommender: Epoch 21 of 300. Elapsed time 3.55 sec\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 1.44E-05. Sample per second: 77921\n",
      "SLIM_BPR_Recommender: Epoch 22 of 300. Elapsed time 3.72 sec\n",
      "Processed 41629 (100.0%) in 0.70 sec. BPR loss is 1.49E-05. Sample per second: 59218\n",
      "SLIM_BPR_Recommender: Epoch 23 of 300. Elapsed time 3.89 sec\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 1.57E-05. Sample per second: 47612\n",
      "SLIM_BPR_Recommender: Epoch 24 of 300. Elapsed time 4.06 sec\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 1.73E-05. Sample per second: 39340\n",
      "SLIM_BPR_Recommender: Epoch 25 of 300. Elapsed time 4.24 sec\n",
      "Processed 41629 (100.0%) in 0.24 sec. BPR loss is 1.76E-05. Sample per second: 171066\n",
      "SLIM_BPR_Recommender: Epoch 26 of 300. Elapsed time 4.43 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 1.75E-05. Sample per second: 97375\n",
      "SLIM_BPR_Recommender: Epoch 27 of 300. Elapsed time 4.61 sec\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 1.84E-05. Sample per second: 69875\n",
      "SLIM_BPR_Recommender: Epoch 28 of 300. Elapsed time 4.78 sec\n",
      "Processed 41629 (100.0%) in 0.77 sec. BPR loss is 1.96E-05. Sample per second: 54335\n",
      "SLIM_BPR_Recommender: Epoch 29 of 300. Elapsed time 4.95 sec\n",
      "Processed 41629 (100.0%) in 0.94 sec. BPR loss is 1.97E-05. Sample per second: 44183\n",
      "SLIM_BPR_Recommender: Epoch 30 of 300. Elapsed time 5.13 sec\n",
      "Processed 41629 (100.0%) in 1.12 sec. BPR loss is 2.09E-05. Sample per second: 37321\n",
      "SLIM_BPR_Recommender: Epoch 31 of 300. Elapsed time 5.30 sec\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 2.17E-05. Sample per second: 144228\n",
      "SLIM_BPR_Recommender: Epoch 32 of 300. Elapsed time 5.48 sec\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 2.21E-05. Sample per second: 90571\n",
      "SLIM_BPR_Recommender: Epoch 33 of 300. Elapsed time 5.65 sec\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 2.30E-05. Sample per second: 66345\n",
      "SLIM_BPR_Recommender: Epoch 34 of 300. Elapsed time 5.81 sec\n",
      "Processed 41629 (100.0%) in 0.80 sec. BPR loss is 2.46E-05. Sample per second: 52054\n",
      "SLIM_BPR_Recommender: Epoch 35 of 300. Elapsed time 5.99 sec\n",
      "Processed 41629 (100.0%) in 0.97 sec. BPR loss is 2.47E-05. Sample per second: 42732\n",
      "SLIM_BPR_Recommender: Epoch 36 of 300. Elapsed time 6.16 sec\n",
      "Processed 41629 (100.0%) in 1.15 sec. BPR loss is 2.49E-05. Sample per second: 36306\n",
      "SLIM_BPR_Recommender: Epoch 37 of 300. Elapsed time 6.33 sec\n",
      "Processed 41629 (100.0%) in 0.32 sec. BPR loss is 2.62E-05. Sample per second: 129720\n",
      "SLIM_BPR_Recommender: Epoch 38 of 300. Elapsed time 6.51 sec\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 2.80E-05. Sample per second: 85320\n",
      "SLIM_BPR_Recommender: Epoch 39 of 300. Elapsed time 6.67 sec\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 2.64E-05. Sample per second: 63490\n",
      "SLIM_BPR_Recommender: Epoch 40 of 300. Elapsed time 6.84 sec\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 2.90E-05. Sample per second: 50181\n",
      "SLIM_BPR_Recommender: Epoch 41 of 300. Elapsed time 7.02 sec\n",
      "Processed 41629 (100.0%) in 1.00 sec. BPR loss is 2.87E-05. Sample per second: 41655\n",
      "SLIM_BPR_Recommender: Epoch 42 of 300. Elapsed time 7.19 sec\n",
      "Processed 41629 (100.0%) in 0.17 sec. BPR loss is 3.01E-05. Sample per second: 248426\n",
      "SLIM_BPR_Recommender: Epoch 43 of 300. Elapsed time 7.36 sec\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 2.80E-05. Sample per second: 121987\n",
      "SLIM_BPR_Recommender: Epoch 44 of 300. Elapsed time 7.53 sec\n",
      "Processed 41629 (100.0%) in 0.51 sec. BPR loss is 3.06E-05. Sample per second: 81736\n",
      "SLIM_BPR_Recommender: Epoch 45 of 300. Elapsed time 7.70 sec\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 3.21E-05. Sample per second: 60701\n",
      "SLIM_BPR_Recommender: Epoch 46 of 300. Elapsed time 7.87 sec\n",
      "Processed 41629 (100.0%) in 0.88 sec. BPR loss is 3.26E-05. Sample per second: 47081\n",
      "SLIM_BPR_Recommender: Epoch 47 of 300. Elapsed time 8.07 sec\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 3.34E-05. Sample per second: 39518\n",
      "SLIM_BPR_Recommender: Epoch 48 of 300. Elapsed time 8.24 sec\n",
      "Processed 41629 (100.0%) in 0.23 sec. BPR loss is 3.23E-05. Sample per second: 184133\n",
      "SLIM_BPR_Recommender: Epoch 49 of 300. Elapsed time 8.41 sec\n",
      "Processed 41629 (100.0%) in 0.39 sec. BPR loss is 3.24E-05. Sample per second: 106092\n",
      "SLIM_BPR_Recommender: Epoch 50 of 300. Elapsed time 8.58 sec\n",
      "Processed 41629 (100.0%) in 0.56 sec. BPR loss is 3.54E-05. Sample per second: 74125\n",
      "SLIM_BPR_Recommender: Epoch 51 of 300. Elapsed time 8.75 sec\n",
      "Processed 41629 (100.0%) in 0.73 sec. BPR loss is 3.56E-05. Sample per second: 56668\n",
      "SLIM_BPR_Recommender: Epoch 52 of 300. Elapsed time 8.92 sec\n",
      "Processed 41629 (100.0%) in 0.91 sec. BPR loss is 3.70E-05. Sample per second: 45919\n",
      "SLIM_BPR_Recommender: Epoch 53 of 300. Elapsed time 9.09 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 3.69E-05. Sample per second: 38890\n",
      "SLIM_BPR_Recommender: Epoch 54 of 300. Elapsed time 9.26 sec\n",
      "Processed 41629 (100.0%) in 0.23 sec. BPR loss is 3.77E-05. Sample per second: 177008\n",
      "SLIM_BPR_Recommender: Epoch 55 of 300. Elapsed time 9.42 sec\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 3.89E-05. Sample per second: 104774\n",
      "SLIM_BPR_Recommender: Epoch 56 of 300. Elapsed time 9.58 sec\n",
      "Processed 41629 (100.0%) in 0.56 sec. BPR loss is 3.93E-05. Sample per second: 74219\n",
      "SLIM_BPR_Recommender: Epoch 57 of 300. Elapsed time 9.75 sec\n",
      "Processed 41629 (100.0%) in 0.73 sec. BPR loss is 3.95E-05. Sample per second: 57001\n",
      "SLIM_BPR_Recommender: Epoch 58 of 300. Elapsed time 9.92 sec\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 4.00E-05. Sample per second: 46133\n",
      "SLIM_BPR_Recommender: Epoch 59 of 300. Elapsed time 10.09 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 3.99E-05. Sample per second: 38787\n",
      "SLIM_BPR_Recommender: Epoch 60 of 300. Elapsed time 10.26 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 4.27E-05. Sample per second: 164974\n",
      "SLIM_BPR_Recommender: Epoch 61 of 300. Elapsed time 10.44 sec\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 4.15E-05. Sample per second: 98398\n",
      "SLIM_BPR_Recommender: Epoch 62 of 300. Elapsed time 10.61 sec\n",
      "Processed 41629 (100.0%) in 0.59 sec. BPR loss is 4.26E-05. Sample per second: 70801\n",
      "SLIM_BPR_Recommender: Epoch 63 of 300. Elapsed time 10.77 sec\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 4.49E-05. Sample per second: 54874\n",
      "SLIM_BPR_Recommender: Epoch 64 of 300. Elapsed time 10.95 sec\n",
      "Processed 41629 (100.0%) in 0.93 sec. BPR loss is 4.22E-05. Sample per second: 44844\n",
      "SLIM_BPR_Recommender: Epoch 65 of 300. Elapsed time 11.12 sec\n",
      "Processed 41629 (100.0%) in 1.10 sec. BPR loss is 4.52E-05. Sample per second: 37892\n",
      "SLIM_BPR_Recommender: Epoch 66 of 300. Elapsed time 11.29 sec\n",
      "Processed 41629 (100.0%) in 0.27 sec. BPR loss is 4.71E-05. Sample per second: 153498\n",
      "SLIM_BPR_Recommender: Epoch 67 of 300. Elapsed time 11.46 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 4.91E-05. Sample per second: 96289\n",
      "SLIM_BPR_Recommender: Epoch 68 of 300. Elapsed time 11.62 sec\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 4.66E-05. Sample per second: 69516\n",
      "SLIM_BPR_Recommender: Epoch 69 of 300. Elapsed time 11.79 sec\n",
      "Processed 41629 (100.0%) in 0.77 sec. BPR loss is 4.86E-05. Sample per second: 53834\n",
      "SLIM_BPR_Recommender: Epoch 70 of 300. Elapsed time 11.96 sec\n",
      "Processed 41629 (100.0%) in 0.94 sec. BPR loss is 4.79E-05. Sample per second: 44175\n",
      "SLIM_BPR_Recommender: Epoch 71 of 300. Elapsed time 12.13 sec\n",
      "Processed 41629 (100.0%) in 1.11 sec. BPR loss is 5.32E-05. Sample per second: 37394\n",
      "SLIM_BPR_Recommender: Epoch 72 of 300. Elapsed time 12.30 sec\n",
      "Processed 41629 (100.0%) in 0.28 sec. BPR loss is 5.08E-05. Sample per second: 146179\n",
      "SLIM_BPR_Recommender: Epoch 73 of 300. Elapsed time 12.47 sec\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 5.04E-05. Sample per second: 91897\n",
      "SLIM_BPR_Recommender: Epoch 74 of 300. Elapsed time 12.64 sec\n",
      "Processed 41629 (100.0%) in 0.62 sec. BPR loss is 5.10E-05. Sample per second: 67446\n",
      "SLIM_BPR_Recommender: Epoch 75 of 300. Elapsed time 12.80 sec\n",
      "Processed 41629 (100.0%) in 0.78 sec. BPR loss is 5.06E-05. Sample per second: 53182\n",
      "SLIM_BPR_Recommender: Epoch 76 of 300. Elapsed time 12.97 sec\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 5.56E-05. Sample per second: 43768\n",
      "SLIM_BPR_Recommender: Epoch 77 of 300. Elapsed time 13.14 sec\n",
      "Processed 41629 (100.0%) in 1.12 sec. BPR loss is 5.54E-05. Sample per second: 37144\n",
      "SLIM_BPR_Recommender: Epoch 78 of 300. Elapsed time 13.31 sec\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 5.41E-05. Sample per second: 145553\n",
      "SLIM_BPR_Recommender: Epoch 79 of 300. Elapsed time 13.47 sec\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 5.56E-05. Sample per second: 91954\n",
      "SLIM_BPR_Recommender: Epoch 80 of 300. Elapsed time 13.64 sec\n",
      "Processed 41629 (100.0%) in 0.62 sec. BPR loss is 5.20E-05. Sample per second: 67036\n",
      "SLIM_BPR_Recommender: Epoch 81 of 300. Elapsed time 13.81 sec\n",
      "Processed 41629 (100.0%) in 0.79 sec. BPR loss is 5.64E-05. Sample per second: 52693\n",
      "SLIM_BPR_Recommender: Epoch 82 of 300. Elapsed time 13.98 sec\n",
      "Processed 41629 (100.0%) in 0.96 sec. BPR loss is 5.57E-05. Sample per second: 43333\n",
      "SLIM_BPR_Recommender: Epoch 83 of 300. Elapsed time 14.15 sec\n",
      "Processed 41629 (100.0%) in 1.13 sec. BPR loss is 5.85E-05. Sample per second: 36912\n",
      "SLIM_BPR_Recommender: Epoch 84 of 300. Elapsed time 14.31 sec\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 5.90E-05. Sample per second: 141459\n",
      "SLIM_BPR_Recommender: Epoch 85 of 300. Elapsed time 14.48 sec\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 6.00E-05. Sample per second: 90765\n",
      "SLIM_BPR_Recommender: Epoch 86 of 300. Elapsed time 14.65 sec\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 5.96E-05. Sample per second: 66253\n",
      "SLIM_BPR_Recommender: Epoch 87 of 300. Elapsed time 14.82 sec\n",
      "Processed 41629 (100.0%) in 0.79 sec. BPR loss is 5.99E-05. Sample per second: 52443\n",
      "SLIM_BPR_Recommender: Epoch 88 of 300. Elapsed time 14.98 sec\n",
      "Processed 41629 (100.0%) in 0.96 sec. BPR loss is 6.11E-05. Sample per second: 43298\n",
      "SLIM_BPR_Recommender: Epoch 89 of 300. Elapsed time 15.15 sec\n",
      "Processed 41629 (100.0%) in 1.13 sec. BPR loss is 6.26E-05. Sample per second: 36867\n",
      "SLIM_BPR_Recommender: Epoch 90 of 300. Elapsed time 15.32 sec\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 6.24E-05. Sample per second: 140031\n",
      "SLIM_BPR_Recommender: Epoch 91 of 300. Elapsed time 15.48 sec\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 6.23E-05. Sample per second: 89226\n",
      "SLIM_BPR_Recommender: Epoch 92 of 300. Elapsed time 15.65 sec\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 6.38E-05. Sample per second: 65526\n",
      "SLIM_BPR_Recommender: Epoch 93 of 300. Elapsed time 15.82 sec\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 6.44E-05. Sample per second: 51457\n",
      "SLIM_BPR_Recommender: Epoch 94 of 300. Elapsed time 16.00 sec\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 6.56E-05. Sample per second: 42531\n",
      "SLIM_BPR_Recommender: Epoch 95 of 300. Elapsed time 16.17 sec\n",
      "Processed 41629 (100.0%) in 1.15 sec. BPR loss is 6.24E-05. Sample per second: 36213\n",
      "SLIM_BPR_Recommender: Epoch 96 of 300. Elapsed time 16.34 sec\n",
      "Processed 41629 (100.0%) in 0.32 sec. BPR loss is 6.78E-05. Sample per second: 130664\n",
      "SLIM_BPR_Recommender: Epoch 97 of 300. Elapsed time 16.51 sec\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 6.49E-05. Sample per second: 85465\n",
      "SLIM_BPR_Recommender: Epoch 98 of 300. Elapsed time 16.67 sec\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 7.16E-05. Sample per second: 63414\n",
      "SLIM_BPR_Recommender: Epoch 99 of 300. Elapsed time 16.84 sec\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 6.78E-05. Sample per second: 50225\n",
      "SLIM_BPR_Recommender: Epoch 100 of 300. Elapsed time 17.02 sec\n",
      "Processed 41629 (100.0%) in 1.00 sec. BPR loss is 6.90E-05. Sample per second: 41653\n",
      "SLIM_BPR_Recommender: Epoch 101 of 300. Elapsed time 17.19 sec\n",
      "Processed 41629 (100.0%) in 0.17 sec. BPR loss is 6.75E-05. Sample per second: 244520\n",
      "SLIM_BPR_Recommender: Epoch 102 of 300. Elapsed time 17.36 sec\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 7.04E-05. Sample per second: 122163\n",
      "SLIM_BPR_Recommender: Epoch 103 of 300. Elapsed time 17.53 sec\n",
      "Processed 41629 (100.0%) in 0.51 sec. BPR loss is 6.96E-05. Sample per second: 81813\n",
      "SLIM_BPR_Recommender: Epoch 104 of 300. Elapsed time 17.70 sec\n",
      "Processed 41629 (100.0%) in 0.67 sec. BPR loss is 6.93E-05. Sample per second: 61677\n",
      "SLIM_BPR_Recommender: Epoch 105 of 300. Elapsed time 17.86 sec\n",
      "Processed 41629 (100.0%) in 0.85 sec. BPR loss is 7.28E-05. Sample per second: 48763\n",
      "SLIM_BPR_Recommender: Epoch 106 of 300. Elapsed time 18.04 sec\n",
      "Processed 41629 (100.0%) in 1.02 sec. BPR loss is 7.42E-05. Sample per second: 40690\n",
      "SLIM_BPR_Recommender: Epoch 107 of 300. Elapsed time 18.21 sec\n",
      "Processed 41629 (100.0%) in 0.19 sec. BPR loss is 7.78E-05. Sample per second: 218605\n",
      "SLIM_BPR_Recommender: Epoch 108 of 300. Elapsed time 18.38 sec\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 7.72E-05. Sample per second: 116314\n",
      "SLIM_BPR_Recommender: Epoch 109 of 300. Elapsed time 18.54 sec\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 7.71E-05. Sample per second: 79102\n",
      "SLIM_BPR_Recommender: Epoch 110 of 300. Elapsed time 18.71 sec\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 7.77E-05. Sample per second: 60113\n",
      "SLIM_BPR_Recommender: Epoch 111 of 300. Elapsed time 18.88 sec\n",
      "Processed 41629 (100.0%) in 0.88 sec. BPR loss is 7.75E-05. Sample per second: 47158\n",
      "SLIM_BPR_Recommender: Epoch 112 of 300. Elapsed time 19.07 sec\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 7.94E-05. Sample per second: 39664\n",
      "SLIM_BPR_Recommender: Epoch 113 of 300. Elapsed time 19.24 sec\n",
      "Processed 41629 (100.0%) in 0.22 sec. BPR loss is 7.83E-05. Sample per second: 193326\n",
      "SLIM_BPR_Recommender: Epoch 114 of 300. Elapsed time 19.40 sec\n",
      "Processed 41629 (100.0%) in 0.38 sec. BPR loss is 7.61E-05. Sample per second: 108729\n",
      "SLIM_BPR_Recommender: Epoch 115 of 300. Elapsed time 19.57 sec\n",
      "Processed 41629 (100.0%) in 0.55 sec. BPR loss is 7.88E-05. Sample per second: 75709\n",
      "SLIM_BPR_Recommender: Epoch 116 of 300. Elapsed time 19.74 sec\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 7.75E-05. Sample per second: 57871\n",
      "SLIM_BPR_Recommender: Epoch 117 of 300. Elapsed time 19.91 sec\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 7.71E-05. Sample per second: 46821\n",
      "SLIM_BPR_Recommender: Epoch 118 of 300. Elapsed time 20.08 sec\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 7.89E-05. Sample per second: 39395\n",
      "SLIM_BPR_Recommender: Epoch 119 of 300. Elapsed time 20.24 sec\n",
      "Processed 41629 (100.0%) in 0.22 sec. BPR loss is 8.62E-05. Sample per second: 185817\n",
      "SLIM_BPR_Recommender: Epoch 120 of 300. Elapsed time 20.41 sec\n",
      "Processed 41629 (100.0%) in 0.39 sec. BPR loss is 8.15E-05. Sample per second: 106748\n",
      "SLIM_BPR_Recommender: Epoch 121 of 300. Elapsed time 20.58 sec\n",
      "Processed 41629 (100.0%) in 0.56 sec. BPR loss is 8.48E-05. Sample per second: 74910\n",
      "SLIM_BPR_Recommender: Epoch 122 of 300. Elapsed time 20.74 sec\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 8.33E-05. Sample per second: 57596\n",
      "SLIM_BPR_Recommender: Epoch 123 of 300. Elapsed time 20.91 sec\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 8.77E-05. Sample per second: 46809\n",
      "SLIM_BPR_Recommender: Epoch 124 of 300. Elapsed time 21.08 sec\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 8.82E-05. Sample per second: 39417\n",
      "SLIM_BPR_Recommender: Epoch 125 of 300. Elapsed time 21.24 sec\n",
      "Processed 41629 (100.0%) in 0.22 sec. BPR loss is 8.59E-05. Sample per second: 187047\n",
      "SLIM_BPR_Recommender: Epoch 126 of 300. Elapsed time 21.41 sec\n",
      "Processed 41629 (100.0%) in 0.39 sec. BPR loss is 8.73E-05. Sample per second: 107969\n",
      "SLIM_BPR_Recommender: Epoch 127 of 300. Elapsed time 21.57 sec\n",
      "Processed 41629 (100.0%) in 0.55 sec. BPR loss is 8.48E-05. Sample per second: 75783\n",
      "SLIM_BPR_Recommender: Epoch 128 of 300. Elapsed time 21.74 sec\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 9.09E-05. Sample per second: 58107\n",
      "SLIM_BPR_Recommender: Epoch 129 of 300. Elapsed time 21.90 sec\n",
      "Processed 41629 (100.0%) in 0.88 sec. BPR loss is 9.24E-05. Sample per second: 47290\n",
      "SLIM_BPR_Recommender: Epoch 130 of 300. Elapsed time 22.07 sec\n",
      "Processed 41629 (100.0%) in 1.04 sec. BPR loss is 8.83E-05. Sample per second: 39937\n",
      "SLIM_BPR_Recommender: Epoch 131 of 300. Elapsed time 22.23 sec\n",
      "Processed 41629 (100.0%) in 0.20 sec. BPR loss is 9.17E-05. Sample per second: 205164\n",
      "SLIM_BPR_Recommender: Epoch 132 of 300. Elapsed time 22.39 sec\n",
      "Processed 41629 (100.0%) in 0.37 sec. BPR loss is 9.26E-05. Sample per second: 113743\n",
      "SLIM_BPR_Recommender: Epoch 133 of 300. Elapsed time 22.55 sec\n",
      "Processed 41629 (100.0%) in 0.52 sec. BPR loss is 9.66E-05. Sample per second: 79317\n",
      "SLIM_BPR_Recommender: Epoch 134 of 300. Elapsed time 22.71 sec\n",
      "Processed 41629 (100.0%) in 0.68 sec. BPR loss is 9.65E-05. Sample per second: 60853\n",
      "SLIM_BPR_Recommender: Epoch 135 of 300. Elapsed time 22.87 sec\n",
      "Processed 41629 (100.0%) in 0.85 sec. BPR loss is 9.69E-05. Sample per second: 48859\n",
      "SLIM_BPR_Recommender: Epoch 136 of 300. Elapsed time 23.04 sec\n",
      "Processed 41629 (100.0%) in 1.02 sec. BPR loss is 9.26E-05. Sample per second: 40814\n",
      "SLIM_BPR_Recommender: Epoch 137 of 300. Elapsed time 23.21 sec\n",
      "Processed 41629 (100.0%) in 0.19 sec. BPR loss is 9.47E-05. Sample per second: 221023\n",
      "SLIM_BPR_Recommender: Epoch 138 of 300. Elapsed time 23.38 sec\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 9.33E-05. Sample per second: 117433\n",
      "SLIM_BPR_Recommender: Epoch 139 of 300. Elapsed time 23.54 sec\n",
      "Processed 41629 (100.0%) in 0.52 sec. BPR loss is 9.63E-05. Sample per second: 79752\n",
      "SLIM_BPR_Recommender: Epoch 140 of 300. Elapsed time 23.71 sec\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 9.77E-05. Sample per second: 60154\n",
      "SLIM_BPR_Recommender: Epoch 141 of 300. Elapsed time 23.88 sec\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 9.32E-05. Sample per second: 48659\n",
      "SLIM_BPR_Recommender: Epoch 142 of 300. Elapsed time 24.04 sec\n",
      "Processed 41629 (100.0%) in 1.02 sec. BPR loss is 9.71E-05. Sample per second: 40809\n",
      "SLIM_BPR_Recommender: Epoch 143 of 300. Elapsed time 24.21 sec\n",
      "Processed 41629 (100.0%) in 0.18 sec. BPR loss is 1.02E-04. Sample per second: 228331\n",
      "SLIM_BPR_Recommender: Epoch 144 of 300. Elapsed time 24.37 sec\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 9.83E-05. Sample per second: 121196\n",
      "SLIM_BPR_Recommender: Epoch 145 of 300. Elapsed time 24.53 sec\n",
      "Processed 41629 (100.0%) in 0.50 sec. BPR loss is 1.03E-04. Sample per second: 82428\n",
      "SLIM_BPR_Recommender: Epoch 146 of 300. Elapsed time 24.69 sec\n",
      "Processed 41629 (100.0%) in 0.67 sec. BPR loss is 1.00E-04. Sample per second: 62402\n",
      "SLIM_BPR_Recommender: Epoch 147 of 300. Elapsed time 24.85 sec\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 1.03E-04. Sample per second: 50210\n",
      "SLIM_BPR_Recommender: Epoch 148 of 300. Elapsed time 25.02 sec\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 1.03E-04. Sample per second: 41966\n",
      "SLIM_BPR_Recommender: Epoch 149 of 300. Elapsed time 25.18 sec\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 1.02E-04. Sample per second: 35996\n",
      "SLIM_BPR_Recommender: Epoch 150 of 300. Elapsed time 25.34 sec\n",
      "Processed 41629 (100.0%) in 0.32 sec. BPR loss is 1.08E-04. Sample per second: 128819\n",
      "SLIM_BPR_Recommender: Epoch 151 of 300. Elapsed time 25.51 sec\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 1.06E-04. Sample per second: 85532\n",
      "SLIM_BPR_Recommender: Epoch 152 of 300. Elapsed time 25.67 sec\n",
      "Processed 41629 (100.0%) in 0.65 sec. BPR loss is 1.03E-04. Sample per second: 63780\n",
      "SLIM_BPR_Recommender: Epoch 153 of 300. Elapsed time 25.84 sec\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 1.04E-04. Sample per second: 50890\n",
      "SLIM_BPR_Recommender: Epoch 154 of 300. Elapsed time 26.00 sec\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 1.05E-04. Sample per second: 42384\n",
      "SLIM_BPR_Recommender: Epoch 155 of 300. Elapsed time 26.17 sec\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 1.07E-04. Sample per second: 36377\n",
      "SLIM_BPR_Recommender: Epoch 156 of 300. Elapsed time 26.33 sec\n",
      "Processed 41629 (100.0%) in 0.31 sec. BPR loss is 1.07E-04. Sample per second: 135306\n",
      "SLIM_BPR_Recommender: Epoch 157 of 300. Elapsed time 26.49 sec\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 1.02E-04. Sample per second: 88573\n",
      "SLIM_BPR_Recommender: Epoch 158 of 300. Elapsed time 26.66 sec\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 1.12E-04. Sample per second: 66011\n",
      "SLIM_BPR_Recommender: Epoch 159 of 300. Elapsed time 26.82 sec\n",
      "Processed 41629 (100.0%) in 0.79 sec. BPR loss is 1.07E-04. Sample per second: 52498\n",
      "SLIM_BPR_Recommender: Epoch 160 of 300. Elapsed time 26.98 sec\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 1.10E-04. Sample per second: 43693\n",
      "SLIM_BPR_Recommender: Epoch 161 of 300. Elapsed time 27.14 sec\n",
      "Processed 41629 (100.0%) in 1.11 sec. BPR loss is 1.12E-04. Sample per second: 37416\n",
      "SLIM_BPR_Recommender: Epoch 162 of 300. Elapsed time 27.30 sec\n",
      "Processed 41629 (100.0%) in 0.27 sec. BPR loss is 1.13E-04. Sample per second: 153333\n",
      "SLIM_BPR_Recommender: Epoch 163 of 300. Elapsed time 27.46 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 1.13E-04. Sample per second: 96372\n",
      "SLIM_BPR_Recommender: Epoch 164 of 300. Elapsed time 27.62 sec\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 1.09E-04. Sample per second: 69704\n",
      "SLIM_BPR_Recommender: Epoch 165 of 300. Elapsed time 27.79 sec\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 1.20E-04. Sample per second: 54423\n",
      "SLIM_BPR_Recommender: Epoch 166 of 300. Elapsed time 27.95 sec\n",
      "Processed 41629 (100.0%) in 0.93 sec. BPR loss is 1.18E-04. Sample per second: 44884\n",
      "SLIM_BPR_Recommender: Epoch 167 of 300. Elapsed time 28.11 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 1.09E-04. Sample per second: 38299\n",
      "SLIM_BPR_Recommender: Epoch 168 of 300. Elapsed time 28.27 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 1.21E-04. Sample per second: 165991\n",
      "SLIM_BPR_Recommender: Epoch 169 of 300. Elapsed time 28.44 sec\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 1.21E-04. Sample per second: 99803\n",
      "SLIM_BPR_Recommender: Epoch 170 of 300. Elapsed time 28.60 sec\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 1.17E-04. Sample per second: 71579\n",
      "SLIM_BPR_Recommender: Epoch 171 of 300. Elapsed time 28.77 sec\n",
      "Processed 41629 (100.0%) in 0.74 sec. BPR loss is 1.12E-04. Sample per second: 55950\n",
      "SLIM_BPR_Recommender: Epoch 172 of 300. Elapsed time 28.93 sec\n",
      "Processed 41629 (100.0%) in 0.91 sec. BPR loss is 1.18E-04. Sample per second: 45800\n",
      "SLIM_BPR_Recommender: Epoch 173 of 300. Elapsed time 29.10 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 1.17E-04. Sample per second: 38772\n",
      "SLIM_BPR_Recommender: Epoch 174 of 300. Elapsed time 29.26 sec\n",
      "Processed 41629 (100.0%) in 0.24 sec. BPR loss is 1.21E-04. Sample per second: 174410\n",
      "SLIM_BPR_Recommender: Epoch 175 of 300. Elapsed time 29.43 sec\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 1.24E-04. Sample per second: 103089\n",
      "SLIM_BPR_Recommender: Epoch 176 of 300. Elapsed time 29.59 sec\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 1.23E-04. Sample per second: 73203\n",
      "SLIM_BPR_Recommender: Epoch 177 of 300. Elapsed time 29.76 sec\n",
      "Processed 41629 (100.0%) in 0.73 sec. BPR loss is 1.29E-04. Sample per second: 56862\n",
      "SLIM_BPR_Recommender: Epoch 178 of 300. Elapsed time 29.92 sec\n",
      "Processed 41629 (100.0%) in 0.93 sec. BPR loss is 1.20E-04. Sample per second: 44838\n",
      "SLIM_BPR_Recommender: Epoch 179 of 300. Elapsed time 30.12 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 1.24E-04. Sample per second: 38137\n",
      "SLIM_BPR_Recommender: Epoch 180 of 300. Elapsed time 30.28 sec\n",
      "Processed 41629 (100.0%) in 0.26 sec. BPR loss is 1.25E-04. Sample per second: 159173\n",
      "SLIM_BPR_Recommender: Epoch 181 of 300. Elapsed time 30.45 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 1.26E-04. Sample per second: 96766\n",
      "SLIM_BPR_Recommender: Epoch 182 of 300. Elapsed time 30.62 sec\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 1.23E-04. Sample per second: 69591\n",
      "SLIM_BPR_Recommender: Epoch 183 of 300. Elapsed time 30.79 sec\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 1.22E-04. Sample per second: 54431\n",
      "SLIM_BPR_Recommender: Epoch 184 of 300. Elapsed time 30.95 sec\n",
      "Processed 41629 (100.0%) in 0.93 sec. BPR loss is 1.28E-04. Sample per second: 44655\n",
      "SLIM_BPR_Recommender: Epoch 185 of 300. Elapsed time 31.12 sec\n",
      "Processed 41629 (100.0%) in 1.10 sec. BPR loss is 1.27E-04. Sample per second: 37901\n",
      "SLIM_BPR_Recommender: Epoch 186 of 300. Elapsed time 31.29 sec\n",
      "Processed 41629 (100.0%) in 0.26 sec. BPR loss is 1.27E-04. Sample per second: 158721\n",
      "SLIM_BPR_Recommender: Epoch 187 of 300. Elapsed time 31.45 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 1.32E-04. Sample per second: 97658\n",
      "SLIM_BPR_Recommender: Epoch 188 of 300. Elapsed time 31.61 sec\n",
      "Processed 41629 (100.0%) in 0.59 sec. BPR loss is 1.32E-04. Sample per second: 70773\n",
      "SLIM_BPR_Recommender: Epoch 189 of 300. Elapsed time 31.78 sec\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 1.32E-04. Sample per second: 55067\n",
      "SLIM_BPR_Recommender: Epoch 190 of 300. Elapsed time 31.94 sec\n",
      "Processed 41629 (100.0%) in 0.92 sec. BPR loss is 1.32E-04. Sample per second: 45111\n",
      "SLIM_BPR_Recommender: Epoch 191 of 300. Elapsed time 32.11 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 1.36E-04. Sample per second: 38215\n",
      "SLIM_BPR_Recommender: Epoch 192 of 300. Elapsed time 32.28 sec\n",
      "Processed 41629 (100.0%) in 0.26 sec. BPR loss is 1.38E-04. Sample per second: 160210\n",
      "SLIM_BPR_Recommender: Epoch 193 of 300. Elapsed time 32.45 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 1.34E-04. Sample per second: 96875\n",
      "SLIM_BPR_Recommender: Epoch 194 of 300. Elapsed time 32.62 sec\n",
      "Processed 41629 (100.0%) in 0.59 sec. BPR loss is 1.38E-04. Sample per second: 70117\n",
      "SLIM_BPR_Recommender: Epoch 195 of 300. Elapsed time 32.78 sec\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 1.36E-04. Sample per second: 54896\n",
      "SLIM_BPR_Recommender: Epoch 196 of 300. Elapsed time 32.95 sec\n",
      "Processed 41629 (100.0%) in 0.92 sec. BPR loss is 1.38E-04. Sample per second: 45037\n",
      "SLIM_BPR_Recommender: Epoch 197 of 300. Elapsed time 33.11 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 1.36E-04. Sample per second: 38323\n",
      "SLIM_BPR_Recommender: Epoch 198 of 300. Elapsed time 33.27 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 1.36E-04. Sample per second: 163326\n",
      "SLIM_BPR_Recommender: Epoch 199 of 300. Elapsed time 33.44 sec\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 1.40E-04. Sample per second: 98450\n",
      "SLIM_BPR_Recommender: Epoch 200 of 300. Elapsed time 33.61 sec\n",
      "Processed 41629 (100.0%) in 0.59 sec. BPR loss is 1.37E-04. Sample per second: 70758\n",
      "SLIM_BPR_Recommender: Epoch 201 of 300. Elapsed time 33.78 sec\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 1.36E-04. Sample per second: 55323\n",
      "SLIM_BPR_Recommender: Epoch 202 of 300. Elapsed time 33.94 sec\n",
      "Processed 41629 (100.0%) in 0.92 sec. BPR loss is 1.37E-04. Sample per second: 45472\n",
      "SLIM_BPR_Recommender: Epoch 203 of 300. Elapsed time 34.10 sec\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 1.38E-04. Sample per second: 38589\n",
      "SLIM_BPR_Recommender: Epoch 204 of 300. Elapsed time 34.27 sec\n",
      "Processed 41629 (100.0%) in 0.24 sec. BPR loss is 1.41E-04. Sample per second: 170785\n",
      "SLIM_BPR_Recommender: Epoch 205 of 300. Elapsed time 34.43 sec\n",
      "Processed 41629 (100.0%) in 0.41 sec. BPR loss is 1.47E-04. Sample per second: 102070\n",
      "SLIM_BPR_Recommender: Epoch 206 of 300. Elapsed time 34.59 sec\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 1.47E-04. Sample per second: 72159\n",
      "SLIM_BPR_Recommender: Epoch 207 of 300. Elapsed time 34.76 sec\n",
      "Processed 41629 (100.0%) in 0.74 sec. BPR loss is 1.44E-04. Sample per second: 55894\n",
      "SLIM_BPR_Recommender: Epoch 208 of 300. Elapsed time 34.93 sec\n",
      "Processed 41629 (100.0%) in 0.91 sec. BPR loss is 1.43E-04. Sample per second: 45771\n",
      "SLIM_BPR_Recommender: Epoch 209 of 300. Elapsed time 35.10 sec\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 1.46E-04. Sample per second: 38673\n",
      "SLIM_BPR_Recommender: Epoch 210 of 300. Elapsed time 35.26 sec\n",
      "Processed 41629 (100.0%) in 0.24 sec. BPR loss is 1.40E-04. Sample per second: 171877\n",
      "SLIM_BPR_Recommender: Epoch 211 of 300. Elapsed time 35.43 sec\n",
      "Processed 41629 (100.0%) in 0.41 sec. BPR loss is 1.52E-04. Sample per second: 101755\n",
      "SLIM_BPR_Recommender: Epoch 212 of 300. Elapsed time 35.60 sec\n",
      "Processed 41629 (100.0%) in 0.59 sec. BPR loss is 1.50E-04. Sample per second: 70694\n",
      "SLIM_BPR_Recommender: Epoch 213 of 300. Elapsed time 35.78 sec\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 1.53E-04. Sample per second: 54616\n",
      "SLIM_BPR_Recommender: Epoch 214 of 300. Elapsed time 35.95 sec\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 1.46E-04. Sample per second: 43768\n",
      "SLIM_BPR_Recommender: Epoch 215 of 300. Elapsed time 36.14 sec\n",
      "Processed 41629 (100.0%) in 1.12 sec. BPR loss is 1.45E-04. Sample per second: 37237\n",
      "SLIM_BPR_Recommender: Epoch 216 of 300. Elapsed time 36.30 sec\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 1.51E-04. Sample per second: 141196\n",
      "SLIM_BPR_Recommender: Epoch 217 of 300. Elapsed time 36.48 sec\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 1.50E-04. Sample per second: 88362\n",
      "SLIM_BPR_Recommender: Epoch 218 of 300. Elapsed time 36.66 sec\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 1.54E-04. Sample per second: 64953\n",
      "SLIM_BPR_Recommender: Epoch 219 of 300. Elapsed time 36.83 sec\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 1.52E-04. Sample per second: 51269\n",
      "SLIM_BPR_Recommender: Epoch 220 of 300. Elapsed time 37.00 sec\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 1.54E-04. Sample per second: 42147\n",
      "SLIM_BPR_Recommender: Epoch 221 of 300. Elapsed time 37.17 sec\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 1.50E-04. Sample per second: 35991\n",
      "SLIM_BPR_Recommender: Epoch 222 of 300. Elapsed time 37.34 sec\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 1.56E-04. Sample per second: 127133\n",
      "SLIM_BPR_Recommender: Epoch 223 of 300. Elapsed time 37.51 sec\n",
      "Processed 41629 (100.0%) in 0.50 sec. BPR loss is 1.57E-04. Sample per second: 83584\n",
      "SLIM_BPR_Recommender: Epoch 224 of 300. Elapsed time 37.68 sec\n",
      "Processed 41629 (100.0%) in 0.67 sec. BPR loss is 1.50E-04. Sample per second: 62342\n",
      "SLIM_BPR_Recommender: Epoch 225 of 300. Elapsed time 37.86 sec\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 1.53E-04. Sample per second: 50036\n",
      "SLIM_BPR_Recommender: Epoch 226 of 300. Elapsed time 38.02 sec\n",
      "Processed 41629 (100.0%) in 1.00 sec. BPR loss is 1.60E-04. Sample per second: 41553\n",
      "SLIM_BPR_Recommender: Epoch 227 of 300. Elapsed time 38.19 sec\n",
      "Processed 41629 (100.0%) in 0.17 sec. BPR loss is 1.55E-04. Sample per second: 247472\n",
      "SLIM_BPR_Recommender: Epoch 228 of 300. Elapsed time 38.36 sec\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 1.62E-04. Sample per second: 123820\n",
      "SLIM_BPR_Recommender: Epoch 229 of 300. Elapsed time 38.52 sec\n",
      "Processed 41629 (100.0%) in 0.50 sec. BPR loss is 1.58E-04. Sample per second: 82652\n",
      "SLIM_BPR_Recommender: Epoch 230 of 300. Elapsed time 38.69 sec\n",
      "Processed 41629 (100.0%) in 0.67 sec. BPR loss is 1.58E-04. Sample per second: 61751\n",
      "SLIM_BPR_Recommender: Epoch 231 of 300. Elapsed time 38.86 sec\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 1.58E-04. Sample per second: 49526\n",
      "SLIM_BPR_Recommender: Epoch 232 of 300. Elapsed time 39.03 sec\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 1.59E-04. Sample per second: 41400\n",
      "SLIM_BPR_Recommender: Epoch 233 of 300. Elapsed time 39.19 sec\n",
      "Processed 41629 (100.0%) in 0.17 sec. BPR loss is 1.59E-04. Sample per second: 239295\n",
      "SLIM_BPR_Recommender: Epoch 234 of 300. Elapsed time 39.36 sec\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 1.61E-04. Sample per second: 122383\n",
      "SLIM_BPR_Recommender: Epoch 235 of 300. Elapsed time 39.53 sec\n",
      "Processed 41629 (100.0%) in 0.51 sec. BPR loss is 1.59E-04. Sample per second: 82213\n",
      "SLIM_BPR_Recommender: Epoch 236 of 300. Elapsed time 39.69 sec\n",
      "Processed 41629 (100.0%) in 0.67 sec. BPR loss is 1.58E-04. Sample per second: 62032\n",
      "SLIM_BPR_Recommender: Epoch 237 of 300. Elapsed time 39.86 sec\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 1.64E-04. Sample per second: 49492\n",
      "SLIM_BPR_Recommender: Epoch 238 of 300. Elapsed time 40.03 sec\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 1.78E-04. Sample per second: 41192\n",
      "SLIM_BPR_Recommender: Epoch 239 of 300. Elapsed time 40.20 sec\n",
      "Processed 41629 (100.0%) in 0.18 sec. BPR loss is 1.61E-04. Sample per second: 231491\n",
      "SLIM_BPR_Recommender: Epoch 240 of 300. Elapsed time 40.37 sec\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 1.63E-04. Sample per second: 118582\n",
      "SLIM_BPR_Recommender: Epoch 241 of 300. Elapsed time 40.54 sec\n",
      "Processed 41629 (100.0%) in 0.52 sec. BPR loss is 1.74E-04. Sample per second: 79624\n",
      "SLIM_BPR_Recommender: Epoch 242 of 300. Elapsed time 40.71 sec\n",
      "Processed 41629 (100.0%) in 0.70 sec. BPR loss is 1.70E-04. Sample per second: 59728\n",
      "SLIM_BPR_Recommender: Epoch 243 of 300. Elapsed time 40.88 sec\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 1.70E-04. Sample per second: 46793\n",
      "SLIM_BPR_Recommender: Epoch 244 of 300. Elapsed time 41.08 sec\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 1.69E-04. Sample per second: 39241\n",
      "SLIM_BPR_Recommender: Epoch 245 of 300. Elapsed time 41.25 sec\n",
      "Processed 41629 (100.0%) in 0.23 sec. BPR loss is 1.74E-04. Sample per second: 181195\n",
      "SLIM_BPR_Recommender: Epoch 246 of 300. Elapsed time 41.42 sec\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 1.68E-04. Sample per second: 105040\n",
      "SLIM_BPR_Recommender: Epoch 247 of 300. Elapsed time 41.58 sec\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 1.78E-04. Sample per second: 73612\n",
      "SLIM_BPR_Recommender: Epoch 248 of 300. Elapsed time 41.75 sec\n",
      "Processed 41629 (100.0%) in 0.73 sec. BPR loss is 1.70E-04. Sample per second: 56955\n",
      "SLIM_BPR_Recommender: Epoch 249 of 300. Elapsed time 41.92 sec\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 1.77E-04. Sample per second: 46304\n",
      "SLIM_BPR_Recommender: Epoch 250 of 300. Elapsed time 42.09 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 1.83E-04. Sample per second: 39024\n",
      "SLIM_BPR_Recommender: Epoch 251 of 300. Elapsed time 42.25 sec\n",
      "Processed 41629 (100.0%) in 0.23 sec. BPR loss is 1.76E-04. Sample per second: 179667\n",
      "SLIM_BPR_Recommender: Epoch 252 of 300. Elapsed time 42.42 sec\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 1.79E-04. Sample per second: 103581\n",
      "SLIM_BPR_Recommender: Epoch 253 of 300. Elapsed time 42.59 sec\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 1.72E-04. Sample per second: 72694\n",
      "SLIM_BPR_Recommender: Epoch 254 of 300. Elapsed time 42.76 sec\n",
      "Processed 41629 (100.0%) in 0.74 sec. BPR loss is 1.76E-04. Sample per second: 56070\n",
      "SLIM_BPR_Recommender: Epoch 255 of 300. Elapsed time 42.93 sec\n",
      "Processed 41629 (100.0%) in 0.91 sec. BPR loss is 1.76E-04. Sample per second: 45585\n",
      "SLIM_BPR_Recommender: Epoch 256 of 300. Elapsed time 43.10 sec\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 1.85E-04. Sample per second: 38496\n",
      "SLIM_BPR_Recommender: Epoch 257 of 300. Elapsed time 43.27 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 1.78E-04. Sample per second: 168105\n",
      "SLIM_BPR_Recommender: Epoch 258 of 300. Elapsed time 43.43 sec\n",
      "Processed 41629 (100.0%) in 0.41 sec. BPR loss is 1.87E-04. Sample per second: 100347\n",
      "SLIM_BPR_Recommender: Epoch 259 of 300. Elapsed time 43.60 sec\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 1.77E-04. Sample per second: 71492\n",
      "SLIM_BPR_Recommender: Epoch 260 of 300. Elapsed time 43.77 sec\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 1.71E-04. Sample per second: 55555\n",
      "SLIM_BPR_Recommender: Epoch 261 of 300. Elapsed time 43.94 sec\n",
      "Processed 41629 (100.0%) in 0.92 sec. BPR loss is 1.86E-04. Sample per second: 45441\n",
      "SLIM_BPR_Recommender: Epoch 262 of 300. Elapsed time 44.10 sec\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 1.77E-04. Sample per second: 38431\n",
      "SLIM_BPR_Recommender: Epoch 263 of 300. Elapsed time 44.27 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 1.85E-04. Sample per second: 166428\n",
      "SLIM_BPR_Recommender: Epoch 264 of 300. Elapsed time 44.44 sec\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 1.80E-04. Sample per second: 99771\n",
      "SLIM_BPR_Recommender: Epoch 265 of 300. Elapsed time 44.60 sec\n",
      "Processed 41629 (100.0%) in 0.59 sec. BPR loss is 1.84E-04. Sample per second: 70841\n",
      "SLIM_BPR_Recommender: Epoch 266 of 300. Elapsed time 44.77 sec\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 1.91E-04. Sample per second: 54976\n",
      "SLIM_BPR_Recommender: Epoch 267 of 300. Elapsed time 44.94 sec\n",
      "Processed 41629 (100.0%) in 0.92 sec. BPR loss is 1.81E-04. Sample per second: 45065\n",
      "SLIM_BPR_Recommender: Epoch 268 of 300. Elapsed time 45.11 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 1.89E-04. Sample per second: 38288\n",
      "SLIM_BPR_Recommender: Epoch 269 of 300. Elapsed time 45.27 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 1.83E-04. Sample per second: 165235\n",
      "SLIM_BPR_Recommender: Epoch 270 of 300. Elapsed time 45.44 sec\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 1.97E-04. Sample per second: 99649\n",
      "SLIM_BPR_Recommender: Epoch 271 of 300. Elapsed time 45.60 sec\n",
      "Processed 41629 (100.0%) in 0.59 sec. BPR loss is 1.79E-04. Sample per second: 70946\n",
      "SLIM_BPR_Recommender: Epoch 272 of 300. Elapsed time 45.77 sec\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 1.93E-04. Sample per second: 54975\n",
      "SLIM_BPR_Recommender: Epoch 273 of 300. Elapsed time 45.94 sec\n",
      "Processed 41629 (100.0%) in 0.93 sec. BPR loss is 1.95E-04. Sample per second: 44976\n",
      "SLIM_BPR_Recommender: Epoch 274 of 300. Elapsed time 46.11 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 1.88E-04. Sample per second: 38036\n",
      "SLIM_BPR_Recommender: Epoch 275 of 300. Elapsed time 46.28 sec\n",
      "Processed 41629 (100.0%) in 0.26 sec. BPR loss is 1.92E-04. Sample per second: 158034\n",
      "SLIM_BPR_Recommender: Epoch 276 of 300. Elapsed time 46.45 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 1.97E-04. Sample per second: 95889\n",
      "SLIM_BPR_Recommender: Epoch 277 of 300. Elapsed time 46.62 sec\n",
      "Processed 41629 (100.0%) in 0.61 sec. BPR loss is 1.97E-04. Sample per second: 68612\n",
      "SLIM_BPR_Recommender: Epoch 278 of 300. Elapsed time 46.79 sec\n",
      "Processed 41629 (100.0%) in 0.78 sec. BPR loss is 1.93E-04. Sample per second: 53228\n",
      "SLIM_BPR_Recommender: Epoch 279 of 300. Elapsed time 46.97 sec\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 1.98E-04. Sample per second: 43671\n",
      "SLIM_BPR_Recommender: Epoch 280 of 300. Elapsed time 47.14 sec\n",
      "Processed 41629 (100.0%) in 1.13 sec. BPR loss is 1.96E-04. Sample per second: 36883\n",
      "SLIM_BPR_Recommender: Epoch 281 of 300. Elapsed time 47.32 sec\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 1.90E-04. Sample per second: 138334\n",
      "SLIM_BPR_Recommender: Epoch 282 of 300. Elapsed time 47.49 sec\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 2.00E-04. Sample per second: 89403\n",
      "SLIM_BPR_Recommender: Epoch 283 of 300. Elapsed time 47.65 sec\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 1.89E-04. Sample per second: 65661\n",
      "SLIM_BPR_Recommender: Epoch 284 of 300. Elapsed time 47.82 sec\n",
      "Processed 41629 (100.0%) in 0.80 sec. BPR loss is 1.97E-04. Sample per second: 51968\n",
      "SLIM_BPR_Recommender: Epoch 285 of 300. Elapsed time 47.99 sec\n",
      "Processed 41629 (100.0%) in 0.97 sec. BPR loss is 1.96E-04. Sample per second: 42843\n",
      "SLIM_BPR_Recommender: Epoch 286 of 300. Elapsed time 48.16 sec\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 2.04E-04. Sample per second: 36387\n",
      "SLIM_BPR_Recommender: Epoch 287 of 300. Elapsed time 48.33 sec\n",
      "Processed 41629 (100.0%) in 0.31 sec. BPR loss is 2.05E-04. Sample per second: 133138\n",
      "SLIM_BPR_Recommender: Epoch 288 of 300. Elapsed time 48.50 sec\n",
      "Processed 41629 (100.0%) in 0.48 sec. BPR loss is 2.00E-04. Sample per second: 87174\n",
      "SLIM_BPR_Recommender: Epoch 289 of 300. Elapsed time 48.66 sec\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 2.05E-04. Sample per second: 64863\n",
      "SLIM_BPR_Recommender: Epoch 290 of 300. Elapsed time 48.83 sec\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 2.02E-04. Sample per second: 51274\n",
      "SLIM_BPR_Recommender: Epoch 291 of 300. Elapsed time 49.00 sec\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 2.05E-04. Sample per second: 42450\n",
      "SLIM_BPR_Recommender: Epoch 292 of 300. Elapsed time 49.17 sec\n",
      "Processed 41629 (100.0%) in 1.15 sec. BPR loss is 2.07E-04. Sample per second: 36244\n",
      "SLIM_BPR_Recommender: Epoch 293 of 300. Elapsed time 49.34 sec\n",
      "Processed 41629 (100.0%) in 0.31 sec. BPR loss is 1.99E-04. Sample per second: 133547\n",
      "SLIM_BPR_Recommender: Epoch 294 of 300. Elapsed time 49.50 sec\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 2.05E-04. Sample per second: 88009\n",
      "SLIM_BPR_Recommender: Epoch 295 of 300. Elapsed time 49.66 sec\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 2.08E-04. Sample per second: 65417\n",
      "SLIM_BPR_Recommender: Epoch 296 of 300. Elapsed time 49.82 sec\n",
      "Processed 41629 (100.0%) in 0.80 sec. BPR loss is 2.02E-04. Sample per second: 51837\n",
      "SLIM_BPR_Recommender: Epoch 297 of 300. Elapsed time 49.99 sec\n",
      "Processed 41629 (100.0%) in 0.96 sec. BPR loss is 2.14E-04. Sample per second: 43222\n",
      "SLIM_BPR_Recommender: Epoch 298 of 300. Elapsed time 50.15 sec\n",
      "Processed 41629 (100.0%) in 1.13 sec. BPR loss is 2.01E-04. Sample per second: 36837\n",
      "SLIM_BPR_Recommender: Epoch 299 of 300. Elapsed time 50.32 sec\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 2.04E-04. Sample per second: 141312\n",
      "SLIM_BPR_Recommender: Epoch 300 of 300. Elapsed time 50.48 sec\n",
      "SLIM_BPR_Recommender: Terminating at epoch 300. Elapsed time 1.20 min\n",
      "Deallocating Cython objects\n"
     ]
    }
   ],
   "source": [
    "from Recommenders.NonPersonalizedRecommender import TopPop\n",
    "from Recommenders.KNN.UserKNNCFRecommender import UserKNNCFRecommender\n",
    "from Recommenders.KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "from Recommenders.KNN.ItemKNNCBFRecommender import ItemKNNCBFRecommender\n",
    "from Recommenders.KNN import ItemKNN_CFCBF_Hybrid_Recommender\n",
    "from Recommenders.SLIM.Cython.SLIM_BPR_Cython import SLIM_BPR_Cython\n",
    "from Recommenders.GraphBased.P3alphaRecommender import P3alphaRecommender\n",
    "from Recommenders.GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "from Recommenders.MatrixFactorization.Cython.MatrixFactorization_Cython import MatrixFactorization_BPR_Cython, MatrixFactorization_FunkSVD_Cython, MatrixFactorization_AsySVD_Cython\n",
    "from Recommenders.MatrixFactorization.PureSVDRecommender import PureSVDRecommender\n",
    "from Recommenders.MatrixFactorization.IALSRecommender import IALSRecommender\n",
    "from Recommenders.MatrixFactorization.NMFRecommender import NMFRecommender\n",
    "\n",
    "MAP_recommender_per_group = {}\n",
    "\n",
    "collaborative_recommender_class = {\n",
    "                                   \"SLIMElasticNetRecommender\": SLIMElasticNetRecommender,\n",
    "                                   \"TopPop\": TopPop,\n",
    "                                   \"UserKNNCF\": UserKNNCFRecommender,\n",
    "                                   \"ItemKNNCF\": ItemKNNCFRecommender,\n",
    "                                   \"P3alpha\": P3alphaRecommender,\n",
    "                                   \"RP3beta\": RP3betaRecommender,\n",
    "                                   \"PureSVD\": PureSVDRecommender,\n",
    "                                   \"NMF\": NMFRecommender,\n",
    "                                   \"FunkSVD\": MatrixFactorization_FunkSVD_Cython,\n",
    "                                   \"SLIMBPR\": SLIM_BPR_Cython,\n",
    "                                   }\n",
    "\n",
    "content_recommender_class = {\"ItemKNNCBF\": ItemKNNCBFRecommender,\n",
    "                             \"ItemKNNCFCBF\": ItemKNN_CFCBF_Hybrid_Recommender\n",
    "                            }\n",
    "\n",
    "recommender_object_dict = {}\n",
    "\n",
    "for label, recommender_class in collaborative_recommender_class.items():\n",
    "    recommender_object = recommender_class(URM_train)\n",
    "    \n",
    "    if isinstance(recommender_object, SLIMElasticNetRecommender):\n",
    "        recommender_object.load_model(\"/kaggle/working\")\n",
    "    else:\n",
    "         recommender_object.fit()\n",
    "            \n",
    "    recommender_object_dict[label] = recommender_object\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eb0c114",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T23:17:00.931207Z",
     "iopub.status.busy": "2022-11-26T23:17:00.930766Z",
     "iopub.status.idle": "2022-11-26T23:26:46.521557Z",
     "shell.execute_reply": "2022-11-26T23:26:46.520325Z"
    },
    "papermill": {
     "duration": 585.677878,
     "end_time": "2022-11-26T23:26:46.524317",
     "exception": false,
     "start_time": "2022-11-26T23:17:00.846439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0, #users in group 2081, average p.len 7.31, median 8.0, min 2, max 9\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2050 (100.0%) in 2.52 sec. Users per second: 814\n",
      "EvaluatorHoldout: Processed 2050 (100.0%) in 2.74 sec. Users per second: 747\n",
      "EvaluatorHoldout: Processed 2050 (100.0%) in 2.33 sec. Users per second: 879\n",
      "EvaluatorHoldout: Processed 2050 (100.0%) in 2.39 sec. Users per second: 859\n",
      "EvaluatorHoldout: Processed 2050 (100.0%) in 2.24 sec. Users per second: 916\n",
      "EvaluatorHoldout: Processed 2050 (100.0%) in 2.24 sec. Users per second: 913\n",
      "EvaluatorHoldout: Processed 2050 (100.0%) in 2.83 sec. Users per second: 723\n",
      "EvaluatorHoldout: Processed 2050 (100.0%) in 4.66 sec. Users per second: 440\n",
      "EvaluatorHoldout: Processed 2050 (100.0%) in 2.87 sec. Users per second: 715\n",
      "EvaluatorHoldout: Processed 2050 (100.0%) in 2.35 sec. Users per second: 873\n",
      "Group 1, #users in group 2081, average p.len 9.64, median 10.0, min 9, max 10\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 2.61 sec. Users per second: 785\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 2.71 sec. Users per second: 755\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 2.27 sec. Users per second: 899\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 2.46 sec. Users per second: 831\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 2.24 sec. Users per second: 914\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 2.29 sec. Users per second: 893\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 2.83 sec. Users per second: 723\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 4.85 sec. Users per second: 422\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 2.87 sec. Users per second: 711\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 2.40 sec. Users per second: 851\n",
      "Group 2, #users in group 2081, average p.len 10.92, median 11.0, min 10, max 12\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2045 (100.0%) in 2.63 sec. Users per second: 778\n",
      "EvaluatorHoldout: Processed 2045 (100.0%) in 2.68 sec. Users per second: 762\n",
      "EvaluatorHoldout: Processed 2045 (100.0%) in 2.25 sec. Users per second: 908\n",
      "EvaluatorHoldout: Processed 2045 (100.0%) in 2.44 sec. Users per second: 837\n",
      "EvaluatorHoldout: Processed 2045 (100.0%) in 2.23 sec. Users per second: 916\n",
      "EvaluatorHoldout: Processed 2045 (100.0%) in 2.40 sec. Users per second: 853\n",
      "EvaluatorHoldout: Processed 2045 (100.0%) in 2.82 sec. Users per second: 725\n",
      "EvaluatorHoldout: Processed 2045 (100.0%) in 4.84 sec. Users per second: 423\n",
      "EvaluatorHoldout: Processed 2045 (100.0%) in 2.85 sec. Users per second: 716\n",
      "EvaluatorHoldout: Processed 2045 (100.0%) in 2.41 sec. Users per second: 847\n",
      "Group 3, #users in group 2081, average p.len 12.05, median 12.0, min 12, max 13\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2042 (100.0%) in 2.62 sec. Users per second: 781\n",
      "EvaluatorHoldout: Processed 2042 (100.0%) in 2.67 sec. Users per second: 765\n",
      "EvaluatorHoldout: Processed 2042 (100.0%) in 2.25 sec. Users per second: 906\n",
      "EvaluatorHoldout: Processed 2042 (100.0%) in 2.57 sec. Users per second: 796\n",
      "EvaluatorHoldout: Processed 2042 (100.0%) in 2.33 sec. Users per second: 876\n",
      "EvaluatorHoldout: Processed 2042 (100.0%) in 2.33 sec. Users per second: 878\n",
      "EvaluatorHoldout: Processed 2042 (100.0%) in 2.92 sec. Users per second: 700\n",
      "EvaluatorHoldout: Processed 2042 (100.0%) in 4.92 sec. Users per second: 415\n",
      "EvaluatorHoldout: Processed 2042 (100.0%) in 2.89 sec. Users per second: 707\n",
      "EvaluatorHoldout: Processed 2042 (100.0%) in 2.43 sec. Users per second: 841\n",
      "Group 4, #users in group 2081, average p.len 13.00, median 13.0, min 13, max 13\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2052 (100.0%) in 2.67 sec. Users per second: 768\n",
      "EvaluatorHoldout: Processed 2052 (100.0%) in 2.68 sec. Users per second: 766\n",
      "EvaluatorHoldout: Processed 2052 (100.0%) in 2.21 sec. Users per second: 927\n",
      "EvaluatorHoldout: Processed 2052 (100.0%) in 2.50 sec. Users per second: 821\n",
      "EvaluatorHoldout: Processed 2052 (100.0%) in 2.32 sec. Users per second: 885\n",
      "EvaluatorHoldout: Processed 2052 (100.0%) in 2.38 sec. Users per second: 863\n",
      "EvaluatorHoldout: Processed 2052 (100.0%) in 2.84 sec. Users per second: 723\n",
      "EvaluatorHoldout: Processed 2052 (100.0%) in 5.03 sec. Users per second: 408\n",
      "EvaluatorHoldout: Processed 2052 (100.0%) in 2.95 sec. Users per second: 696\n",
      "EvaluatorHoldout: Processed 2052 (100.0%) in 2.47 sec. Users per second: 832\n",
      "Group 5, #users in group 2081, average p.len 13.96, median 14.0, min 13, max 14\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 2.66 sec. Users per second: 768\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 2.67 sec. Users per second: 765\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 2.22 sec. Users per second: 919\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 2.53 sec. Users per second: 808\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 2.26 sec. Users per second: 906\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 2.35 sec. Users per second: 871\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 2.84 sec. Users per second: 720\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 4.91 sec. Users per second: 416\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 2.98 sec. Users per second: 686\n",
      "EvaluatorHoldout: Processed 2044 (100.0%) in 2.50 sec. Users per second: 816\n",
      "Group 6, #users in group 2081, average p.len 14.91, median 15.0, min 14, max 15\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2058 (100.0%) in 2.70 sec. Users per second: 762\n",
      "EvaluatorHoldout: Processed 2058 (100.0%) in 2.67 sec. Users per second: 772\n",
      "EvaluatorHoldout: Processed 2058 (100.0%) in 2.20 sec. Users per second: 936\n",
      "EvaluatorHoldout: Processed 2058 (100.0%) in 2.60 sec. Users per second: 791\n",
      "EvaluatorHoldout: Processed 2058 (100.0%) in 2.28 sec. Users per second: 901\n",
      "EvaluatorHoldout: Processed 2058 (100.0%) in 2.35 sec. Users per second: 877\n",
      "EvaluatorHoldout: Processed 2058 (100.0%) in 2.84 sec. Users per second: 725\n",
      "EvaluatorHoldout: Processed 2058 (100.0%) in 4.91 sec. Users per second: 419\n",
      "EvaluatorHoldout: Processed 2058 (100.0%) in 2.88 sec. Users per second: 714\n",
      "EvaluatorHoldout: Processed 2058 (100.0%) in 2.53 sec. Users per second: 812\n",
      "Group 7, #users in group 2081, average p.len 15.81, median 16.0, min 15, max 16\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 2.75 sec. Users per second: 750\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 2.75 sec. Users per second: 751\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 2.21 sec. Users per second: 934\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 2.63 sec. Users per second: 785\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 2.30 sec. Users per second: 895\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 2.41 sec. Users per second: 857\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 2.88 sec. Users per second: 717\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 4.90 sec. Users per second: 421\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 2.97 sec. Users per second: 693\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 2.52 sec. Users per second: 819\n",
      "Group 8, #users in group 2081, average p.len 16.81, median 17.0, min 16, max 17\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2060 (100.0%) in 2.82 sec. Users per second: 730\n",
      "EvaluatorHoldout: Processed 2060 (100.0%) in 2.70 sec. Users per second: 764\n",
      "EvaluatorHoldout: Processed 2060 (100.0%) in 2.21 sec. Users per second: 932\n",
      "EvaluatorHoldout: Processed 2060 (100.0%) in 2.67 sec. Users per second: 770\n",
      "EvaluatorHoldout: Processed 2060 (100.0%) in 2.30 sec. Users per second: 894\n",
      "EvaluatorHoldout: Processed 2060 (100.0%) in 2.40 sec. Users per second: 860\n",
      "EvaluatorHoldout: Processed 2060 (100.0%) in 2.87 sec. Users per second: 718\n",
      "EvaluatorHoldout: Processed 2060 (100.0%) in 4.97 sec. Users per second: 415\n",
      "EvaluatorHoldout: Processed 2060 (100.0%) in 2.88 sec. Users per second: 716\n",
      "EvaluatorHoldout: Processed 2060 (100.0%) in 2.50 sec. Users per second: 825\n",
      "Group 9, #users in group 2081, average p.len 17.83, median 18.0, min 17, max 18\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 2.88 sec. Users per second: 715\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 2.76 sec. Users per second: 748\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 2.26 sec. Users per second: 912\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 2.73 sec. Users per second: 756\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 2.29 sec. Users per second: 899\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 2.44 sec. Users per second: 844\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 2.85 sec. Users per second: 723\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 4.93 sec. Users per second: 419\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 2.90 sec. Users per second: 712\n",
      "EvaluatorHoldout: Processed 2062 (100.0%) in 2.56 sec. Users per second: 805\n",
      "Group 10, #users in group 2081, average p.len 19.07, median 19.0, min 18, max 20\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2070 (100.0%) in 2.82 sec. Users per second: 733\n",
      "EvaluatorHoldout: Processed 2070 (100.0%) in 2.73 sec. Users per second: 758\n",
      "EvaluatorHoldout: Processed 2070 (100.0%) in 2.26 sec. Users per second: 916\n",
      "EvaluatorHoldout: Processed 2070 (100.0%) in 2.91 sec. Users per second: 712\n",
      "EvaluatorHoldout: Processed 2070 (100.0%) in 2.32 sec. Users per second: 893\n",
      "EvaluatorHoldout: Processed 2070 (100.0%) in 2.46 sec. Users per second: 843\n",
      "EvaluatorHoldout: Processed 2070 (100.0%) in 2.89 sec. Users per second: 717\n",
      "EvaluatorHoldout: Processed 2070 (100.0%) in 5.06 sec. Users per second: 409\n",
      "EvaluatorHoldout: Processed 2070 (100.0%) in 2.89 sec. Users per second: 717\n",
      "EvaluatorHoldout: Processed 2070 (100.0%) in 2.59 sec. Users per second: 800\n",
      "Group 11, #users in group 2081, average p.len 20.40, median 20.0, min 20, max 21\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2073 (100.0%) in 2.96 sec. Users per second: 699\n",
      "EvaluatorHoldout: Processed 2073 (100.0%) in 2.72 sec. Users per second: 762\n",
      "EvaluatorHoldout: Processed 2073 (100.0%) in 2.27 sec. Users per second: 914\n",
      "EvaluatorHoldout: Processed 2073 (100.0%) in 2.93 sec. Users per second: 707\n",
      "EvaluatorHoldout: Processed 2073 (100.0%) in 2.40 sec. Users per second: 865\n",
      "EvaluatorHoldout: Processed 2073 (100.0%) in 2.50 sec. Users per second: 829\n",
      "EvaluatorHoldout: Processed 2073 (100.0%) in 2.87 sec. Users per second: 722\n",
      "EvaluatorHoldout: Processed 2073 (100.0%) in 4.99 sec. Users per second: 415\n",
      "EvaluatorHoldout: Processed 2073 (100.0%) in 2.89 sec. Users per second: 716\n",
      "EvaluatorHoldout: Processed 2073 (100.0%) in 2.57 sec. Users per second: 806\n",
      "Group 12, #users in group 2081, average p.len 21.93, median 22.0, min 21, max 23\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2079 (100.0%) in 2.90 sec. Users per second: 718\n",
      "EvaluatorHoldout: Processed 2079 (100.0%) in 2.72 sec. Users per second: 766\n",
      "EvaluatorHoldout: Processed 2079 (100.0%) in 2.27 sec. Users per second: 915\n",
      "EvaluatorHoldout: Processed 2079 (100.0%) in 2.89 sec. Users per second: 719\n",
      "EvaluatorHoldout: Processed 2079 (100.0%) in 2.39 sec. Users per second: 871\n",
      "EvaluatorHoldout: Processed 2079 (100.0%) in 2.53 sec. Users per second: 821\n",
      "EvaluatorHoldout: Processed 2079 (100.0%) in 2.93 sec. Users per second: 710\n",
      "EvaluatorHoldout: Processed 2079 (100.0%) in 4.96 sec. Users per second: 420\n",
      "EvaluatorHoldout: Processed 2079 (100.0%) in 2.91 sec. Users per second: 713\n",
      "EvaluatorHoldout: Processed 2079 (100.0%) in 2.61 sec. Users per second: 797\n",
      "Group 13, #users in group 2081, average p.len 23.76, median 24.0, min 23, max 25\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2078 (100.0%) in 2.96 sec. Users per second: 702\n",
      "EvaluatorHoldout: Processed 2078 (100.0%) in 2.69 sec. Users per second: 773\n",
      "EvaluatorHoldout: Processed 2078 (100.0%) in 2.35 sec. Users per second: 885\n",
      "EvaluatorHoldout: Processed 2078 (100.0%) in 2.98 sec. Users per second: 697\n",
      "EvaluatorHoldout: Processed 2078 (100.0%) in 2.34 sec. Users per second: 886\n",
      "EvaluatorHoldout: Processed 2078 (100.0%) in 2.52 sec. Users per second: 823\n",
      "EvaluatorHoldout: Processed 2078 (100.0%) in 2.88 sec. Users per second: 722\n",
      "EvaluatorHoldout: Processed 2078 (100.0%) in 5.00 sec. Users per second: 415\n",
      "EvaluatorHoldout: Processed 2078 (100.0%) in 2.91 sec. Users per second: 714\n",
      "EvaluatorHoldout: Processed 2078 (100.0%) in 2.66 sec. Users per second: 782\n",
      "Group 14, #users in group 2081, average p.len 25.99, median 26.0, min 25, max 27\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 3.01 sec. Users per second: 692\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 2.67 sec. Users per second: 780\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 2.33 sec. Users per second: 894\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 3.08 sec. Users per second: 676\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 2.35 sec. Users per second: 887\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 2.49 sec. Users per second: 836\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 3.04 sec. Users per second: 685\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 5.12 sec. Users per second: 407\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 2.99 sec. Users per second: 696\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 2.67 sec. Users per second: 780\n",
      "Group 15, #users in group 2081, average p.len 28.91, median 29.0, min 27, max 31\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 3.15 sec. Users per second: 660\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 2.71 sec. Users per second: 768\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 2.40 sec. Users per second: 868\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 3.14 sec. Users per second: 662\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 2.41 sec. Users per second: 863\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 2.57 sec. Users per second: 809\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 2.94 sec. Users per second: 707\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 4.96 sec. Users per second: 419\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 2.92 sec. Users per second: 713\n",
      "EvaluatorHoldout: Processed 2080 (100.0%) in 2.70 sec. Users per second: 770\n",
      "Group 16, #users in group 2081, average p.len 32.71, median 33.0, min 31, max 35\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 3.14 sec. Users per second: 662\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.80 sec. Users per second: 744\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.44 sec. Users per second: 851\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 3.24 sec. Users per second: 642\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.36 sec. Users per second: 883\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.57 sec. Users per second: 810\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.89 sec. Users per second: 720\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 5.30 sec. Users per second: 393\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 3.00 sec. Users per second: 693\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.72 sec. Users per second: 764\n",
      "Group 17, #users in group 2081, average p.len 38.28, median 38.0, min 35, max 42\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 3.29 sec. Users per second: 632\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.77 sec. Users per second: 751\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.53 sec. Users per second: 823\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 3.35 sec. Users per second: 621\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.53 sec. Users per second: 822\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.64 sec. Users per second: 787\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.94 sec. Users per second: 707\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 5.48 sec. Users per second: 380\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.97 sec. Users per second: 700\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.80 sec. Users per second: 743\n",
      "Group 18, #users in group 2081, average p.len 47.56, median 47.0, min 42, max 55\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 3.46 sec. Users per second: 602\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.72 sec. Users per second: 765\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.61 sec. Users per second: 799\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 3.54 sec. Users per second: 588\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.46 sec. Users per second: 844\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.72 sec. Users per second: 765\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.91 sec. Users per second: 715\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 5.54 sec. Users per second: 376\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.98 sec. Users per second: 698\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.94 sec. Users per second: 708\n",
      "Group 19, #users in group 2081, average p.len 84.97, median 71.0, min 55, max 358\n",
      "EvaluatorHoldout: Ignoring 317 ( 0.8%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 39548 Users\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 3.97 sec. Users per second: 524\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.78 sec. Users per second: 750\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.95 sec. Users per second: 705\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 3.82 sec. Users per second: 544\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.55 sec. Users per second: 816\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.91 sec. Users per second: 714\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 2.92 sec. Users per second: 713\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 4.97 sec. Users per second: 419\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 3.05 sec. Users per second: 682\n",
      "EvaluatorHoldout: Processed 2081 (100.0%) in 3.24 sec. Users per second: 642\n"
     ]
    }
   ],
   "source": [
    "cutoff = 10\n",
    "\n",
    "for group_id in range(0, 20):\n",
    "    \n",
    "    start_pos = group_id*block_size\n",
    "    end_pos = min((group_id+1)*block_size, len(profile_length))\n",
    "    \n",
    "    users_in_group = sorted_users[start_pos:end_pos]\n",
    "    \n",
    "    users_in_group_p_len = profile_length[users_in_group]\n",
    "    \n",
    "    print(\"Group {}, #users in group {}, average p.len {:.2f}, median {}, min {}, max {}\".format(\n",
    "        group_id, \n",
    "        users_in_group.shape[0],\n",
    "        users_in_group_p_len.mean(),\n",
    "        np.median(users_in_group_p_len),\n",
    "        users_in_group_p_len.min(),\n",
    "        users_in_group_p_len.max()))\n",
    "    \n",
    "    \n",
    "    users_not_in_group_flag = np.isin(sorted_users, users_in_group, invert=True)\n",
    "    users_not_in_group = sorted_users[users_not_in_group_flag]\n",
    "    \n",
    "    evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=[cutoff], ignore_users=users_not_in_group)\n",
    "    \n",
    "    for label, recommender in recommender_object_dict.items():\n",
    "        result_df, _ = evaluator_test.evaluateRecommender(recommender)\n",
    "        if label in MAP_recommender_per_group:\n",
    "            MAP_recommender_per_group[label].append(result_df.loc[cutoff][\"MAP\"])\n",
    "        else:\n",
    "            MAP_recommender_per_group[label] = [result_df.loc[cutoff][\"MAP\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "083c9311",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T23:26:46.719677Z",
     "iopub.status.busy": "2022-11-26T23:26:46.718960Z",
     "iopub.status.idle": "2022-11-26T23:26:47.364564Z",
     "shell.execute_reply": "2022-11-26T23:26:47.363406Z"
    },
    "papermill": {
     "duration": 0.746947,
     "end_time": "2022-11-26T23:26:47.367090",
     "exception": false,
     "start_time": "2022-11-26T23:26:46.620143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "_ = plt.figure(figsize=(16, 9))\n",
    "for label, recommender in recommender_object_dict.items():\n",
    "    results = MAP_recommender_per_group[label]\n",
    "    plt.scatter(x=np.arange(0,len(results)), y=results, label=label)\n",
    "plt.ylabel('MAP')\n",
    "plt.xlabel('User Group')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1523.601292,
   "end_time": "2022-11-26T23:26:50.189615",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-26T23:01:26.588323",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
