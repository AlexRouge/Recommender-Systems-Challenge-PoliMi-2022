{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb2fd6e5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-02T10:16:36.139499Z",
     "iopub.status.busy": "2022-12-02T10:16:36.138800Z",
     "iopub.status.idle": "2022-12-02T10:16:42.031889Z",
     "shell.execute_reply": "2022-12-02T10:16:42.030593Z"
    },
    "papermill": {
     "duration": 5.904179,
     "end_time": "2022-12-02T10:16:42.035018",
     "exception": false,
     "start_time": "2022-12-02T10:16:36.130839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r ../input/recsys-repo/RecSys_Course_AT_PoliMi-master/* ./\n",
    "%config Completer.use_jedi = False\n",
    "%load_ext Cython\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "import matplotlib.pyplot as pyplot\n",
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "from Recommenders.GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "from Recommenders.GraphBased.P3alphaRecommender import P3alphaRecommender\n",
    "from Recommenders.EASE_R.EASE_R_Recommender import EASE_R_Recommender\n",
    "from Recommenders.KNN.ItemKNNCustomSimilarityRecommender import ItemKNNCustomSimilarityRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "172a127d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T10:16:42.047767Z",
     "iopub.status.busy": "2022-12-02T10:16:42.047388Z",
     "iopub.status.idle": "2022-12-02T10:19:36.283585Z",
     "shell.execute_reply": "2022-12-02T10:19:36.282213Z"
    },
    "papermill": {
     "duration": 174.245785,
     "end_time": "2022-12-02T10:19:36.286424",
     "exception": false,
     "start_time": "2022-12-02T10:16:42.040639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_compile_all_cython: Found 10 Cython files in 4 folders...\r\n",
      "run_compile_all_cython: All files will be compiled using your current python environment: '/opt/conda/bin/python'\r\n",
      "Compiling [1/10]: MatrixFactorization_Cython_Epoch.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KMatrixFactorization_Cython_Epoch.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorization_Cython_Epoch.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_32MatrixFactorization_Cython_Epoch_32MatrixFactorization_Cython_Epoch_10epochIteration_Cython_ASY_SVD_SGD\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KMatrixFactorization_Cython_Epoch.c:8669:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_end_pos_seen_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 8669 |         \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K (__pyx_t_19 = __pyx_v_start_pos_seen_items; __pyx_t_19 < __pyx_t_18; __pyx_t_19+=1) {\r\n",
      "      |         \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorization_Cython_Epoch.c:8669:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_start_pos_seen_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/MatrixFactorization/Cython/MatrixFactorization_Cython_Epoch.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [1/10]: MatrixFactorization_Cython_Epoch.pyx... PASS\r\n",
      "\r\n",
      "Compiling [2/10]: MatrixFactorizationImpressions_Cython_Epoch.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_f_43MatrixFactorizationImpressions_Cython_Epoch_32MatrixFactorization_Cython_Epoch_sampleBPR_Cython\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:12758:17:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_start_pos_impression_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      "12758 |       \u001b[01;35m\u001b[K__pyx_t_4 = (__pyx_v_start_pos_impression_items + __pyx_v_index)\u001b[m\u001b[K;\r\n",
      "      |       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_43MatrixFactorizationImpressions_Cython_Epoch_32MatrixFactorization_Cython_Epoch_10epochIteration_Cython_ASY_SVD_SGD\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:8736:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_end_pos_seen_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 8736 |       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K (__pyx_t_19 = __pyx_v_start_pos_seen_items; __pyx_t_19 < __pyx_t_18; __pyx_t_19+=1) {\r\n",
      "      |       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:8736:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_start_pos_seen_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/MatrixFactorization/Cython/MatrixFactorizationImpressions_Cython_Epoch.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [2/10]: MatrixFactorizationImpressions_Cython_Epoch.pyx... PASS\r\n",
      "\r\n",
      "Compiling [3/10]: Compute_Similarity_Cython.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KCompute_Similarity_Cython.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/Similarity/Cython/Compute_Similarity_Cython.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [3/10]: Compute_Similarity_Cython.pyx... PASS\r\n",
      "\r\n",
      "Compiling [4/10]: Triangular_Matrix.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KTriangular_Matrix.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/SLIM/Cython/Triangular_Matrix.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [4/10]: Triangular_Matrix.pyx... PASS\r\n",
      "\r\n",
      "Compiling [5/10]: Sparse_Matrix_Tree_CSR.pyx... \r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KSparse_Matrix_Tree_CSR.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KSparse_Matrix_Tree_CSR.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_f_22Sparse_Matrix_Tree_CSR_22Sparse_Matrix_Tree_CSR_test_list_tree_conversion\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KSparse_Matrix_Tree_CSR.c:5844:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_previous_element\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 5844 |     \u001b[01;35m\u001b[K__pyx_t_7 = __pyx_v_current_element->lower\u001b[m\u001b[K;\r\n",
      "      |     \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/SLIM/Cython/Sparse_Matrix_Tree_CSR.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "Compiling [5/10]: Sparse_Matrix_Tree_CSR.pyx... PASS\r\n",
      "\r\n",
      "Compiling [6/10]: SLIM_BPR_Cython_Epoch.pyx... \r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KSLIM_BPR_Cython_Epoch.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KSLIM_BPR_Cython_Epoch.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_f_21SLIM_BPR_Cython_Epoch_22Sparse_Matrix_Tree_CSR_test_list_tee_conversion\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KSLIM_BPR_Cython_Epoch.c:10848:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_previous_element\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      "10848 |     \u001b[01;35m\u001b[K__pyx_t_7 = __pyx_v_current_element->lower\u001b[m\u001b[K;\r\n",
      "      |     \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/SLIM/Cython/SLIM_BPR_Cython_Epoch.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "Compiling [6/10]: SLIM_BPR_Cython_Epoch.pyx... PASS\r\n",
      "\r\n",
      "Compiling [7/10]: CFW_D_Similarity_Cython_SGD.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KCFW_D_Similarity_Cython_SGD.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KCFW_D_Similarity_Cython_SGD.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_27CFW_D_Similarity_Cython_SGD_27CFW_D_Similarity_Cython_SGD_6fit\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KCFW_D_Similarity_Cython_SGD.c:6056:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_sample_num\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 6056 |   __pyx_t_3 = PyFloat_FromDouble((__pyx_v_cum_loss / \u001b[01;35m\u001b[K((double)__pyx_v_sample_num)\u001b[m\u001b[K)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 290, __pyx_L1_error)\r\n",
      "      |                                                      \u001b[01;35m\u001b[K~^~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/CFW_D_Similarity_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [7/10]: CFW_D_Similarity_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "Compiling [8/10]: HP3_Similarity_Cython_SGD.pyx... \r\n",
      "warning: HP3_Similarity_Cython_SGD.pyx:113:40: Index should be typed for more efficient access\r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KHP3_Similarity_Cython_SGD.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KHP3_Similarity_Cython_SGD.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_25HP3_Similarity_Cython_SGD_25HP3_Similarity_Cython_SGD_4fit\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KHP3_Similarity_Cython_SGD.c:6303:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_sample_num\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 6303 |   __pyx_t_1 = PyFloat_FromDouble((__pyx_v_cum_loss / \u001b[01;35m\u001b[K((double)__pyx_v_sample_num)\u001b[m\u001b[K)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 291, __pyx_L1_error)\r\n",
      "      |                                                      \u001b[01;35m\u001b[K~^~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/HP3_Similarity_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "warning: HP3_Similarity_Cython_SGD.pyx:113:40: Index should be typed for more efficient access\r\n",
      "Compiling [8/10]: HP3_Similarity_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "Compiling [9/10]: FBSM_Rating_Cython_SGD.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KFBSM_Rating_Cython_SGD.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KFBSM_Rating_Cython_SGD.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_22FBSM_Rating_Cython_SGD_22FBSM_Rating_Cython_SGD_2fit\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KFBSM_Rating_Cython_SGD.c:9031:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_num_sample\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 9031 |   __pyx_t_5 = PyFloat_FromDouble((__pyx_v_cum_loss / \u001b[01;35m\u001b[K((double)__pyx_v_num_sample)\u001b[m\u001b[K)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 551, __pyx_L1_error)\r\n",
      "      |                                                      \u001b[01;35m\u001b[K~^~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/FBSM_Rating_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [9/10]: FBSM_Rating_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "Compiling [10/10]: CFW_DVV_Similarity_Cython_SGD.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KCFW_DVV_Similarity_Cython_SGD.c:746\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/CFW_DVV_Similarity_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [10/10]: CFW_DVV_Similarity_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "run_compile_all_cython: Compilation finished. SUCCESS.\r\n",
      "Compilation log can be found here: './result_experiments/run_compile_all_cython.txt'\r\n"
     ]
    }
   ],
   "source": [
    "!python run_compile_all_cython.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e89a6cb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T10:19:36.305380Z",
     "iopub.status.busy": "2022-12-02T10:19:36.304960Z",
     "iopub.status.idle": "2022-12-02T10:19:36.914144Z",
     "shell.execute_reply": "2022-12-02T10:19:36.912967Z"
    },
    "papermill": {
     "duration": 0.62185,
     "end_time": "2022-12-02T10:19:36.916617",
     "exception": false,
     "start_time": "2022-12-02T10:19:36.294767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<41629x24507 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1554640 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_all_dataframe = pd.read_csv('/kaggle/input/urm-true-binary/URM_True_Binary.csv')\n",
    "URM_all_dataframe\n",
    "URM_all = sps.coo_matrix((URM_all_dataframe[\"Data\"].values, \n",
    "                          (URM_all_dataframe[\"UserID\"].values, URM_all_dataframe[\"ItemID\"].values)))\n",
    "URM_all = URM_all.tocsr() # to obtain fast access to rows (users)\n",
    "URM_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2b91f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T10:19:36.936598Z",
     "iopub.status.busy": "2022-12-02T10:19:36.936207Z",
     "iopub.status.idle": "2022-12-02T10:19:40.003974Z",
     "shell.execute_reply": "2022-12-02T10:19:40.002609Z"
    },
    "papermill": {
     "duration": 3.081351,
     "end_time": "2022-12-02T10:19:40.006845",
     "exception": false,
     "start_time": "2022-12-02T10:19:36.925494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 296 (0.71 %) of 41629 users have no sampled items\n"
     ]
    }
   ],
   "source": [
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "\n",
    "# split data into train and validation data 80/20\n",
    "URM_train, URM_valid = split_train_in_two_percentage_global_sample(URM_all, train_percentage = 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c910fdd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T10:19:40.025751Z",
     "iopub.status.busy": "2022-12-02T10:19:40.025355Z",
     "iopub.status.idle": "2022-12-02T10:19:40.049722Z",
     "shell.execute_reply": "2022-12-02T10:19:40.048457Z"
    },
    "papermill": {
     "duration": 0.037014,
     "end_time": "2022-12-02T10:19:40.052556",
     "exception": false,
     "start_time": "2022-12-02T10:19:40.015542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Ignoring 296 ( 0.7%) Users that have less than 1 test interactions\n"
     ]
    }
   ],
   "source": [
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "\n",
    "#create an evaluator object to evaluate validation set\n",
    "#we will use it for hyperparameter tuning\n",
    "evaluator_valid = EvaluatorHoldout(URM_valid, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f196e3a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T10:19:40.073587Z",
     "iopub.status.busy": "2022-12-02T10:19:40.073175Z",
     "iopub.status.idle": "2022-12-02T10:19:40.394744Z",
     "shell.execute_reply": "2022-12-02T10:19:40.393470Z"
    },
    "papermill": {
     "duration": 0.334816,
     "end_time": "2022-12-02T10:19:40.397801",
     "exception": false,
     "start_time": "2022-12-02T10:19:40.062985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "from Recommenders.Recommender_utils import check_matrix\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from Recommenders.BaseSimilarityMatrixRecommender import BaseItemSimilarityMatrixRecommender\n",
    "from Utils.seconds_to_biggest_unit import seconds_to_biggest_unit\n",
    "import time, sys\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# os.environ[\"PYTHONWARNINGS\"] = ('ignore::exceptions.ConvergenceWarning:sklearn.linear_model')\n",
    "# os.environ[\"PYTHONWARNINGS\"] = ('ignore:Objective did not converge:ConvergenceWarning:')\n",
    "\n",
    "class SLIMElasticNetRecommender(BaseItemSimilarityMatrixRecommender):\n",
    "    \"\"\"\n",
    "    Train a Sparse Linear Methods (SLIM) item similarity model.\n",
    "    NOTE: ElasticNet solver is parallel, a single intance of SLIM_ElasticNet will\n",
    "          make use of half the cores available\n",
    "    See:\n",
    "        Efficient Top-N Recommendation by Linear Regression,\n",
    "        M. Levy and K. Jack, LSRS workshop at RecSys 2013.\n",
    "        SLIM: Sparse linear methods for top-n recommender systems,\n",
    "        X. Ning and G. Karypis, ICDM 2011.\n",
    "        http://glaros.dtc.umn.edu/gkhome/fetch/papers/SLIM2011icdm.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"SLIMElasticNetRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, verbose = True):\n",
    "        super(SLIMElasticNetRecommender, self).__init__(URM_train, verbose = verbose)\n",
    "\n",
    "    @ignore_warnings(category=ConvergenceWarning)\n",
    "    def fit(self, l1_ratio=0.1, alpha = 1.0, positive_only=True, topK = 100,**earlystopping_kwargs):\n",
    "\n",
    "        assert l1_ratio>= 0 and l1_ratio<=1, \"{}: l1_ratio must be between 0 and 1, provided value was {}\".format(self.RECOMMENDER_NAME, l1_ratio)\n",
    "\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.positive_only = positive_only\n",
    "        self.topK = topK\n",
    "\n",
    "\n",
    "        # initialize the ElasticNet model\n",
    "        self.model = ElasticNet(alpha=alpha,\n",
    "                                l1_ratio=self.l1_ratio,\n",
    "                                positive=self.positive_only,\n",
    "                                fit_intercept=False,\n",
    "                                copy_X=False,\n",
    "                                precompute=True,\n",
    "                                selection='random',\n",
    "                                max_iter=100,\n",
    "                                tol=1e-4)\n",
    "\n",
    "        URM_train = check_matrix(self.URM_train, 'csc', dtype=np.float32)\n",
    "\n",
    "        n_items = URM_train.shape[1]\n",
    "\n",
    "        # Use array as it reduces memory requirements compared to lists\n",
    "        dataBlock = 10000000\n",
    "\n",
    "        rows = np.zeros(dataBlock, dtype=np.int32)\n",
    "        cols = np.zeros(dataBlock, dtype=np.int32)\n",
    "        values = np.zeros(dataBlock, dtype=np.float32)\n",
    "\n",
    "        numCells = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        start_time_printBatch = start_time\n",
    "\n",
    "        # fit each item's factors sequentially (not in parallel)\n",
    "        for currentItem in range(n_items):\n",
    "\n",
    "            # get the target column\n",
    "            y = URM_train[:, currentItem].toarray()\n",
    "\n",
    "            # set the j-th column of X to zero\n",
    "            start_pos = URM_train.indptr[currentItem]\n",
    "            end_pos = URM_train.indptr[currentItem + 1]\n",
    "\n",
    "            current_item_data_backup = URM_train.data[start_pos: end_pos].copy()\n",
    "            URM_train.data[start_pos: end_pos] = 0.0\n",
    "\n",
    "            # fit one ElasticNet model per column\n",
    "            self.model.fit(URM_train, y)\n",
    "\n",
    "            # self.model.coef_ contains the coefficient of the ElasticNet model\n",
    "            # let's keep only the non-zero values\n",
    "\n",
    "            # Select topK values\n",
    "            # Sorting is done in three steps. Faster then plain np.argsort for higher number of items\n",
    "            # - Partition the data to extract the set of relevant items\n",
    "            # - Sort only the relevant items\n",
    "            # - Get the original item index\n",
    "\n",
    "            nonzero_model_coef_index = self.model.sparse_coef_.indices\n",
    "            nonzero_model_coef_value = self.model.sparse_coef_.data\n",
    "\n",
    "            local_topK = min(len(nonzero_model_coef_value)-1, self.topK)\n",
    "\n",
    "            relevant_items_partition = (-nonzero_model_coef_value).argpartition(local_topK)[0:local_topK]\n",
    "            relevant_items_partition_sorting = np.argsort(-nonzero_model_coef_value[relevant_items_partition])\n",
    "            ranking = relevant_items_partition[relevant_items_partition_sorting]\n",
    "\n",
    "            for index in range(len(ranking)):\n",
    "\n",
    "                if numCells == len(rows):\n",
    "                    rows = np.concatenate((rows, np.zeros(dataBlock, dtype=np.int32)))\n",
    "                    cols = np.concatenate((cols, np.zeros(dataBlock, dtype=np.int32)))\n",
    "                    values = np.concatenate((values, np.zeros(dataBlock, dtype=np.float32)))\n",
    "\n",
    "\n",
    "                rows[numCells] = nonzero_model_coef_index[ranking[index]]\n",
    "                cols[numCells] = currentItem\n",
    "                values[numCells] = nonzero_model_coef_value[ranking[index]]\n",
    "\n",
    "                numCells += 1\n",
    "\n",
    "            # finally, replace the original values of the j-th column\n",
    "            URM_train.data[start_pos:end_pos] = current_item_data_backup\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "            new_time_value, new_time_unit = seconds_to_biggest_unit(elapsed_time)\n",
    "\n",
    "\n",
    "            if time.time() - start_time_printBatch > 300 or currentItem == n_items-1:\n",
    "                self._print(\"Processed {} ({:4.1f}%) in {:.2f} {}. Items per second: {:.2f}\".format(\n",
    "                    currentItem+1,\n",
    "                    100.0* float(currentItem+1)/n_items,\n",
    "                    new_time_value,\n",
    "                    new_time_unit,\n",
    "                    float(currentItem)/elapsed_time))\n",
    "\n",
    "                sys.stdout.flush()\n",
    "                sys.stderr.flush()\n",
    "\n",
    "                start_time_printBatch = time.time()\n",
    "\n",
    "        # generate the sparse weight matrix\n",
    "        self.W_sparse = sps.csr_matrix((values[:numCells], (rows[:numCells], cols[:numCells])),\n",
    "                                       shape=(n_items, n_items), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "186eb2b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T10:19:40.416549Z",
     "iopub.status.busy": "2022-12-02T10:19:40.416119Z",
     "iopub.status.idle": "2022-12-02T10:19:40.421357Z",
     "shell.execute_reply": "2022-12-02T10:19:40.420205Z"
    },
    "papermill": {
     "duration": 0.017411,
     "end_time": "2022-12-02T10:19:40.423792",
     "exception": false,
     "start_time": "2022-12-02T10:19:40.406381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_folder_path = \"result_experiments/\"\n",
    "\n",
    "# If directory does not exist, create\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d571c5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T10:19:40.443676Z",
     "iopub.status.busy": "2022-12-02T10:19:40.443246Z",
     "iopub.status.idle": "2022-12-02T10:55:15.057523Z",
     "shell.execute_reply": "2022-12-02T10:55:15.056200Z"
    },
    "papermill": {
     "duration": 2134.627426,
     "end_time": "2022-12-02T10:55:15.060224",
     "exception": false,
     "start_time": "2022-12-02T10:19:40.432798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: Processed 3087 (12.6%) in 5.00 min. Items per second: 10.29\n",
      "SLIMElasticNetRecommender: Processed 6619 (27.0%) in 10.00 min. Items per second: 11.03\n",
      "SLIMElasticNetRecommender: Processed 10073 (41.1%) in 15.00 min. Items per second: 11.19\n",
      "SLIMElasticNetRecommender: Processed 13582 (55.4%) in 20.00 min. Items per second: 11.32\n",
      "SLIMElasticNetRecommender: Processed 17081 (69.7%) in 25.00 min. Items per second: 11.38\n",
      "SLIMElasticNetRecommender: Processed 20616 (84.1%) in 30.00 min. Items per second: 11.45\n",
      "SLIMElasticNetRecommender: Processed 24094 (98.3%) in 35.00 min. Items per second: 11.47\n",
      "SLIMElasticNetRecommender: Processed 24507 (100.0%) in 35.57 min. Items per second: 11.48\n"
     ]
    }
   ],
   "source": [
    "recommender_SLIMElasticNet = SLIMElasticNetRecommender(URM_train)\n",
    "recommender_SLIMElasticNet.fit(epochs = 500, l1_ratio = 0.001, alpha = 0.01, \n",
    "               positive_only = True, topK = 384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e93137b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T10:55:15.079944Z",
     "iopub.status.busy": "2022-12-02T10:55:15.079556Z",
     "iopub.status.idle": "2022-12-02T10:55:28.393218Z",
     "shell.execute_reply": "2022-12-02T10:55:28.391842Z"
    },
    "papermill": {
     "duration": 13.326892,
     "end_time": "2022-12-02T10:55:28.396132",
     "exception": false,
     "start_time": "2022-12-02T10:55:15.069240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RP3betaRecommender: Similarity column 24507 (100.0%), 2256.46 column/sec. Elapsed time 10.86 sec\n"
     ]
    }
   ],
   "source": [
    "RP3beta_all = RP3betaRecommender(URM_train)\n",
    "RP3beta_all.fit(alpha= 1.0, beta= 0.28666076265452467, topK= 57, implicit= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f825beb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T10:55:28.417236Z",
     "iopub.status.busy": "2022-12-02T10:55:28.416776Z",
     "iopub.status.idle": "2022-12-02T11:06:45.577004Z",
     "shell.execute_reply": "2022-12-02T11:06:45.575661Z"
    },
    "papermill": {
     "duration": 677.174668,
     "end_time": "2022-12-02T11:06:45.580352",
     "exception": false,
     "start_time": "2022-12-02T10:55:28.405684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EASE_R_Recommender: Fitting model... \n",
      "EASE_R_Recommender: Fitting model... done in 10.58 min\n"
     ]
    }
   ],
   "source": [
    "EASE_R = EASE_R_Recommender(URM_all)\n",
    "#%%\n",
    "EASE_R.fit(topK = 416, l2_norm = 115.67139771839786, normalize_matrix = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "863217ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:06:45.604005Z",
     "iopub.status.busy": "2022-12-02T11:06:45.602925Z",
     "iopub.status.idle": "2022-12-02T11:10:26.754630Z",
     "shell.execute_reply": "2022-12-02T11:10:26.753005Z"
    },
    "papermill": {
     "duration": 221.248192,
     "end_time": "2022-12-02T11:10:26.839195",
     "exception": false,
     "start_time": "2022-12-02T11:06:45.591003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIM_BPR_Recommender: Automatic selection of fastest train mode. Available RAM is 28458.00 MB (88.63%) of 32110.00 MB, required is 2402.37 MB. Using dense matrix.\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 1.67E-01. Sample per second: 41194\n",
      "SLIM_BPR_Recommender: Epoch 1 of 615. Elapsed time 0.29 sec\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 6.09E-01. Sample per second: 145202\n",
      "SLIM_BPR_Recommender: Epoch 2 of 615. Elapsed time 0.56 sec\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 1.03E+00. Sample per second: 72429\n",
      "SLIM_BPR_Recommender: Epoch 3 of 615. Elapsed time 0.85 sec\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 1.49E+00. Sample per second: 48045\n",
      "SLIM_BPR_Recommender: Epoch 4 of 615. Elapsed time 1.14 sec\n",
      "Processed 41629 (100.0%) in 1.15 sec. BPR loss is 1.84E+00. Sample per second: 36110\n",
      "SLIM_BPR_Recommender: Epoch 5 of 615. Elapsed time 1.43 sec\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 2.23E+00. Sample per second: 95618\n",
      "SLIM_BPR_Recommender: Epoch 6 of 615. Elapsed time 1.71 sec\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 2.69E+00. Sample per second: 57543\n",
      "SLIM_BPR_Recommender: Epoch 7 of 615. Elapsed time 2.00 sec\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 2.89E+00. Sample per second: 41335\n",
      "SLIM_BPR_Recommender: Epoch 8 of 615. Elapsed time 2.28 sec\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 3.38E+00. Sample per second: 142440\n",
      "SLIM_BPR_Recommender: Epoch 9 of 615. Elapsed time 2.57 sec\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 3.65E+00. Sample per second: 72477\n",
      "SLIM_BPR_Recommender: Epoch 10 of 615. Elapsed time 2.85 sec\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 3.82E+00. Sample per second: 48627\n",
      "SLIM_BPR_Recommender: Epoch 11 of 615. Elapsed time 3.13 sec\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 4.08E+00. Sample per second: 35752\n",
      "SLIM_BPR_Recommender: Epoch 12 of 615. Elapsed time 3.44 sec\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 4.46E+00. Sample per second: 93787\n",
      "SLIM_BPR_Recommender: Epoch 13 of 615. Elapsed time 3.72 sec\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 4.69E+00. Sample per second: 57556\n",
      "SLIM_BPR_Recommender: Epoch 14 of 615. Elapsed time 4.00 sec\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 4.89E+00. Sample per second: 41392\n",
      "SLIM_BPR_Recommender: Epoch 15 of 615. Elapsed time 4.28 sec\n",
      "Processed 41629 (100.0%) in 0.28 sec. BPR loss is 5.24E+00. Sample per second: 150512\n",
      "SLIM_BPR_Recommender: Epoch 16 of 615. Elapsed time 4.55 sec\n",
      "Processed 41629 (100.0%) in 0.55 sec. BPR loss is 5.30E+00. Sample per second: 75841\n",
      "SLIM_BPR_Recommender: Epoch 17 of 615. Elapsed time 4.83 sec\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 5.50E+00. Sample per second: 50641\n",
      "SLIM_BPR_Recommender: Epoch 18 of 615. Elapsed time 5.10 sec\n",
      "Processed 41629 (100.0%) in 1.10 sec. BPR loss is 5.79E+00. Sample per second: 37933\n",
      "SLIM_BPR_Recommender: Epoch 19 of 615. Elapsed time 5.38 sec\n",
      "Processed 41629 (100.0%) in 0.37 sec. BPR loss is 6.03E+00. Sample per second: 111206\n",
      "SLIM_BPR_Recommender: Epoch 20 of 615. Elapsed time 5.65 sec\n",
      "Processed 41629 (100.0%) in 0.65 sec. BPR loss is 6.38E+00. Sample per second: 64419\n",
      "SLIM_BPR_Recommender: Epoch 21 of 615. Elapsed time 5.92 sec\n",
      "Processed 41629 (100.0%) in 0.92 sec. BPR loss is 6.73E+00. Sample per second: 45407\n",
      "SLIM_BPR_Recommender: Epoch 22 of 615. Elapsed time 6.19 sec\n",
      "Processed 41629 (100.0%) in 1.22 sec. BPR loss is 6.68E+00. Sample per second: 34166\n",
      "SLIM_BPR_Recommender: Epoch 23 of 615. Elapsed time 6.49 sec\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 7.00E+00. Sample per second: 84616\n",
      "SLIM_BPR_Recommender: Epoch 24 of 615. Elapsed time 6.77 sec\n",
      "Processed 41629 (100.0%) in 0.77 sec. BPR loss is 6.89E+00. Sample per second: 53892\n",
      "SLIM_BPR_Recommender: Epoch 25 of 615. Elapsed time 7.05 sec\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 6.83E+00. Sample per second: 39808\n",
      "SLIM_BPR_Recommender: Epoch 26 of 615. Elapsed time 7.32 sec\n",
      "Processed 41629 (100.0%) in 0.32 sec. BPR loss is 7.54E+00. Sample per second: 130272\n",
      "SLIM_BPR_Recommender: Epoch 27 of 615. Elapsed time 7.60 sec\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 7.42E+00. Sample per second: 69660\n",
      "SLIM_BPR_Recommender: Epoch 28 of 615. Elapsed time 7.87 sec\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 7.36E+00. Sample per second: 47747\n",
      "SLIM_BPR_Recommender: Epoch 29 of 615. Elapsed time 8.15 sec\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 7.88E+00. Sample per second: 36369\n",
      "SLIM_BPR_Recommender: Epoch 30 of 615. Elapsed time 8.42 sec\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 8.17E+00. Sample per second: 99421\n",
      "SLIM_BPR_Recommender: Epoch 31 of 615. Elapsed time 8.70 sec\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 8.20E+00. Sample per second: 60048\n",
      "SLIM_BPR_Recommender: Epoch 32 of 615. Elapsed time 8.97 sec\n",
      "Processed 41629 (100.0%) in 0.97 sec. BPR loss is 7.91E+00. Sample per second: 43100\n",
      "SLIM_BPR_Recommender: Epoch 33 of 615. Elapsed time 9.24 sec\n",
      "Processed 41629 (100.0%) in 1.24 sec. BPR loss is 8.60E+00. Sample per second: 33646\n",
      "SLIM_BPR_Recommender: Epoch 34 of 615. Elapsed time 9.51 sec\n",
      "Processed 41629 (100.0%) in 0.51 sec. BPR loss is 8.47E+00. Sample per second: 81552\n",
      "SLIM_BPR_Recommender: Epoch 35 of 615. Elapsed time 9.79 sec\n",
      "Processed 41629 (100.0%) in 0.80 sec. BPR loss is 8.69E+00. Sample per second: 52274\n",
      "SLIM_BPR_Recommender: Epoch 36 of 615. Elapsed time 10.07 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 8.70E+00. Sample per second: 38959\n",
      "SLIM_BPR_Recommender: Epoch 37 of 615. Elapsed time 10.35 sec\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 9.01E+00. Sample per second: 122370\n",
      "SLIM_BPR_Recommender: Epoch 38 of 615. Elapsed time 10.62 sec\n",
      "Processed 41629 (100.0%) in 0.61 sec. BPR loss is 9.02E+00. Sample per second: 68049\n",
      "SLIM_BPR_Recommender: Epoch 39 of 615. Elapsed time 10.89 sec\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 9.39E+00. Sample per second: 46792\n",
      "SLIM_BPR_Recommender: Epoch 40 of 615. Elapsed time 11.17 sec\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 9.76E+00. Sample per second: 35833\n",
      "SLIM_BPR_Recommender: Epoch 41 of 615. Elapsed time 11.44 sec\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 9.66E+00. Sample per second: 95538\n",
      "SLIM_BPR_Recommender: Epoch 42 of 615. Elapsed time 11.71 sec\n",
      "Processed 41629 (100.0%) in 0.71 sec. BPR loss is 9.23E+00. Sample per second: 58257\n",
      "SLIM_BPR_Recommender: Epoch 43 of 615. Elapsed time 11.99 sec\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 9.82E+00. Sample per second: 41880\n",
      "SLIM_BPR_Recommender: Epoch 44 of 615. Elapsed time 12.27 sec\n",
      "Processed 41629 (100.0%) in 1.27 sec. BPR loss is 9.51E+00. Sample per second: 32712\n",
      "SLIM_BPR_Recommender: Epoch 45 of 615. Elapsed time 12.55 sec\n",
      "Processed 41629 (100.0%) in 0.55 sec. BPR loss is 9.79E+00. Sample per second: 76341\n",
      "SLIM_BPR_Recommender: Epoch 46 of 615. Elapsed time 12.82 sec\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 9.82E+00. Sample per second: 50467\n",
      "SLIM_BPR_Recommender: Epoch 47 of 615. Elapsed time 13.10 sec\n",
      "Processed 41629 (100.0%) in 1.10 sec. BPR loss is 1.01E+01. Sample per second: 37757\n",
      "SLIM_BPR_Recommender: Epoch 48 of 615. Elapsed time 13.38 sec\n",
      "Processed 41629 (100.0%) in 0.38 sec. BPR loss is 9.95E+00. Sample per second: 110312\n",
      "SLIM_BPR_Recommender: Epoch 49 of 615. Elapsed time 13.65 sec\n",
      "Processed 41629 (100.0%) in 0.65 sec. BPR loss is 1.02E+01. Sample per second: 63975\n",
      "SLIM_BPR_Recommender: Epoch 50 of 615. Elapsed time 13.93 sec\n",
      "Processed 41629 (100.0%) in 0.93 sec. BPR loss is 1.04E+01. Sample per second: 44892\n",
      "SLIM_BPR_Recommender: Epoch 51 of 615. Elapsed time 14.20 sec\n",
      "Processed 41629 (100.0%) in 1.20 sec. BPR loss is 1.07E+01. Sample per second: 34574\n",
      "SLIM_BPR_Recommender: Epoch 52 of 615. Elapsed time 14.48 sec\n",
      "Processed 41629 (100.0%) in 0.48 sec. BPR loss is 1.02E+01. Sample per second: 86929\n",
      "SLIM_BPR_Recommender: Epoch 53 of 615. Elapsed time 14.76 sec\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 1.06E+01. Sample per second: 54942\n",
      "SLIM_BPR_Recommender: Epoch 54 of 615. Elapsed time 15.03 sec\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 1.06E+01. Sample per second: 40423\n",
      "SLIM_BPR_Recommender: Epoch 55 of 615. Elapsed time 15.31 sec\n",
      "Processed 41629 (100.0%) in 0.31 sec. BPR loss is 1.08E+01. Sample per second: 135920\n",
      "SLIM_BPR_Recommender: Epoch 56 of 615. Elapsed time 15.58 sec\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 1.12E+01. Sample per second: 71613\n",
      "SLIM_BPR_Recommender: Epoch 57 of 615. Elapsed time 15.86 sec\n",
      "Processed 41629 (100.0%) in 0.85 sec. BPR loss is 1.13E+01. Sample per second: 48815\n",
      "SLIM_BPR_Recommender: Epoch 58 of 615. Elapsed time 16.13 sec\n",
      "Processed 41629 (100.0%) in 1.13 sec. BPR loss is 1.08E+01. Sample per second: 36881\n",
      "SLIM_BPR_Recommender: Epoch 59 of 615. Elapsed time 16.41 sec\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 1.08E+01. Sample per second: 103585\n",
      "SLIM_BPR_Recommender: Epoch 60 of 615. Elapsed time 16.68 sec\n",
      "Processed 41629 (100.0%) in 0.68 sec. BPR loss is 1.13E+01. Sample per second: 61232\n",
      "SLIM_BPR_Recommender: Epoch 61 of 615. Elapsed time 16.96 sec\n",
      "Processed 41629 (100.0%) in 0.96 sec. BPR loss is 1.11E+01. Sample per second: 43346\n",
      "SLIM_BPR_Recommender: Epoch 62 of 615. Elapsed time 17.24 sec\n",
      "Processed 41629 (100.0%) in 1.26 sec. BPR loss is 1.16E+01. Sample per second: 33141\n",
      "SLIM_BPR_Recommender: Epoch 63 of 615. Elapsed time 17.53 sec\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 1.13E+01. Sample per second: 79244\n",
      "SLIM_BPR_Recommender: Epoch 64 of 615. Elapsed time 17.80 sec\n",
      "Processed 41629 (100.0%) in 0.79 sec. BPR loss is 1.18E+01. Sample per second: 52361\n",
      "SLIM_BPR_Recommender: Epoch 65 of 615. Elapsed time 18.07 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 1.16E+01. Sample per second: 38845\n",
      "SLIM_BPR_Recommender: Epoch 66 of 615. Elapsed time 18.35 sec\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 1.24E+01. Sample per second: 120297\n",
      "SLIM_BPR_Recommender: Epoch 67 of 615. Elapsed time 18.62 sec\n",
      "Processed 41629 (100.0%) in 0.62 sec. BPR loss is 1.14E+01. Sample per second: 66822\n",
      "SLIM_BPR_Recommender: Epoch 68 of 615. Elapsed time 18.90 sec\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 1.16E+01. Sample per second: 46276\n",
      "SLIM_BPR_Recommender: Epoch 69 of 615. Elapsed time 19.18 sec\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 1.20E+01. Sample per second: 35457\n",
      "SLIM_BPR_Recommender: Epoch 70 of 615. Elapsed time 19.45 sec\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 1.20E+01. Sample per second: 92541\n",
      "SLIM_BPR_Recommender: Epoch 71 of 615. Elapsed time 19.73 sec\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 1.22E+01. Sample per second: 57577\n",
      "SLIM_BPR_Recommender: Epoch 72 of 615. Elapsed time 20.00 sec\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 1.20E+01. Sample per second: 41870\n",
      "SLIM_BPR_Recommender: Epoch 73 of 615. Elapsed time 20.27 sec\n",
      "Processed 41629 (100.0%) in 1.27 sec. BPR loss is 1.18E+01. Sample per second: 32779\n",
      "SLIM_BPR_Recommender: Epoch 74 of 615. Elapsed time 20.55 sec\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 1.19E+01. Sample per second: 76584\n",
      "SLIM_BPR_Recommender: Epoch 75 of 615. Elapsed time 20.82 sec\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 1.23E+01. Sample per second: 51054\n",
      "SLIM_BPR_Recommender: Epoch 76 of 615. Elapsed time 21.09 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 1.22E+01. Sample per second: 38264\n",
      "SLIM_BPR_Recommender: Epoch 77 of 615. Elapsed time 21.36 sec\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 1.25E+01. Sample per second: 114344\n",
      "SLIM_BPR_Recommender: Epoch 78 of 615. Elapsed time 21.64 sec\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 1.23E+01. Sample per second: 64874\n",
      "SLIM_BPR_Recommender: Epoch 79 of 615. Elapsed time 21.92 sec\n",
      "Processed 41629 (100.0%) in 0.92 sec. BPR loss is 1.24E+01. Sample per second: 45332\n",
      "SLIM_BPR_Recommender: Epoch 80 of 615. Elapsed time 22.20 sec\n",
      "Processed 41629 (100.0%) in 1.20 sec. BPR loss is 1.24E+01. Sample per second: 34762\n",
      "SLIM_BPR_Recommender: Epoch 81 of 615. Elapsed time 22.47 sec\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 1.29E+01. Sample per second: 88342\n",
      "SLIM_BPR_Recommender: Epoch 82 of 615. Elapsed time 22.75 sec\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 1.23E+01. Sample per second: 55629\n",
      "SLIM_BPR_Recommender: Epoch 83 of 615. Elapsed time 23.02 sec\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 1.26E+01. Sample per second: 40583\n",
      "SLIM_BPR_Recommender: Epoch 84 of 615. Elapsed time 23.30 sec\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 1.24E+01. Sample per second: 136906\n",
      "SLIM_BPR_Recommender: Epoch 85 of 615. Elapsed time 23.58 sec\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 1.28E+01. Sample per second: 72310\n",
      "SLIM_BPR_Recommender: Epoch 86 of 615. Elapsed time 23.85 sec\n",
      "Processed 41629 (100.0%) in 0.85 sec. BPR loss is 1.27E+01. Sample per second: 49196\n",
      "SLIM_BPR_Recommender: Epoch 87 of 615. Elapsed time 24.12 sec\n",
      "Processed 41629 (100.0%) in 1.12 sec. BPR loss is 1.28E+01. Sample per second: 37075\n",
      "SLIM_BPR_Recommender: Epoch 88 of 615. Elapsed time 24.40 sec\n",
      "Processed 41629 (100.0%) in 0.39 sec. BPR loss is 1.29E+01. Sample per second: 105932\n",
      "SLIM_BPR_Recommender: Epoch 89 of 615. Elapsed time 24.67 sec\n",
      "Processed 41629 (100.0%) in 0.67 sec. BPR loss is 1.28E+01. Sample per second: 62325\n",
      "SLIM_BPR_Recommender: Epoch 90 of 615. Elapsed time 24.94 sec\n",
      "Processed 41629 (100.0%) in 0.94 sec. BPR loss is 1.33E+01. Sample per second: 44199\n",
      "SLIM_BPR_Recommender: Epoch 91 of 615. Elapsed time 25.22 sec\n",
      "Processed 41629 (100.0%) in 1.22 sec. BPR loss is 1.33E+01. Sample per second: 34145\n",
      "SLIM_BPR_Recommender: Epoch 92 of 615. Elapsed time 25.49 sec\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 1.31E+01. Sample per second: 84209\n",
      "SLIM_BPR_Recommender: Epoch 93 of 615. Elapsed time 25.77 sec\n",
      "Processed 41629 (100.0%) in 0.78 sec. BPR loss is 1.29E+01. Sample per second: 53645\n",
      "SLIM_BPR_Recommender: Epoch 94 of 615. Elapsed time 26.05 sec\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 1.33E+01. Sample per second: 39503\n",
      "SLIM_BPR_Recommender: Epoch 95 of 615. Elapsed time 26.33 sec\n",
      "Processed 41629 (100.0%) in 0.32 sec. BPR loss is 1.30E+01. Sample per second: 128104\n",
      "SLIM_BPR_Recommender: Epoch 96 of 615. Elapsed time 26.60 sec\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 1.34E+01. Sample per second: 69418\n",
      "SLIM_BPR_Recommender: Epoch 97 of 615. Elapsed time 26.88 sec\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 1.31E+01. Sample per second: 47830\n",
      "SLIM_BPR_Recommender: Epoch 98 of 615. Elapsed time 27.15 sec\n",
      "Processed 41629 (100.0%) in 1.15 sec. BPR loss is 1.33E+01. Sample per second: 36242\n",
      "SLIM_BPR_Recommender: Epoch 99 of 615. Elapsed time 27.43 sec\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 1.35E+01. Sample per second: 98900\n",
      "SLIM_BPR_Recommender: Epoch 100 of 615. Elapsed time 27.70 sec\n",
      "Processed 41629 (100.0%) in 0.70 sec. BPR loss is 1.36E+01. Sample per second: 59779\n",
      "SLIM_BPR_Recommender: Epoch 101 of 615. Elapsed time 27.97 sec\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 1.37E+01. Sample per second: 42313\n",
      "SLIM_BPR_Recommender: Epoch 102 of 615. Elapsed time 28.26 sec\n",
      "Processed 41629 (100.0%) in 1.28 sec. BPR loss is 1.42E+01. Sample per second: 32590\n",
      "SLIM_BPR_Recommender: Epoch 103 of 615. Elapsed time 28.56 sec\n",
      "Processed 41629 (100.0%) in 0.55 sec. BPR loss is 1.35E+01. Sample per second: 75274\n",
      "SLIM_BPR_Recommender: Epoch 104 of 615. Elapsed time 28.83 sec\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 1.36E+01. Sample per second: 50471\n",
      "SLIM_BPR_Recommender: Epoch 105 of 615. Elapsed time 29.10 sec\n",
      "Processed 41629 (100.0%) in 1.10 sec. BPR loss is 1.41E+01. Sample per second: 37722\n",
      "SLIM_BPR_Recommender: Epoch 106 of 615. Elapsed time 29.38 sec\n",
      "Processed 41629 (100.0%) in 0.38 sec. BPR loss is 1.34E+01. Sample per second: 109470\n",
      "SLIM_BPR_Recommender: Epoch 107 of 615. Elapsed time 29.66 sec\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 1.37E+01. Sample per second: 62588\n",
      "SLIM_BPR_Recommender: Epoch 108 of 615. Elapsed time 29.94 sec\n",
      "Processed 41629 (100.0%) in 0.94 sec. BPR loss is 1.34E+01. Sample per second: 44331\n",
      "SLIM_BPR_Recommender: Epoch 109 of 615. Elapsed time 30.22 sec\n",
      "Processed 41629 (100.0%) in 1.21 sec. BPR loss is 1.38E+01. Sample per second: 34259\n",
      "SLIM_BPR_Recommender: Epoch 110 of 615. Elapsed time 30.49 sec\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 1.36E+01. Sample per second: 84544\n",
      "SLIM_BPR_Recommender: Epoch 111 of 615. Elapsed time 30.77 sec\n",
      "Processed 41629 (100.0%) in 0.78 sec. BPR loss is 1.35E+01. Sample per second: 53628\n",
      "SLIM_BPR_Recommender: Epoch 112 of 615. Elapsed time 31.05 sec\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 1.41E+01. Sample per second: 39421\n",
      "SLIM_BPR_Recommender: Epoch 113 of 615. Elapsed time 31.33 sec\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 1.38E+01. Sample per second: 126558\n",
      "SLIM_BPR_Recommender: Epoch 114 of 615. Elapsed time 31.61 sec\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 1.42E+01. Sample per second: 69193\n",
      "SLIM_BPR_Recommender: Epoch 115 of 615. Elapsed time 31.88 sec\n",
      "Processed 41629 (100.0%) in 0.88 sec. BPR loss is 1.39E+01. Sample per second: 47441\n",
      "SLIM_BPR_Recommender: Epoch 116 of 615. Elapsed time 32.15 sec\n",
      "Processed 41629 (100.0%) in 1.15 sec. BPR loss is 1.40E+01. Sample per second: 36138\n",
      "SLIM_BPR_Recommender: Epoch 117 of 615. Elapsed time 32.43 sec\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 1.40E+01. Sample per second: 98203\n",
      "SLIM_BPR_Recommender: Epoch 118 of 615. Elapsed time 32.70 sec\n",
      "Processed 41629 (100.0%) in 0.70 sec. BPR loss is 1.46E+01. Sample per second: 59492\n",
      "SLIM_BPR_Recommender: Epoch 119 of 615. Elapsed time 32.98 sec\n",
      "Processed 41629 (100.0%) in 0.97 sec. BPR loss is 1.39E+01. Sample per second: 42788\n",
      "SLIM_BPR_Recommender: Epoch 120 of 615. Elapsed time 33.25 sec\n",
      "Processed 41629 (100.0%) in 1.25 sec. BPR loss is 1.45E+01. Sample per second: 33397\n",
      "SLIM_BPR_Recommender: Epoch 121 of 615. Elapsed time 33.52 sec\n",
      "Processed 41629 (100.0%) in 0.52 sec. BPR loss is 1.50E+01. Sample per second: 79679\n",
      "SLIM_BPR_Recommender: Epoch 122 of 615. Elapsed time 33.80 sec\n",
      "Processed 41629 (100.0%) in 0.80 sec. BPR loss is 1.46E+01. Sample per second: 52142\n",
      "SLIM_BPR_Recommender: Epoch 123 of 615. Elapsed time 34.07 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 1.41E+01. Sample per second: 38826\n",
      "SLIM_BPR_Recommender: Epoch 124 of 615. Elapsed time 34.35 sec\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 1.44E+01. Sample per second: 121325\n",
      "SLIM_BPR_Recommender: Epoch 125 of 615. Elapsed time 34.62 sec\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 1.48E+01. Sample per second: 64884\n",
      "SLIM_BPR_Recommender: Epoch 126 of 615. Elapsed time 34.92 sec\n",
      "Processed 41629 (100.0%) in 0.93 sec. BPR loss is 1.48E+01. Sample per second: 44775\n",
      "SLIM_BPR_Recommender: Epoch 127 of 615. Elapsed time 35.21 sec\n",
      "Processed 41629 (100.0%) in 1.20 sec. BPR loss is 1.47E+01. Sample per second: 34635\n",
      "SLIM_BPR_Recommender: Epoch 128 of 615. Elapsed time 35.48 sec\n",
      "Processed 41629 (100.0%) in 0.48 sec. BPR loss is 1.44E+01. Sample per second: 86544\n",
      "SLIM_BPR_Recommender: Epoch 129 of 615. Elapsed time 35.76 sec\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 1.47E+01. Sample per second: 55082\n",
      "SLIM_BPR_Recommender: Epoch 130 of 615. Elapsed time 36.03 sec\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 1.48E+01. Sample per second: 40468\n",
      "SLIM_BPR_Recommender: Epoch 131 of 615. Elapsed time 36.30 sec\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 1.53E+01. Sample per second: 139004\n",
      "SLIM_BPR_Recommender: Epoch 132 of 615. Elapsed time 36.58 sec\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 1.46E+01. Sample per second: 71971\n",
      "SLIM_BPR_Recommender: Epoch 133 of 615. Elapsed time 36.85 sec\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 1.47E+01. Sample per second: 48459\n",
      "SLIM_BPR_Recommender: Epoch 134 of 615. Elapsed time 37.14 sec\n",
      "Processed 41629 (100.0%) in 1.13 sec. BPR loss is 1.50E+01. Sample per second: 36796\n",
      "SLIM_BPR_Recommender: Epoch 135 of 615. Elapsed time 37.41 sec\n",
      "Processed 41629 (100.0%) in 0.41 sec. BPR loss is 1.47E+01. Sample per second: 102334\n",
      "SLIM_BPR_Recommender: Epoch 136 of 615. Elapsed time 37.68 sec\n",
      "Processed 41629 (100.0%) in 0.68 sec. BPR loss is 1.52E+01. Sample per second: 61324\n",
      "SLIM_BPR_Recommender: Epoch 137 of 615. Elapsed time 37.95 sec\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 1.51E+01. Sample per second: 44002\n",
      "SLIM_BPR_Recommender: Epoch 138 of 615. Elapsed time 38.22 sec\n",
      "Processed 41629 (100.0%) in 1.22 sec. BPR loss is 1.51E+01. Sample per second: 34110\n",
      "SLIM_BPR_Recommender: Epoch 139 of 615. Elapsed time 38.50 sec\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 1.48E+01. Sample per second: 84669\n",
      "SLIM_BPR_Recommender: Epoch 140 of 615. Elapsed time 38.77 sec\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 1.55E+01. Sample per second: 54719\n",
      "SLIM_BPR_Recommender: Epoch 141 of 615. Elapsed time 39.04 sec\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 1.53E+01. Sample per second: 39219\n",
      "SLIM_BPR_Recommender: Epoch 142 of 615. Elapsed time 39.34 sec\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 1.51E+01. Sample per second: 125821\n",
      "SLIM_BPR_Recommender: Epoch 143 of 615. Elapsed time 39.61 sec\n",
      "Processed 41629 (100.0%) in 0.61 sec. BPR loss is 1.49E+01. Sample per second: 68448\n",
      "SLIM_BPR_Recommender: Epoch 144 of 615. Elapsed time 39.88 sec\n",
      "Processed 41629 (100.0%) in 0.88 sec. BPR loss is 1.53E+01. Sample per second: 47272\n",
      "SLIM_BPR_Recommender: Epoch 145 of 615. Elapsed time 40.16 sec\n",
      "Processed 41629 (100.0%) in 1.15 sec. BPR loss is 1.52E+01. Sample per second: 36212\n",
      "SLIM_BPR_Recommender: Epoch 146 of 615. Elapsed time 40.43 sec\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 1.49E+01. Sample per second: 98967\n",
      "SLIM_BPR_Recommender: Epoch 147 of 615. Elapsed time 40.70 sec\n",
      "Processed 41629 (100.0%) in 0.70 sec. BPR loss is 1.52E+01. Sample per second: 59880\n",
      "SLIM_BPR_Recommender: Epoch 148 of 615. Elapsed time 40.97 sec\n",
      "Processed 41629 (100.0%) in 0.97 sec. BPR loss is 1.55E+01. Sample per second: 43062\n",
      "SLIM_BPR_Recommender: Epoch 149 of 615. Elapsed time 41.24 sec\n",
      "Processed 41629 (100.0%) in 1.24 sec. BPR loss is 1.58E+01. Sample per second: 33467\n",
      "SLIM_BPR_Recommender: Epoch 150 of 615. Elapsed time 41.52 sec\n",
      "Processed 41629 (100.0%) in 0.52 sec. BPR loss is 1.54E+01. Sample per second: 80288\n",
      "SLIM_BPR_Recommender: Epoch 151 of 615. Elapsed time 41.79 sec\n",
      "Processed 41629 (100.0%) in 0.79 sec. BPR loss is 1.52E+01. Sample per second: 52630\n",
      "SLIM_BPR_Recommender: Epoch 152 of 615. Elapsed time 42.07 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 1.55E+01. Sample per second: 38969\n",
      "SLIM_BPR_Recommender: Epoch 153 of 615. Elapsed time 42.34 sec\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 1.59E+01. Sample per second: 121452\n",
      "SLIM_BPR_Recommender: Epoch 154 of 615. Elapsed time 42.62 sec\n",
      "Processed 41629 (100.0%) in 0.62 sec. BPR loss is 1.54E+01. Sample per second: 67484\n",
      "SLIM_BPR_Recommender: Epoch 155 of 615. Elapsed time 42.89 sec\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 1.54E+01. Sample per second: 46886\n",
      "SLIM_BPR_Recommender: Epoch 156 of 615. Elapsed time 43.16 sec\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 1.53E+01. Sample per second: 35865\n",
      "SLIM_BPR_Recommender: Epoch 157 of 615. Elapsed time 43.44 sec\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 1.59E+01. Sample per second: 95593\n",
      "SLIM_BPR_Recommender: Epoch 158 of 615. Elapsed time 43.71 sec\n",
      "Processed 41629 (100.0%) in 0.71 sec. BPR loss is 1.54E+01. Sample per second: 58845\n",
      "SLIM_BPR_Recommender: Epoch 159 of 615. Elapsed time 43.98 sec\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 1.54E+01. Sample per second: 42221\n",
      "SLIM_BPR_Recommender: Epoch 160 of 615. Elapsed time 44.26 sec\n",
      "Processed 41629 (100.0%) in 1.26 sec. BPR loss is 1.54E+01. Sample per second: 33053\n",
      "SLIM_BPR_Recommender: Epoch 161 of 615. Elapsed time 44.54 sec\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 1.57E+01. Sample per second: 77839\n",
      "SLIM_BPR_Recommender: Epoch 162 of 615. Elapsed time 44.81 sec\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 1.59E+01. Sample per second: 51467\n",
      "SLIM_BPR_Recommender: Epoch 163 of 615. Elapsed time 45.09 sec\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 1.61E+01. Sample per second: 38420\n",
      "SLIM_BPR_Recommender: Epoch 164 of 615. Elapsed time 45.36 sec\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 1.60E+01. Sample per second: 116814\n",
      "SLIM_BPR_Recommender: Epoch 165 of 615. Elapsed time 45.63 sec\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 1.54E+01. Sample per second: 66468\n",
      "SLIM_BPR_Recommender: Epoch 166 of 615. Elapsed time 45.90 sec\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 1.54E+01. Sample per second: 46387\n",
      "SLIM_BPR_Recommender: Epoch 167 of 615. Elapsed time 46.17 sec\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 1.56E+01. Sample per second: 35638\n",
      "SLIM_BPR_Recommender: Epoch 168 of 615. Elapsed time 46.44 sec\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 1.58E+01. Sample per second: 95282\n",
      "SLIM_BPR_Recommender: Epoch 169 of 615. Elapsed time 46.71 sec\n",
      "Processed 41629 (100.0%) in 0.71 sec. BPR loss is 1.61E+01. Sample per second: 58706\n",
      "SLIM_BPR_Recommender: Epoch 170 of 615. Elapsed time 46.99 sec\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 1.57E+01. Sample per second: 42597\n",
      "SLIM_BPR_Recommender: Epoch 171 of 615. Elapsed time 47.25 sec\n",
      "Processed 41629 (100.0%) in 1.25 sec. BPR loss is 1.61E+01. Sample per second: 33184\n",
      "SLIM_BPR_Recommender: Epoch 172 of 615. Elapsed time 47.53 sec\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 1.64E+01. Sample per second: 79196\n",
      "SLIM_BPR_Recommender: Epoch 173 of 615. Elapsed time 47.80 sec\n",
      "Processed 41629 (100.0%) in 0.80 sec. BPR loss is 1.60E+01. Sample per second: 52183\n",
      "SLIM_BPR_Recommender: Epoch 174 of 615. Elapsed time 48.07 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 1.63E+01. Sample per second: 38840\n",
      "SLIM_BPR_Recommender: Epoch 175 of 615. Elapsed time 48.35 sec\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 1.57E+01. Sample per second: 120404\n",
      "SLIM_BPR_Recommender: Epoch 176 of 615. Elapsed time 48.62 sec\n",
      "Processed 41629 (100.0%) in 0.62 sec. BPR loss is 1.61E+01. Sample per second: 67087\n",
      "SLIM_BPR_Recommender: Epoch 177 of 615. Elapsed time 48.90 sec\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 1.62E+01. Sample per second: 46575\n",
      "SLIM_BPR_Recommender: Epoch 178 of 615. Elapsed time 49.17 sec\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 1.60E+01. Sample per second: 35473\n",
      "SLIM_BPR_Recommender: Epoch 179 of 615. Elapsed time 49.45 sec\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 1.62E+01. Sample per second: 93409\n",
      "SLIM_BPR_Recommender: Epoch 180 of 615. Elapsed time 49.72 sec\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 1.64E+01. Sample per second: 57938\n",
      "SLIM_BPR_Recommender: Epoch 181 of 615. Elapsed time 50.00 sec\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 1.65E+01. Sample per second: 41152\n",
      "SLIM_BPR_Recommender: Epoch 182 of 615. Elapsed time 50.29 sec\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 1.61E+01. Sample per second: 141328\n",
      "SLIM_BPR_Recommender: Epoch 183 of 615. Elapsed time 50.57 sec\n",
      "Processed 41629 (100.0%) in 0.56 sec. BPR loss is 1.64E+01. Sample per second: 73666\n",
      "SLIM_BPR_Recommender: Epoch 184 of 615. Elapsed time 50.84 sec\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 1.66E+01. Sample per second: 49482\n",
      "SLIM_BPR_Recommender: Epoch 185 of 615. Elapsed time 51.12 sec\n",
      "Processed 41629 (100.0%) in 1.12 sec. BPR loss is 1.65E+01. Sample per second: 37308\n",
      "SLIM_BPR_Recommender: Epoch 186 of 615. Elapsed time 51.39 sec\n",
      "Processed 41629 (100.0%) in 0.39 sec. BPR loss is 1.63E+01. Sample per second: 106851\n",
      "SLIM_BPR_Recommender: Epoch 187 of 615. Elapsed time 51.67 sec\n",
      "Processed 41629 (100.0%) in 0.67 sec. BPR loss is 1.64E+01. Sample per second: 62289\n",
      "SLIM_BPR_Recommender: Epoch 188 of 615. Elapsed time 51.94 sec\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 1.68E+01. Sample per second: 43905\n",
      "SLIM_BPR_Recommender: Epoch 189 of 615. Elapsed time 52.23 sec\n",
      "Processed 41629 (100.0%) in 1.23 sec. BPR loss is 1.67E+01. Sample per second: 33872\n",
      "SLIM_BPR_Recommender: Epoch 190 of 615. Elapsed time 52.51 sec\n",
      "Processed 41629 (100.0%) in 0.50 sec. BPR loss is 1.68E+01. Sample per second: 83456\n",
      "SLIM_BPR_Recommender: Epoch 191 of 615. Elapsed time 52.78 sec\n",
      "Processed 41629 (100.0%) in 0.77 sec. BPR loss is 1.64E+01. Sample per second: 54167\n",
      "SLIM_BPR_Recommender: Epoch 192 of 615. Elapsed time 53.04 sec\n",
      "Processed 41629 (100.0%) in 1.04 sec. BPR loss is 1.71E+01. Sample per second: 39979\n",
      "SLIM_BPR_Recommender: Epoch 193 of 615. Elapsed time 53.32 sec\n",
      "Processed 41629 (100.0%) in 0.32 sec. BPR loss is 1.66E+01. Sample per second: 131020\n",
      "SLIM_BPR_Recommender: Epoch 194 of 615. Elapsed time 53.59 sec\n",
      "Processed 41629 (100.0%) in 0.59 sec. BPR loss is 1.67E+01. Sample per second: 70179\n",
      "SLIM_BPR_Recommender: Epoch 195 of 615. Elapsed time 53.87 sec\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 1.71E+01. Sample per second: 47895\n",
      "SLIM_BPR_Recommender: Epoch 196 of 615. Elapsed time 54.15 sec\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 1.70E+01. Sample per second: 36493\n",
      "SLIM_BPR_Recommender: Epoch 197 of 615. Elapsed time 54.42 sec\n",
      "Processed 41629 (100.0%) in 0.41 sec. BPR loss is 1.67E+01. Sample per second: 100412\n",
      "SLIM_BPR_Recommender: Epoch 198 of 615. Elapsed time 54.69 sec\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 1.65E+01. Sample per second: 60044\n",
      "SLIM_BPR_Recommender: Epoch 199 of 615. Elapsed time 54.97 sec\n",
      "Processed 41629 (100.0%) in 0.97 sec. BPR loss is 1.70E+01. Sample per second: 43074\n",
      "SLIM_BPR_Recommender: Epoch 200 of 615. Elapsed time 55.24 sec\n",
      "Processed 41629 (100.0%) in 1.24 sec. BPR loss is 1.70E+01. Sample per second: 33506\n",
      "SLIM_BPR_Recommender: Epoch 201 of 615. Elapsed time 55.52 sec\n",
      "Processed 41629 (100.0%) in 0.52 sec. BPR loss is 1.66E+01. Sample per second: 80019\n",
      "SLIM_BPR_Recommender: Epoch 202 of 615. Elapsed time 55.80 sec\n",
      "Processed 41629 (100.0%) in 0.79 sec. BPR loss is 1.65E+01. Sample per second: 52387\n",
      "SLIM_BPR_Recommender: Epoch 203 of 615. Elapsed time 56.07 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 1.70E+01. Sample per second: 38888\n",
      "SLIM_BPR_Recommender: Epoch 204 of 615. Elapsed time 56.35 sec\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 1.68E+01. Sample per second: 122008\n",
      "SLIM_BPR_Recommender: Epoch 205 of 615. Elapsed time 56.62 sec\n",
      "Processed 41629 (100.0%) in 0.61 sec. BPR loss is 1.68E+01. Sample per second: 67717\n",
      "SLIM_BPR_Recommender: Epoch 206 of 615. Elapsed time 56.89 sec\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 1.72E+01. Sample per second: 46786\n",
      "SLIM_BPR_Recommender: Epoch 207 of 615. Elapsed time 57.17 sec\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 1.67E+01. Sample per second: 35835\n",
      "SLIM_BPR_Recommender: Epoch 208 of 615. Elapsed time 57.44 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 1.71E+01. Sample per second: 96306\n",
      "SLIM_BPR_Recommender: Epoch 209 of 615. Elapsed time 57.71 sec\n",
      "Processed 41629 (100.0%) in 0.70 sec. BPR loss is 1.70E+01. Sample per second: 59066\n",
      "SLIM_BPR_Recommender: Epoch 210 of 615. Elapsed time 57.98 sec\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 1.68E+01. Sample per second: 42471\n",
      "SLIM_BPR_Recommender: Epoch 211 of 615. Elapsed time 58.26 sec\n",
      "Processed 41629 (100.0%) in 1.26 sec. BPR loss is 1.71E+01. Sample per second: 33044\n",
      "SLIM_BPR_Recommender: Epoch 212 of 615. Elapsed time 58.54 sec\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 1.69E+01. Sample per second: 77399\n",
      "SLIM_BPR_Recommender: Epoch 213 of 615. Elapsed time 58.81 sec\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 1.71E+01. Sample per second: 51667\n",
      "SLIM_BPR_Recommender: Epoch 214 of 615. Elapsed time 59.08 sec\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 1.66E+01. Sample per second: 38598\n",
      "SLIM_BPR_Recommender: Epoch 215 of 615. Elapsed time 59.35 sec\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 1.70E+01. Sample per second: 118223\n",
      "SLIM_BPR_Recommender: Epoch 216 of 615. Elapsed time 59.63 sec\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 1.74E+01. Sample per second: 66567\n",
      "SLIM_BPR_Recommender: Epoch 217 of 615. Elapsed time 59.90 sec\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 1.69E+01. Sample per second: 46493\n",
      "SLIM_BPR_Recommender: Epoch 218 of 615. Elapsed time 1.00 min\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 1.73E+01. Sample per second: 35599\n",
      "SLIM_BPR_Recommender: Epoch 219 of 615. Elapsed time 1.01 min\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 1.67E+01. Sample per second: 94661\n",
      "SLIM_BPR_Recommender: Epoch 220 of 615. Elapsed time 1.01 min\n",
      "Processed 41629 (100.0%) in 0.71 sec. BPR loss is 1.75E+01. Sample per second: 58472\n",
      "SLIM_BPR_Recommender: Epoch 221 of 615. Elapsed time 1.02 min\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 1.74E+01. Sample per second: 41174\n",
      "SLIM_BPR_Recommender: Epoch 222 of 615. Elapsed time 1.02 min\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 1.72E+01. Sample per second: 140337\n",
      "SLIM_BPR_Recommender: Epoch 223 of 615. Elapsed time 1.03 min\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 1.71E+01. Sample per second: 73645\n",
      "SLIM_BPR_Recommender: Epoch 224 of 615. Elapsed time 1.03 min\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 1.71E+01. Sample per second: 49811\n",
      "SLIM_BPR_Recommender: Epoch 225 of 615. Elapsed time 1.04 min\n",
      "Processed 41629 (100.0%) in 1.11 sec. BPR loss is 1.75E+01. Sample per second: 37604\n",
      "SLIM_BPR_Recommender: Epoch 226 of 615. Elapsed time 1.04 min\n",
      "Processed 41629 (100.0%) in 0.38 sec. BPR loss is 1.77E+01. Sample per second: 110626\n",
      "SLIM_BPR_Recommender: Epoch 227 of 615. Elapsed time 1.04 min\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 1.71E+01. Sample per second: 64592\n",
      "SLIM_BPR_Recommender: Epoch 228 of 615. Elapsed time 1.05 min\n",
      "Processed 41629 (100.0%) in 0.92 sec. BPR loss is 1.74E+01. Sample per second: 45408\n",
      "SLIM_BPR_Recommender: Epoch 229 of 615. Elapsed time 1.05 min\n",
      "Processed 41629 (100.0%) in 1.18 sec. BPR loss is 1.78E+01. Sample per second: 35187\n",
      "SLIM_BPR_Recommender: Epoch 230 of 615. Elapsed time 1.06 min\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 1.73E+01. Sample per second: 92734\n",
      "SLIM_BPR_Recommender: Epoch 231 of 615. Elapsed time 1.06 min\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 1.74E+01. Sample per second: 57698\n",
      "SLIM_BPR_Recommender: Epoch 232 of 615. Elapsed time 1.07 min\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 1.75E+01. Sample per second: 42064\n",
      "SLIM_BPR_Recommender: Epoch 233 of 615. Elapsed time 1.07 min\n",
      "Processed 41629 (100.0%) in 1.26 sec. BPR loss is 1.72E+01. Sample per second: 32938\n",
      "SLIM_BPR_Recommender: Epoch 234 of 615. Elapsed time 1.08 min\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 1.76E+01. Sample per second: 77938\n",
      "SLIM_BPR_Recommender: Epoch 235 of 615. Elapsed time 1.08 min\n",
      "Processed 41629 (100.0%) in 0.80 sec. BPR loss is 1.75E+01. Sample per second: 51790\n",
      "SLIM_BPR_Recommender: Epoch 236 of 615. Elapsed time 1.08 min\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 1.75E+01. Sample per second: 38844\n",
      "SLIM_BPR_Recommender: Epoch 237 of 615. Elapsed time 1.09 min\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 1.75E+01. Sample per second: 123923\n",
      "SLIM_BPR_Recommender: Epoch 238 of 615. Elapsed time 1.09 min\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 1.80E+01. Sample per second: 68845\n",
      "SLIM_BPR_Recommender: Epoch 239 of 615. Elapsed time 1.10 min\n",
      "Processed 41629 (100.0%) in 0.88 sec. BPR loss is 1.75E+01. Sample per second: 47294\n",
      "SLIM_BPR_Recommender: Epoch 240 of 615. Elapsed time 1.10 min\n",
      "Processed 41629 (100.0%) in 1.18 sec. BPR loss is 1.74E+01. Sample per second: 35365\n",
      "SLIM_BPR_Recommender: Epoch 241 of 615. Elapsed time 1.11 min\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 1.82E+01. Sample per second: 87705\n",
      "SLIM_BPR_Recommender: Epoch 242 of 615. Elapsed time 1.11 min\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 1.74E+01. Sample per second: 55178\n",
      "SLIM_BPR_Recommender: Epoch 243 of 615. Elapsed time 1.12 min\n",
      "Processed 41629 (100.0%) in 1.04 sec. BPR loss is 1.79E+01. Sample per second: 40107\n",
      "SLIM_BPR_Recommender: Epoch 244 of 615. Elapsed time 1.12 min\n",
      "Processed 41629 (100.0%) in 0.31 sec. BPR loss is 1.75E+01. Sample per second: 133400\n",
      "SLIM_BPR_Recommender: Epoch 245 of 615. Elapsed time 1.13 min\n",
      "Processed 41629 (100.0%) in 0.59 sec. BPR loss is 1.77E+01. Sample per second: 71049\n",
      "SLIM_BPR_Recommender: Epoch 246 of 615. Elapsed time 1.13 min\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 1.81E+01. Sample per second: 48327\n",
      "SLIM_BPR_Recommender: Epoch 247 of 615. Elapsed time 1.14 min\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 1.78E+01. Sample per second: 36482\n",
      "SLIM_BPR_Recommender: Epoch 248 of 615. Elapsed time 1.14 min\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 1.79E+01. Sample per second: 98598\n",
      "SLIM_BPR_Recommender: Epoch 249 of 615. Elapsed time 1.14 min\n",
      "Processed 41629 (100.0%) in 0.70 sec. BPR loss is 1.82E+01. Sample per second: 59029\n",
      "SLIM_BPR_Recommender: Epoch 250 of 615. Elapsed time 1.15 min\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 1.81E+01. Sample per second: 42342\n",
      "SLIM_BPR_Recommender: Epoch 251 of 615. Elapsed time 1.15 min\n",
      "Processed 41629 (100.0%) in 1.26 sec. BPR loss is 1.77E+01. Sample per second: 32938\n",
      "SLIM_BPR_Recommender: Epoch 252 of 615. Elapsed time 1.16 min\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 1.80E+01. Sample per second: 77530\n",
      "SLIM_BPR_Recommender: Epoch 253 of 615. Elapsed time 1.16 min\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 1.77E+01. Sample per second: 51581\n",
      "SLIM_BPR_Recommender: Epoch 254 of 615. Elapsed time 1.17 min\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 1.78E+01. Sample per second: 38559\n",
      "SLIM_BPR_Recommender: Epoch 255 of 615. Elapsed time 1.17 min\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 1.79E+01. Sample per second: 117635\n",
      "SLIM_BPR_Recommender: Epoch 256 of 615. Elapsed time 1.18 min\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 1.81E+01. Sample per second: 66212\n",
      "SLIM_BPR_Recommender: Epoch 257 of 615. Elapsed time 1.18 min\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 1.83E+01. Sample per second: 46105\n",
      "SLIM_BPR_Recommender: Epoch 258 of 615. Elapsed time 1.19 min\n",
      "Processed 41629 (100.0%) in 1.18 sec. BPR loss is 1.82E+01. Sample per second: 35361\n",
      "SLIM_BPR_Recommender: Epoch 259 of 615. Elapsed time 1.19 min\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 1.85E+01. Sample per second: 92335\n",
      "SLIM_BPR_Recommender: Epoch 260 of 615. Elapsed time 1.20 min\n",
      "Processed 41629 (100.0%) in 0.73 sec. BPR loss is 1.84E+01. Sample per second: 57362\n",
      "SLIM_BPR_Recommender: Epoch 261 of 615. Elapsed time 1.20 min\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 1.83E+01. Sample per second: 40466\n",
      "SLIM_BPR_Recommender: Epoch 262 of 615. Elapsed time 1.21 min\n",
      "Processed 41629 (100.0%) in 0.31 sec. BPR loss is 1.82E+01. Sample per second: 134529\n",
      "SLIM_BPR_Recommender: Epoch 263 of 615. Elapsed time 1.21 min\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 1.84E+01. Sample per second: 71180\n",
      "SLIM_BPR_Recommender: Epoch 264 of 615. Elapsed time 1.21 min\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 1.85E+01. Sample per second: 48182\n",
      "SLIM_BPR_Recommender: Epoch 265 of 615. Elapsed time 1.22 min\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 1.82E+01. Sample per second: 36630\n",
      "SLIM_BPR_Recommender: Epoch 266 of 615. Elapsed time 1.22 min\n",
      "Processed 41629 (100.0%) in 0.41 sec. BPR loss is 1.87E+01. Sample per second: 101208\n",
      "SLIM_BPR_Recommender: Epoch 267 of 615. Elapsed time 1.23 min\n",
      "Processed 41629 (100.0%) in 0.68 sec. BPR loss is 1.84E+01. Sample per second: 60829\n",
      "SLIM_BPR_Recommender: Epoch 268 of 615. Elapsed time 1.23 min\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 1.81E+01. Sample per second: 43787\n",
      "SLIM_BPR_Recommender: Epoch 269 of 615. Elapsed time 1.24 min\n",
      "Processed 41629 (100.0%) in 1.22 sec. BPR loss is 1.85E+01. Sample per second: 34049\n",
      "SLIM_BPR_Recommender: Epoch 270 of 615. Elapsed time 1.24 min\n",
      "Processed 41629 (100.0%) in 0.50 sec. BPR loss is 1.87E+01. Sample per second: 83371\n",
      "SLIM_BPR_Recommender: Epoch 271 of 615. Elapsed time 1.25 min\n",
      "Processed 41629 (100.0%) in 0.78 sec. BPR loss is 1.92E+01. Sample per second: 53598\n",
      "SLIM_BPR_Recommender: Epoch 272 of 615. Elapsed time 1.25 min\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 1.85E+01. Sample per second: 39508\n",
      "SLIM_BPR_Recommender: Epoch 273 of 615. Elapsed time 1.26 min\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 1.85E+01. Sample per second: 125578\n",
      "SLIM_BPR_Recommender: Epoch 274 of 615. Elapsed time 1.26 min\n",
      "Processed 41629 (100.0%) in 0.61 sec. BPR loss is 1.85E+01. Sample per second: 68073\n",
      "SLIM_BPR_Recommender: Epoch 275 of 615. Elapsed time 1.26 min\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 1.85E+01. Sample per second: 46752\n",
      "SLIM_BPR_Recommender: Epoch 276 of 615. Elapsed time 1.27 min\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 1.86E+01. Sample per second: 35650\n",
      "SLIM_BPR_Recommender: Epoch 277 of 615. Elapsed time 1.27 min\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 1.88E+01. Sample per second: 94573\n",
      "SLIM_BPR_Recommender: Epoch 278 of 615. Elapsed time 1.28 min\n",
      "Processed 41629 (100.0%) in 0.71 sec. BPR loss is 1.85E+01. Sample per second: 58369\n",
      "SLIM_BPR_Recommender: Epoch 279 of 615. Elapsed time 1.28 min\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 1.87E+01. Sample per second: 42303\n",
      "SLIM_BPR_Recommender: Epoch 280 of 615. Elapsed time 1.29 min\n",
      "Processed 41629 (100.0%) in 1.27 sec. BPR loss is 1.88E+01. Sample per second: 32885\n",
      "SLIM_BPR_Recommender: Epoch 281 of 615. Elapsed time 1.29 min\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 1.83E+01. Sample per second: 77581\n",
      "SLIM_BPR_Recommender: Epoch 282 of 615. Elapsed time 1.30 min\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 1.91E+01. Sample per second: 51453\n",
      "SLIM_BPR_Recommender: Epoch 283 of 615. Elapsed time 1.30 min\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 1.90E+01. Sample per second: 38437\n",
      "SLIM_BPR_Recommender: Epoch 284 of 615. Elapsed time 1.31 min\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 1.88E+01. Sample per second: 115917\n",
      "SLIM_BPR_Recommender: Epoch 285 of 615. Elapsed time 1.31 min\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 1.88E+01. Sample per second: 65776\n",
      "SLIM_BPR_Recommender: Epoch 286 of 615. Elapsed time 1.32 min\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 1.89E+01. Sample per second: 46070\n",
      "SLIM_BPR_Recommender: Epoch 287 of 615. Elapsed time 1.32 min\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 1.89E+01. Sample per second: 35421\n",
      "SLIM_BPR_Recommender: Epoch 288 of 615. Elapsed time 1.32 min\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 1.89E+01. Sample per second: 94183\n",
      "SLIM_BPR_Recommender: Epoch 289 of 615. Elapsed time 1.33 min\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 1.87E+01. Sample per second: 58200\n",
      "SLIM_BPR_Recommender: Epoch 290 of 615. Elapsed time 1.33 min\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 1.88E+01. Sample per second: 42206\n",
      "SLIM_BPR_Recommender: Epoch 291 of 615. Elapsed time 1.34 min\n",
      "Processed 41629 (100.0%) in 1.26 sec. BPR loss is 1.86E+01. Sample per second: 33141\n",
      "SLIM_BPR_Recommender: Epoch 292 of 615. Elapsed time 1.34 min\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 1.90E+01. Sample per second: 78032\n",
      "SLIM_BPR_Recommender: Epoch 293 of 615. Elapsed time 1.35 min\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 1.87E+01. Sample per second: 51573\n",
      "SLIM_BPR_Recommender: Epoch 294 of 615. Elapsed time 1.35 min\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 1.89E+01. Sample per second: 38571\n",
      "SLIM_BPR_Recommender: Epoch 295 of 615. Elapsed time 1.36 min\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 1.89E+01. Sample per second: 117193\n",
      "SLIM_BPR_Recommender: Epoch 296 of 615. Elapsed time 1.36 min\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 1.93E+01. Sample per second: 65401\n",
      "SLIM_BPR_Recommender: Epoch 297 of 615. Elapsed time 1.37 min\n",
      "Processed 41629 (100.0%) in 0.91 sec. BPR loss is 1.86E+01. Sample per second: 45486\n",
      "SLIM_BPR_Recommender: Epoch 298 of 615. Elapsed time 1.37 min\n",
      "Processed 41629 (100.0%) in 1.19 sec. BPR loss is 1.91E+01. Sample per second: 34957\n",
      "SLIM_BPR_Recommender: Epoch 299 of 615. Elapsed time 1.37 min\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 1.90E+01. Sample per second: 89064\n",
      "SLIM_BPR_Recommender: Epoch 300 of 615. Elapsed time 1.38 min\n",
      "Processed 41629 (100.0%) in 0.74 sec. BPR loss is 1.87E+01. Sample per second: 56431\n",
      "SLIM_BPR_Recommender: Epoch 301 of 615. Elapsed time 1.38 min\n",
      "Processed 41629 (100.0%) in 1.04 sec. BPR loss is 1.91E+01. Sample per second: 39873\n",
      "SLIM_BPR_Recommender: Epoch 302 of 615. Elapsed time 1.39 min\n",
      "Processed 41629 (100.0%) in 0.32 sec. BPR loss is 1.91E+01. Sample per second: 129374\n",
      "SLIM_BPR_Recommender: Epoch 303 of 615. Elapsed time 1.39 min\n",
      "Processed 41629 (100.0%) in 0.59 sec. BPR loss is 1.88E+01. Sample per second: 69953\n",
      "SLIM_BPR_Recommender: Epoch 304 of 615. Elapsed time 1.40 min\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 1.91E+01. Sample per second: 47887\n",
      "SLIM_BPR_Recommender: Epoch 305 of 615. Elapsed time 1.40 min\n",
      "Processed 41629 (100.0%) in 1.15 sec. BPR loss is 1.88E+01. Sample per second: 36177\n",
      "SLIM_BPR_Recommender: Epoch 306 of 615. Elapsed time 1.41 min\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 1.88E+01. Sample per second: 98882\n",
      "SLIM_BPR_Recommender: Epoch 307 of 615. Elapsed time 1.41 min\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 1.87E+01. Sample per second: 59957\n",
      "SLIM_BPR_Recommender: Epoch 308 of 615. Elapsed time 1.42 min\n",
      "Processed 41629 (100.0%) in 0.97 sec. BPR loss is 1.95E+01. Sample per second: 43094\n",
      "SLIM_BPR_Recommender: Epoch 309 of 615. Elapsed time 1.42 min\n",
      "Processed 41629 (100.0%) in 1.24 sec. BPR loss is 1.92E+01. Sample per second: 33504\n",
      "SLIM_BPR_Recommender: Epoch 310 of 615. Elapsed time 1.43 min\n",
      "Processed 41629 (100.0%) in 0.52 sec. BPR loss is 1.91E+01. Sample per second: 80752\n",
      "SLIM_BPR_Recommender: Epoch 311 of 615. Elapsed time 1.43 min\n",
      "Processed 41629 (100.0%) in 0.79 sec. BPR loss is 1.87E+01. Sample per second: 52590\n",
      "SLIM_BPR_Recommender: Epoch 312 of 615. Elapsed time 1.43 min\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 1.88E+01. Sample per second: 39162\n",
      "SLIM_BPR_Recommender: Epoch 313 of 615. Elapsed time 1.44 min\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 1.90E+01. Sample per second: 123385\n",
      "SLIM_BPR_Recommender: Epoch 314 of 615. Elapsed time 1.44 min\n",
      "Processed 41629 (100.0%) in 0.61 sec. BPR loss is 1.90E+01. Sample per second: 68387\n",
      "SLIM_BPR_Recommender: Epoch 315 of 615. Elapsed time 1.45 min\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 1.92E+01. Sample per second: 46947\n",
      "SLIM_BPR_Recommender: Epoch 316 of 615. Elapsed time 1.45 min\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 1.89E+01. Sample per second: 35838\n",
      "SLIM_BPR_Recommender: Epoch 317 of 615. Elapsed time 1.46 min\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 1.95E+01. Sample per second: 95004\n",
      "SLIM_BPR_Recommender: Epoch 318 of 615. Elapsed time 1.46 min\n",
      "Processed 41629 (100.0%) in 0.71 sec. BPR loss is 1.90E+01. Sample per second: 58484\n",
      "SLIM_BPR_Recommender: Epoch 319 of 615. Elapsed time 1.47 min\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 1.93E+01. Sample per second: 42155\n",
      "SLIM_BPR_Recommender: Epoch 320 of 615. Elapsed time 1.47 min\n",
      "Processed 41629 (100.0%) in 1.26 sec. BPR loss is 1.94E+01. Sample per second: 33066\n",
      "SLIM_BPR_Recommender: Epoch 321 of 615. Elapsed time 1.48 min\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 1.91E+01. Sample per second: 77020\n",
      "SLIM_BPR_Recommender: Epoch 322 of 615. Elapsed time 1.48 min\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 1.93E+01. Sample per second: 51361\n",
      "SLIM_BPR_Recommender: Epoch 323 of 615. Elapsed time 1.48 min\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 1.92E+01. Sample per second: 38445\n",
      "SLIM_BPR_Recommender: Epoch 324 of 615. Elapsed time 1.49 min\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 1.97E+01. Sample per second: 116458\n",
      "SLIM_BPR_Recommender: Epoch 325 of 615. Elapsed time 1.49 min\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 1.92E+01. Sample per second: 66337\n",
      "SLIM_BPR_Recommender: Epoch 326 of 615. Elapsed time 1.50 min\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 1.94E+01. Sample per second: 46104\n",
      "SLIM_BPR_Recommender: Epoch 327 of 615. Elapsed time 1.50 min\n",
      "Processed 41629 (100.0%) in 1.18 sec. BPR loss is 1.99E+01. Sample per second: 35289\n",
      "SLIM_BPR_Recommender: Epoch 328 of 615. Elapsed time 1.51 min\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 1.96E+01. Sample per second: 91397\n",
      "SLIM_BPR_Recommender: Epoch 329 of 615. Elapsed time 1.51 min\n",
      "Processed 41629 (100.0%) in 0.73 sec. BPR loss is 1.93E+01. Sample per second: 56705\n",
      "SLIM_BPR_Recommender: Epoch 330 of 615. Elapsed time 1.52 min\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 1.94E+01. Sample per second: 41311\n",
      "SLIM_BPR_Recommender: Epoch 331 of 615. Elapsed time 1.52 min\n",
      "Processed 41629 (100.0%) in 0.28 sec. BPR loss is 1.95E+01. Sample per second: 147572\n",
      "SLIM_BPR_Recommender: Epoch 332 of 615. Elapsed time 1.53 min\n",
      "Processed 41629 (100.0%) in 0.55 sec. BPR loss is 2.00E+01. Sample per second: 74998\n",
      "SLIM_BPR_Recommender: Epoch 333 of 615. Elapsed time 1.53 min\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 1.97E+01. Sample per second: 50283\n",
      "SLIM_BPR_Recommender: Epoch 334 of 615. Elapsed time 1.54 min\n",
      "Processed 41629 (100.0%) in 1.10 sec. BPR loss is 1.95E+01. Sample per second: 37844\n",
      "SLIM_BPR_Recommender: Epoch 335 of 615. Elapsed time 1.54 min\n",
      "Processed 41629 (100.0%) in 0.37 sec. BPR loss is 1.94E+01. Sample per second: 111392\n",
      "SLIM_BPR_Recommender: Epoch 336 of 615. Elapsed time 1.54 min\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 1.96E+01. Sample per second: 64578\n",
      "SLIM_BPR_Recommender: Epoch 337 of 615. Elapsed time 1.55 min\n",
      "Processed 41629 (100.0%) in 0.92 sec. BPR loss is 1.93E+01. Sample per second: 45425\n",
      "SLIM_BPR_Recommender: Epoch 338 of 615. Elapsed time 1.55 min\n",
      "Processed 41629 (100.0%) in 1.19 sec. BPR loss is 1.95E+01. Sample per second: 34928\n",
      "SLIM_BPR_Recommender: Epoch 339 of 615. Elapsed time 1.56 min\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 1.96E+01. Sample per second: 89132\n",
      "SLIM_BPR_Recommender: Epoch 340 of 615. Elapsed time 1.56 min\n",
      "Processed 41629 (100.0%) in 0.74 sec. BPR loss is 1.98E+01. Sample per second: 56086\n",
      "SLIM_BPR_Recommender: Epoch 341 of 615. Elapsed time 1.57 min\n",
      "Processed 41629 (100.0%) in 1.04 sec. BPR loss is 1.97E+01. Sample per second: 39939\n",
      "SLIM_BPR_Recommender: Epoch 342 of 615. Elapsed time 1.57 min\n",
      "Processed 41629 (100.0%) in 0.31 sec. BPR loss is 1.94E+01. Sample per second: 133634\n",
      "SLIM_BPR_Recommender: Epoch 343 of 615. Elapsed time 1.58 min\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 1.95E+01. Sample per second: 71356\n",
      "SLIM_BPR_Recommender: Epoch 344 of 615. Elapsed time 1.58 min\n",
      "Processed 41629 (100.0%) in 0.85 sec. BPR loss is 1.95E+01. Sample per second: 48715\n",
      "SLIM_BPR_Recommender: Epoch 345 of 615. Elapsed time 1.59 min\n",
      "Processed 41629 (100.0%) in 1.13 sec. BPR loss is 1.97E+01. Sample per second: 36890\n",
      "SLIM_BPR_Recommender: Epoch 346 of 615. Elapsed time 1.59 min\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 1.94E+01. Sample per second: 102960\n",
      "SLIM_BPR_Recommender: Epoch 347 of 615. Elapsed time 1.59 min\n",
      "Processed 41629 (100.0%) in 0.68 sec. BPR loss is 1.97E+01. Sample per second: 61499\n",
      "SLIM_BPR_Recommender: Epoch 348 of 615. Elapsed time 1.60 min\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 1.98E+01. Sample per second: 43737\n",
      "SLIM_BPR_Recommender: Epoch 349 of 615. Elapsed time 1.60 min\n",
      "Processed 41629 (100.0%) in 1.22 sec. BPR loss is 2.01E+01. Sample per second: 33991\n",
      "SLIM_BPR_Recommender: Epoch 350 of 615. Elapsed time 1.61 min\n",
      "Processed 41629 (100.0%) in 0.50 sec. BPR loss is 1.99E+01. Sample per second: 83341\n",
      "SLIM_BPR_Recommender: Epoch 351 of 615. Elapsed time 1.61 min\n",
      "Processed 41629 (100.0%) in 0.77 sec. BPR loss is 2.01E+01. Sample per second: 53746\n",
      "SLIM_BPR_Recommender: Epoch 352 of 615. Elapsed time 1.62 min\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 1.95E+01. Sample per second: 39626\n",
      "SLIM_BPR_Recommender: Epoch 353 of 615. Elapsed time 1.62 min\n",
      "Processed 41629 (100.0%) in 0.32 sec. BPR loss is 1.95E+01. Sample per second: 129290\n",
      "SLIM_BPR_Recommender: Epoch 354 of 615. Elapsed time 1.63 min\n",
      "Processed 41629 (100.0%) in 0.61 sec. BPR loss is 1.97E+01. Sample per second: 68570\n",
      "SLIM_BPR_Recommender: Epoch 355 of 615. Elapsed time 1.63 min\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 2.02E+01. Sample per second: 44001\n",
      "SLIM_BPR_Recommender: Epoch 356 of 615. Elapsed time 1.64 min\n",
      "Processed 41629 (100.0%) in 1.22 sec. BPR loss is 1.98E+01. Sample per second: 34190\n",
      "SLIM_BPR_Recommender: Epoch 357 of 615. Elapsed time 1.64 min\n",
      "Processed 41629 (100.0%) in 0.50 sec. BPR loss is 2.03E+01. Sample per second: 82968\n",
      "SLIM_BPR_Recommender: Epoch 358 of 615. Elapsed time 1.65 min\n",
      "Processed 41629 (100.0%) in 0.77 sec. BPR loss is 1.97E+01. Sample per second: 53792\n",
      "SLIM_BPR_Recommender: Epoch 359 of 615. Elapsed time 1.65 min\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 1.97E+01. Sample per second: 39657\n",
      "SLIM_BPR_Recommender: Epoch 360 of 615. Elapsed time 1.66 min\n",
      "Processed 41629 (100.0%) in 0.32 sec. BPR loss is 2.00E+01. Sample per second: 128324\n",
      "SLIM_BPR_Recommender: Epoch 361 of 615. Elapsed time 1.66 min\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 2.02E+01. Sample per second: 69108\n",
      "SLIM_BPR_Recommender: Epoch 362 of 615. Elapsed time 1.66 min\n",
      "Processed 41629 (100.0%) in 0.88 sec. BPR loss is 2.04E+01. Sample per second: 47278\n",
      "SLIM_BPR_Recommender: Epoch 363 of 615. Elapsed time 1.67 min\n",
      "Processed 41629 (100.0%) in 1.15 sec. BPR loss is 2.04E+01. Sample per second: 36079\n",
      "SLIM_BPR_Recommender: Epoch 364 of 615. Elapsed time 1.67 min\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 1.98E+01. Sample per second: 98061\n",
      "SLIM_BPR_Recommender: Epoch 365 of 615. Elapsed time 1.68 min\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 2.03E+01. Sample per second: 60033\n",
      "SLIM_BPR_Recommender: Epoch 366 of 615. Elapsed time 1.68 min\n",
      "Processed 41629 (100.0%) in 0.96 sec. BPR loss is 2.04E+01. Sample per second: 43143\n",
      "SLIM_BPR_Recommender: Epoch 367 of 615. Elapsed time 1.69 min\n",
      "Processed 41629 (100.0%) in 1.24 sec. BPR loss is 2.01E+01. Sample per second: 33623\n",
      "SLIM_BPR_Recommender: Epoch 368 of 615. Elapsed time 1.69 min\n",
      "Processed 41629 (100.0%) in 0.51 sec. BPR loss is 2.02E+01. Sample per second: 81659\n",
      "SLIM_BPR_Recommender: Epoch 369 of 615. Elapsed time 1.70 min\n",
      "Processed 41629 (100.0%) in 0.79 sec. BPR loss is 2.01E+01. Sample per second: 53009\n",
      "SLIM_BPR_Recommender: Epoch 370 of 615. Elapsed time 1.70 min\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 1.99E+01. Sample per second: 39272\n",
      "SLIM_BPR_Recommender: Epoch 371 of 615. Elapsed time 1.71 min\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 2.07E+01. Sample per second: 123808\n",
      "SLIM_BPR_Recommender: Epoch 372 of 615. Elapsed time 1.71 min\n",
      "Processed 41629 (100.0%) in 0.61 sec. BPR loss is 2.05E+01. Sample per second: 67979\n",
      "SLIM_BPR_Recommender: Epoch 373 of 615. Elapsed time 1.71 min\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 2.06E+01. Sample per second: 46867\n",
      "SLIM_BPR_Recommender: Epoch 374 of 615. Elapsed time 1.72 min\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 2.04E+01. Sample per second: 35819\n",
      "SLIM_BPR_Recommender: Epoch 375 of 615. Elapsed time 1.72 min\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 2.04E+01. Sample per second: 95529\n",
      "SLIM_BPR_Recommender: Epoch 376 of 615. Elapsed time 1.73 min\n",
      "Processed 41629 (100.0%) in 0.70 sec. BPR loss is 2.03E+01. Sample per second: 59322\n",
      "SLIM_BPR_Recommender: Epoch 377 of 615. Elapsed time 1.73 min\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 2.07E+01. Sample per second: 42624\n",
      "SLIM_BPR_Recommender: Epoch 378 of 615. Elapsed time 1.74 min\n",
      "Processed 41629 (100.0%) in 1.25 sec. BPR loss is 2.07E+01. Sample per second: 33375\n",
      "SLIM_BPR_Recommender: Epoch 379 of 615. Elapsed time 1.74 min\n",
      "Processed 41629 (100.0%) in 0.52 sec. BPR loss is 2.04E+01. Sample per second: 80528\n",
      "SLIM_BPR_Recommender: Epoch 380 of 615. Elapsed time 1.75 min\n",
      "Processed 41629 (100.0%) in 0.79 sec. BPR loss is 2.04E+01. Sample per second: 52869\n",
      "SLIM_BPR_Recommender: Epoch 381 of 615. Elapsed time 1.75 min\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 2.04E+01. Sample per second: 38309\n",
      "SLIM_BPR_Recommender: Epoch 382 of 615. Elapsed time 1.76 min\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 2.07E+01. Sample per second: 115882\n",
      "SLIM_BPR_Recommender: Epoch 383 of 615. Elapsed time 1.76 min\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 2.09E+01. Sample per second: 65316\n",
      "SLIM_BPR_Recommender: Epoch 384 of 615. Elapsed time 1.77 min\n",
      "Processed 41629 (100.0%) in 0.91 sec. BPR loss is 2.03E+01. Sample per second: 45703\n",
      "SLIM_BPR_Recommender: Epoch 385 of 615. Elapsed time 1.77 min\n",
      "Processed 41629 (100.0%) in 1.19 sec. BPR loss is 2.01E+01. Sample per second: 34965\n",
      "SLIM_BPR_Recommender: Epoch 386 of 615. Elapsed time 1.77 min\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 2.04E+01. Sample per second: 90237\n",
      "SLIM_BPR_Recommender: Epoch 387 of 615. Elapsed time 1.78 min\n",
      "Processed 41629 (100.0%) in 0.73 sec. BPR loss is 2.05E+01. Sample per second: 56759\n",
      "SLIM_BPR_Recommender: Epoch 388 of 615. Elapsed time 1.78 min\n",
      "Processed 41629 (100.0%) in 1.00 sec. BPR loss is 2.07E+01. Sample per second: 41551\n",
      "SLIM_BPR_Recommender: Epoch 389 of 615. Elapsed time 1.79 min\n",
      "Processed 41629 (100.0%) in 0.27 sec. BPR loss is 2.05E+01. Sample per second: 154927\n",
      "SLIM_BPR_Recommender: Epoch 390 of 615. Elapsed time 1.79 min\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 2.04E+01. Sample per second: 77909\n",
      "SLIM_BPR_Recommender: Epoch 391 of 615. Elapsed time 1.80 min\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 2.06E+01. Sample per second: 51560\n",
      "SLIM_BPR_Recommender: Epoch 392 of 615. Elapsed time 1.80 min\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 2.07E+01. Sample per second: 38576\n",
      "SLIM_BPR_Recommender: Epoch 393 of 615. Elapsed time 1.81 min\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 2.09E+01. Sample per second: 118882\n",
      "SLIM_BPR_Recommender: Epoch 394 of 615. Elapsed time 1.81 min\n",
      "Processed 41629 (100.0%) in 0.62 sec. BPR loss is 2.07E+01. Sample per second: 66735\n",
      "SLIM_BPR_Recommender: Epoch 395 of 615. Elapsed time 1.82 min\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 2.03E+01. Sample per second: 46473\n",
      "SLIM_BPR_Recommender: Epoch 396 of 615. Elapsed time 1.82 min\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 2.04E+01. Sample per second: 35498\n",
      "SLIM_BPR_Recommender: Epoch 397 of 615. Elapsed time 1.82 min\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 2.07E+01. Sample per second: 93314\n",
      "SLIM_BPR_Recommender: Epoch 398 of 615. Elapsed time 1.83 min\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 2.08E+01. Sample per second: 57869\n",
      "SLIM_BPR_Recommender: Epoch 399 of 615. Elapsed time 1.83 min\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 2.07E+01. Sample per second: 41920\n",
      "SLIM_BPR_Recommender: Epoch 400 of 615. Elapsed time 1.84 min\n",
      "Processed 41629 (100.0%) in 1.26 sec. BPR loss is 2.09E+01. Sample per second: 32904\n",
      "SLIM_BPR_Recommender: Epoch 401 of 615. Elapsed time 1.84 min\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 2.10E+01. Sample per second: 77305\n",
      "SLIM_BPR_Recommender: Epoch 402 of 615. Elapsed time 1.85 min\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 2.07E+01. Sample per second: 51313\n",
      "SLIM_BPR_Recommender: Epoch 403 of 615. Elapsed time 1.85 min\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 2.09E+01. Sample per second: 38296\n",
      "SLIM_BPR_Recommender: Epoch 404 of 615. Elapsed time 1.86 min\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 2.03E+01. Sample per second: 114850\n",
      "SLIM_BPR_Recommender: Epoch 405 of 615. Elapsed time 1.86 min\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 2.07E+01. Sample per second: 65591\n",
      "SLIM_BPR_Recommender: Epoch 406 of 615. Elapsed time 1.87 min\n",
      "Processed 41629 (100.0%) in 0.91 sec. BPR loss is 2.06E+01. Sample per second: 45638\n",
      "SLIM_BPR_Recommender: Epoch 407 of 615. Elapsed time 1.87 min\n",
      "Processed 41629 (100.0%) in 1.18 sec. BPR loss is 2.10E+01. Sample per second: 35283\n",
      "SLIM_BPR_Recommender: Epoch 408 of 615. Elapsed time 1.87 min\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 2.06E+01. Sample per second: 92899\n",
      "SLIM_BPR_Recommender: Epoch 409 of 615. Elapsed time 1.88 min\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 2.10E+01. Sample per second: 57652\n",
      "SLIM_BPR_Recommender: Epoch 410 of 615. Elapsed time 1.88 min\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 2.11E+01. Sample per second: 41885\n",
      "SLIM_BPR_Recommender: Epoch 411 of 615. Elapsed time 1.89 min\n",
      "Processed 41629 (100.0%) in 1.27 sec. BPR loss is 2.11E+01. Sample per second: 32781\n",
      "SLIM_BPR_Recommender: Epoch 412 of 615. Elapsed time 1.89 min\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 2.10E+01. Sample per second: 76425\n",
      "SLIM_BPR_Recommender: Epoch 413 of 615. Elapsed time 1.90 min\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 2.09E+01. Sample per second: 50933\n",
      "SLIM_BPR_Recommender: Epoch 414 of 615. Elapsed time 1.90 min\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 2.12E+01. Sample per second: 38149\n",
      "SLIM_BPR_Recommender: Epoch 415 of 615. Elapsed time 1.91 min\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 2.12E+01. Sample per second: 114098\n",
      "SLIM_BPR_Recommender: Epoch 416 of 615. Elapsed time 1.91 min\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 2.13E+01. Sample per second: 64779\n",
      "SLIM_BPR_Recommender: Epoch 417 of 615. Elapsed time 1.92 min\n",
      "Processed 41629 (100.0%) in 0.92 sec. BPR loss is 2.11E+01. Sample per second: 45383\n",
      "SLIM_BPR_Recommender: Epoch 418 of 615. Elapsed time 1.92 min\n",
      "Processed 41629 (100.0%) in 1.19 sec. BPR loss is 2.10E+01. Sample per second: 34988\n",
      "SLIM_BPR_Recommender: Epoch 419 of 615. Elapsed time 1.92 min\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 2.07E+01. Sample per second: 90066\n",
      "SLIM_BPR_Recommender: Epoch 420 of 615. Elapsed time 1.93 min\n",
      "Processed 41629 (100.0%) in 0.74 sec. BPR loss is 2.09E+01. Sample per second: 56382\n",
      "SLIM_BPR_Recommender: Epoch 421 of 615. Elapsed time 1.93 min\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 2.11E+01. Sample per second: 39625\n",
      "SLIM_BPR_Recommender: Epoch 422 of 615. Elapsed time 1.94 min\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 2.06E+01. Sample per second: 127631\n",
      "SLIM_BPR_Recommender: Epoch 423 of 615. Elapsed time 1.94 min\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 2.12E+01. Sample per second: 69713\n",
      "SLIM_BPR_Recommender: Epoch 424 of 615. Elapsed time 1.95 min\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 2.10E+01. Sample per second: 47873\n",
      "SLIM_BPR_Recommender: Epoch 425 of 615. Elapsed time 1.95 min\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 2.13E+01. Sample per second: 36398\n",
      "SLIM_BPR_Recommender: Epoch 426 of 615. Elapsed time 1.96 min\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 2.12E+01. Sample per second: 98506\n",
      "SLIM_BPR_Recommender: Epoch 427 of 615. Elapsed time 1.96 min\n",
      "Processed 41629 (100.0%) in 0.70 sec. BPR loss is 2.14E+01. Sample per second: 59518\n",
      "SLIM_BPR_Recommender: Epoch 428 of 615. Elapsed time 1.97 min\n",
      "Processed 41629 (100.0%) in 0.97 sec. BPR loss is 2.08E+01. Sample per second: 42762\n",
      "SLIM_BPR_Recommender: Epoch 429 of 615. Elapsed time 1.97 min\n",
      "Processed 41629 (100.0%) in 1.24 sec. BPR loss is 2.14E+01. Sample per second: 33453\n",
      "SLIM_BPR_Recommender: Epoch 430 of 615. Elapsed time 1.98 min\n",
      "Processed 41629 (100.0%) in 0.52 sec. BPR loss is 2.15E+01. Sample per second: 79828\n",
      "SLIM_BPR_Recommender: Epoch 431 of 615. Elapsed time 1.98 min\n",
      "Processed 41629 (100.0%) in 0.79 sec. BPR loss is 2.13E+01. Sample per second: 52483\n",
      "SLIM_BPR_Recommender: Epoch 432 of 615. Elapsed time 1.98 min\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 2.12E+01. Sample per second: 38867\n",
      "SLIM_BPR_Recommender: Epoch 433 of 615. Elapsed time 1.99 min\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 2.17E+01. Sample per second: 121654\n",
      "SLIM_BPR_Recommender: Epoch 434 of 615. Elapsed time 1.99 min\n",
      "Processed 41629 (100.0%) in 0.62 sec. BPR loss is 2.11E+01. Sample per second: 67550\n",
      "SLIM_BPR_Recommender: Epoch 435 of 615. Elapsed time 2.00 min\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 2.12E+01. Sample per second: 46854\n",
      "SLIM_BPR_Recommender: Epoch 436 of 615. Elapsed time 2.00 min\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 2.14E+01. Sample per second: 35923\n",
      "SLIM_BPR_Recommender: Epoch 437 of 615. Elapsed time 2.01 min\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 2.14E+01. Sample per second: 95523\n",
      "SLIM_BPR_Recommender: Epoch 438 of 615. Elapsed time 2.01 min\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 2.13E+01. Sample per second: 57441\n",
      "SLIM_BPR_Recommender: Epoch 439 of 615. Elapsed time 2.02 min\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 2.11E+01. Sample per second: 41126\n",
      "SLIM_BPR_Recommender: Epoch 440 of 615. Elapsed time 2.02 min\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 2.13E+01. Sample per second: 144612\n",
      "SLIM_BPR_Recommender: Epoch 441 of 615. Elapsed time 2.03 min\n",
      "Processed 41629 (100.0%) in 0.56 sec. BPR loss is 2.16E+01. Sample per second: 74295\n",
      "SLIM_BPR_Recommender: Epoch 442 of 615. Elapsed time 2.03 min\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 2.12E+01. Sample per second: 49800\n",
      "SLIM_BPR_Recommender: Epoch 443 of 615. Elapsed time 2.04 min\n",
      "Processed 41629 (100.0%) in 1.12 sec. BPR loss is 2.12E+01. Sample per second: 37286\n",
      "SLIM_BPR_Recommender: Epoch 444 of 615. Elapsed time 2.04 min\n",
      "Processed 41629 (100.0%) in 0.39 sec. BPR loss is 2.16E+01. Sample per second: 105348\n",
      "SLIM_BPR_Recommender: Epoch 445 of 615. Elapsed time 2.04 min\n",
      "Processed 41629 (100.0%) in 0.67 sec. BPR loss is 2.14E+01. Sample per second: 62410\n",
      "SLIM_BPR_Recommender: Epoch 446 of 615. Elapsed time 2.05 min\n",
      "Processed 41629 (100.0%) in 0.94 sec. BPR loss is 2.10E+01. Sample per second: 44256\n",
      "SLIM_BPR_Recommender: Epoch 447 of 615. Elapsed time 2.05 min\n",
      "Processed 41629 (100.0%) in 1.22 sec. BPR loss is 2.15E+01. Sample per second: 34184\n",
      "SLIM_BPR_Recommender: Epoch 448 of 615. Elapsed time 2.06 min\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 2.11E+01. Sample per second: 85166\n",
      "SLIM_BPR_Recommender: Epoch 449 of 615. Elapsed time 2.06 min\n",
      "Processed 41629 (100.0%) in 0.77 sec. BPR loss is 2.13E+01. Sample per second: 54359\n",
      "SLIM_BPR_Recommender: Epoch 450 of 615. Elapsed time 2.07 min\n",
      "Processed 41629 (100.0%) in 1.04 sec. BPR loss is 2.16E+01. Sample per second: 39957\n",
      "SLIM_BPR_Recommender: Epoch 451 of 615. Elapsed time 2.07 min\n",
      "Processed 41629 (100.0%) in 0.32 sec. BPR loss is 2.17E+01. Sample per second: 131127\n",
      "SLIM_BPR_Recommender: Epoch 452 of 615. Elapsed time 2.08 min\n",
      "Processed 41629 (100.0%) in 0.59 sec. BPR loss is 2.15E+01. Sample per second: 70707\n",
      "SLIM_BPR_Recommender: Epoch 453 of 615. Elapsed time 2.08 min\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 2.17E+01. Sample per second: 47936\n",
      "SLIM_BPR_Recommender: Epoch 454 of 615. Elapsed time 2.09 min\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 2.13E+01. Sample per second: 36594\n",
      "SLIM_BPR_Recommender: Epoch 455 of 615. Elapsed time 2.09 min\n",
      "Processed 41629 (100.0%) in 0.41 sec. BPR loss is 2.20E+01. Sample per second: 102124\n",
      "SLIM_BPR_Recommender: Epoch 456 of 615. Elapsed time 2.09 min\n",
      "Processed 41629 (100.0%) in 0.68 sec. BPR loss is 2.14E+01. Sample per second: 60985\n",
      "SLIM_BPR_Recommender: Epoch 457 of 615. Elapsed time 2.10 min\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 2.14E+01. Sample per second: 43604\n",
      "SLIM_BPR_Recommender: Epoch 458 of 615. Elapsed time 2.10 min\n",
      "Processed 41629 (100.0%) in 1.22 sec. BPR loss is 2.15E+01. Sample per second: 34001\n",
      "SLIM_BPR_Recommender: Epoch 459 of 615. Elapsed time 2.11 min\n",
      "Processed 41629 (100.0%) in 0.50 sec. BPR loss is 2.11E+01. Sample per second: 83944\n",
      "SLIM_BPR_Recommender: Epoch 460 of 615. Elapsed time 2.11 min\n",
      "Processed 41629 (100.0%) in 0.78 sec. BPR loss is 2.21E+01. Sample per second: 53688\n",
      "SLIM_BPR_Recommender: Epoch 461 of 615. Elapsed time 2.12 min\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 2.16E+01. Sample per second: 38795\n",
      "SLIM_BPR_Recommender: Epoch 462 of 615. Elapsed time 2.12 min\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 2.13E+01. Sample per second: 120563\n",
      "SLIM_BPR_Recommender: Epoch 463 of 615. Elapsed time 2.13 min\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 2.16E+01. Sample per second: 66008\n",
      "SLIM_BPR_Recommender: Epoch 464 of 615. Elapsed time 2.13 min\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 2.18E+01. Sample per second: 46056\n",
      "SLIM_BPR_Recommender: Epoch 465 of 615. Elapsed time 2.14 min\n",
      "Processed 41629 (100.0%) in 1.18 sec. BPR loss is 2.16E+01. Sample per second: 35329\n",
      "SLIM_BPR_Recommender: Epoch 466 of 615. Elapsed time 2.14 min\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 2.15E+01. Sample per second: 92122\n",
      "SLIM_BPR_Recommender: Epoch 467 of 615. Elapsed time 2.15 min\n",
      "Processed 41629 (100.0%) in 0.73 sec. BPR loss is 2.17E+01. Sample per second: 56758\n",
      "SLIM_BPR_Recommender: Epoch 468 of 615. Elapsed time 2.15 min\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 2.16E+01. Sample per second: 41271\n",
      "SLIM_BPR_Recommender: Epoch 469 of 615. Elapsed time 2.15 min\n",
      "Processed 41629 (100.0%) in 0.31 sec. BPR loss is 2.15E+01. Sample per second: 132244\n",
      "SLIM_BPR_Recommender: Epoch 470 of 615. Elapsed time 2.16 min\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 2.17E+01. Sample per second: 69006\n",
      "SLIM_BPR_Recommender: Epoch 471 of 615. Elapsed time 2.16 min\n",
      "Processed 41629 (100.0%) in 0.91 sec. BPR loss is 2.16E+01. Sample per second: 45911\n",
      "SLIM_BPR_Recommender: Epoch 472 of 615. Elapsed time 2.17 min\n",
      "Processed 41629 (100.0%) in 1.20 sec. BPR loss is 2.15E+01. Sample per second: 34671\n",
      "SLIM_BPR_Recommender: Epoch 473 of 615. Elapsed time 2.17 min\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 2.17E+01. Sample per second: 85760\n",
      "SLIM_BPR_Recommender: Epoch 474 of 615. Elapsed time 2.18 min\n",
      "Processed 41629 (100.0%) in 0.77 sec. BPR loss is 2.17E+01. Sample per second: 53860\n",
      "SLIM_BPR_Recommender: Epoch 475 of 615. Elapsed time 2.18 min\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 2.15E+01. Sample per second: 39612\n",
      "SLIM_BPR_Recommender: Epoch 476 of 615. Elapsed time 2.19 min\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 2.17E+01. Sample per second: 124526\n",
      "SLIM_BPR_Recommender: Epoch 477 of 615. Elapsed time 2.19 min\n",
      "Processed 41629 (100.0%) in 0.61 sec. BPR loss is 2.18E+01. Sample per second: 67944\n",
      "SLIM_BPR_Recommender: Epoch 478 of 615. Elapsed time 2.20 min\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 2.24E+01. Sample per second: 46602\n",
      "SLIM_BPR_Recommender: Epoch 479 of 615. Elapsed time 2.20 min\n",
      "Processed 41629 (100.0%) in 1.18 sec. BPR loss is 2.17E+01. Sample per second: 35170\n",
      "SLIM_BPR_Recommender: Epoch 480 of 615. Elapsed time 2.21 min\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 2.17E+01. Sample per second: 89142\n",
      "SLIM_BPR_Recommender: Epoch 481 of 615. Elapsed time 2.21 min\n",
      "Processed 41629 (100.0%) in 0.74 sec. BPR loss is 2.17E+01. Sample per second: 56092\n",
      "SLIM_BPR_Recommender: Epoch 482 of 615. Elapsed time 2.22 min\n",
      "Processed 41629 (100.0%) in 1.02 sec. BPR loss is 2.21E+01. Sample per second: 40735\n",
      "SLIM_BPR_Recommender: Epoch 483 of 615. Elapsed time 2.22 min\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 2.18E+01. Sample per second: 140188\n",
      "SLIM_BPR_Recommender: Epoch 484 of 615. Elapsed time 2.23 min\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 2.22E+01. Sample per second: 72867\n",
      "SLIM_BPR_Recommender: Epoch 485 of 615. Elapsed time 2.23 min\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 2.16E+01. Sample per second: 49292\n",
      "SLIM_BPR_Recommender: Epoch 486 of 615. Elapsed time 2.24 min\n",
      "Processed 41629 (100.0%) in 1.12 sec. BPR loss is 2.20E+01. Sample per second: 37054\n",
      "SLIM_BPR_Recommender: Epoch 487 of 615. Elapsed time 2.24 min\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 2.17E+01. Sample per second: 103287\n",
      "SLIM_BPR_Recommender: Epoch 488 of 615. Elapsed time 2.24 min\n",
      "Processed 41629 (100.0%) in 0.68 sec. BPR loss is 2.21E+01. Sample per second: 61164\n",
      "SLIM_BPR_Recommender: Epoch 489 of 615. Elapsed time 2.25 min\n",
      "Processed 41629 (100.0%) in 0.96 sec. BPR loss is 2.19E+01. Sample per second: 43469\n",
      "SLIM_BPR_Recommender: Epoch 490 of 615. Elapsed time 2.25 min\n",
      "Processed 41629 (100.0%) in 1.23 sec. BPR loss is 2.24E+01. Sample per second: 33805\n",
      "SLIM_BPR_Recommender: Epoch 491 of 615. Elapsed time 2.26 min\n",
      "Processed 41629 (100.0%) in 0.51 sec. BPR loss is 2.18E+01. Sample per second: 81852\n",
      "SLIM_BPR_Recommender: Epoch 492 of 615. Elapsed time 2.26 min\n",
      "Processed 41629 (100.0%) in 0.78 sec. BPR loss is 2.17E+01. Sample per second: 53103\n",
      "SLIM_BPR_Recommender: Epoch 493 of 615. Elapsed time 2.27 min\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 2.22E+01. Sample per second: 39326\n",
      "SLIM_BPR_Recommender: Epoch 494 of 615. Elapsed time 2.27 min\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 2.20E+01. Sample per second: 125527\n",
      "SLIM_BPR_Recommender: Epoch 495 of 615. Elapsed time 2.28 min\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 2.21E+01. Sample per second: 68895\n",
      "SLIM_BPR_Recommender: Epoch 496 of 615. Elapsed time 2.28 min\n",
      "Processed 41629 (100.0%) in 0.88 sec. BPR loss is 2.21E+01. Sample per second: 47385\n",
      "SLIM_BPR_Recommender: Epoch 497 of 615. Elapsed time 2.29 min\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 2.14E+01. Sample per second: 35837\n",
      "SLIM_BPR_Recommender: Epoch 498 of 615. Elapsed time 2.29 min\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 2.19E+01. Sample per second: 95542\n",
      "SLIM_BPR_Recommender: Epoch 499 of 615. Elapsed time 2.30 min\n",
      "Processed 41629 (100.0%) in 0.71 sec. BPR loss is 2.20E+01. Sample per second: 58562\n",
      "SLIM_BPR_Recommender: Epoch 500 of 615. Elapsed time 2.30 min\n",
      "Processed 41629 (100.0%) in 1.00 sec. BPR loss is 2.22E+01. Sample per second: 41460\n",
      "SLIM_BPR_Recommender: Epoch 501 of 615. Elapsed time 2.30 min\n",
      "Processed 41629 (100.0%) in 0.28 sec. BPR loss is 2.23E+01. Sample per second: 147160\n",
      "SLIM_BPR_Recommender: Epoch 502 of 615. Elapsed time 2.31 min\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 2.20E+01. Sample per second: 73178\n",
      "SLIM_BPR_Recommender: Epoch 503 of 615. Elapsed time 2.31 min\n",
      "Processed 41629 (100.0%) in 0.85 sec. BPR loss is 2.19E+01. Sample per second: 48705\n",
      "SLIM_BPR_Recommender: Epoch 504 of 615. Elapsed time 2.32 min\n",
      "Processed 41629 (100.0%) in 1.13 sec. BPR loss is 2.21E+01. Sample per second: 36786\n",
      "SLIM_BPR_Recommender: Epoch 505 of 615. Elapsed time 2.32 min\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 2.22E+01. Sample per second: 103406\n",
      "SLIM_BPR_Recommender: Epoch 506 of 615. Elapsed time 2.33 min\n",
      "Processed 41629 (100.0%) in 0.67 sec. BPR loss is 2.20E+01. Sample per second: 61665\n",
      "SLIM_BPR_Recommender: Epoch 507 of 615. Elapsed time 2.33 min\n",
      "Processed 41629 (100.0%) in 0.94 sec. BPR loss is 2.19E+01. Sample per second: 44172\n",
      "SLIM_BPR_Recommender: Epoch 508 of 615. Elapsed time 2.34 min\n",
      "Processed 41629 (100.0%) in 1.22 sec. BPR loss is 2.25E+01. Sample per second: 34169\n",
      "SLIM_BPR_Recommender: Epoch 509 of 615. Elapsed time 2.34 min\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 2.19E+01. Sample per second: 85636\n",
      "SLIM_BPR_Recommender: Epoch 510 of 615. Elapsed time 2.35 min\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 2.20E+01. Sample per second: 55177\n",
      "SLIM_BPR_Recommender: Epoch 511 of 615. Elapsed time 2.35 min\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 2.18E+01. Sample per second: 40581\n",
      "SLIM_BPR_Recommender: Epoch 512 of 615. Elapsed time 2.36 min\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 2.21E+01. Sample per second: 139947\n",
      "SLIM_BPR_Recommender: Epoch 513 of 615. Elapsed time 2.36 min\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 2.22E+01. Sample per second: 71198\n",
      "SLIM_BPR_Recommender: Epoch 514 of 615. Elapsed time 2.36 min\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 2.21E+01. Sample per second: 48265\n",
      "SLIM_BPR_Recommender: Epoch 515 of 615. Elapsed time 2.37 min\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 2.25E+01. Sample per second: 36502\n",
      "SLIM_BPR_Recommender: Epoch 516 of 615. Elapsed time 2.37 min\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 2.24E+01. Sample per second: 98735\n",
      "SLIM_BPR_Recommender: Epoch 517 of 615. Elapsed time 2.38 min\n",
      "Processed 41629 (100.0%) in 0.70 sec. BPR loss is 2.23E+01. Sample per second: 59645\n",
      "SLIM_BPR_Recommender: Epoch 518 of 615. Elapsed time 2.38 min\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 2.26E+01. Sample per second: 42481\n",
      "SLIM_BPR_Recommender: Epoch 519 of 615. Elapsed time 2.39 min\n",
      "Processed 41629 (100.0%) in 1.26 sec. BPR loss is 2.19E+01. Sample per second: 33074\n",
      "SLIM_BPR_Recommender: Epoch 520 of 615. Elapsed time 2.39 min\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 2.25E+01. Sample per second: 78152\n",
      "SLIM_BPR_Recommender: Epoch 521 of 615. Elapsed time 2.40 min\n",
      "Processed 41629 (100.0%) in 0.80 sec. BPR loss is 2.27E+01. Sample per second: 51858\n",
      "SLIM_BPR_Recommender: Epoch 522 of 615. Elapsed time 2.40 min\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 2.21E+01. Sample per second: 38063\n",
      "SLIM_BPR_Recommender: Epoch 523 of 615. Elapsed time 2.41 min\n",
      "Processed 41629 (100.0%) in 0.37 sec. BPR loss is 2.26E+01. Sample per second: 113746\n",
      "SLIM_BPR_Recommender: Epoch 524 of 615. Elapsed time 2.41 min\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 2.23E+01. Sample per second: 64780\n",
      "SLIM_BPR_Recommender: Epoch 525 of 615. Elapsed time 2.42 min\n",
      "Processed 41629 (100.0%) in 0.93 sec. BPR loss is 2.23E+01. Sample per second: 44911\n",
      "SLIM_BPR_Recommender: Epoch 526 of 615. Elapsed time 2.42 min\n",
      "Processed 41629 (100.0%) in 1.21 sec. BPR loss is 2.25E+01. Sample per second: 34505\n",
      "SLIM_BPR_Recommender: Epoch 527 of 615. Elapsed time 2.42 min\n",
      "Processed 41629 (100.0%) in 0.48 sec. BPR loss is 2.24E+01. Sample per second: 86673\n",
      "SLIM_BPR_Recommender: Epoch 528 of 615. Elapsed time 2.43 min\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 2.22E+01. Sample per second: 55028\n",
      "SLIM_BPR_Recommender: Epoch 529 of 615. Elapsed time 2.43 min\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 2.25E+01. Sample per second: 40349\n",
      "SLIM_BPR_Recommender: Epoch 530 of 615. Elapsed time 2.44 min\n",
      "Processed 41629 (100.0%) in 0.31 sec. BPR loss is 2.22E+01. Sample per second: 136074\n",
      "SLIM_BPR_Recommender: Epoch 531 of 615. Elapsed time 2.44 min\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 2.23E+01. Sample per second: 71176\n",
      "SLIM_BPR_Recommender: Epoch 532 of 615. Elapsed time 2.45 min\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 2.28E+01. Sample per second: 48558\n",
      "SLIM_BPR_Recommender: Epoch 533 of 615. Elapsed time 2.45 min\n",
      "Processed 41629 (100.0%) in 1.13 sec. BPR loss is 2.24E+01. Sample per second: 36964\n",
      "SLIM_BPR_Recommender: Epoch 534 of 615. Elapsed time 2.46 min\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 2.28E+01. Sample per second: 105146\n",
      "SLIM_BPR_Recommender: Epoch 535 of 615. Elapsed time 2.46 min\n",
      "Processed 41629 (100.0%) in 0.67 sec. BPR loss is 2.26E+01. Sample per second: 62513\n",
      "SLIM_BPR_Recommender: Epoch 536 of 615. Elapsed time 2.47 min\n",
      "Processed 41629 (100.0%) in 0.94 sec. BPR loss is 2.23E+01. Sample per second: 44175\n",
      "SLIM_BPR_Recommender: Epoch 537 of 615. Elapsed time 2.47 min\n",
      "Processed 41629 (100.0%) in 1.21 sec. BPR loss is 2.25E+01. Sample per second: 34280\n",
      "SLIM_BPR_Recommender: Epoch 538 of 615. Elapsed time 2.47 min\n",
      "Processed 41629 (100.0%) in 0.48 sec. BPR loss is 2.25E+01. Sample per second: 85836\n",
      "SLIM_BPR_Recommender: Epoch 539 of 615. Elapsed time 2.48 min\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 2.19E+01. Sample per second: 54763\n",
      "SLIM_BPR_Recommender: Epoch 540 of 615. Elapsed time 2.48 min\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 2.24E+01. Sample per second: 39151\n",
      "SLIM_BPR_Recommender: Epoch 541 of 615. Elapsed time 2.49 min\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 2.20E+01. Sample per second: 124335\n",
      "SLIM_BPR_Recommender: Epoch 542 of 615. Elapsed time 2.49 min\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 2.29E+01. Sample per second: 68931\n",
      "SLIM_BPR_Recommender: Epoch 543 of 615. Elapsed time 2.50 min\n",
      "Processed 41629 (100.0%) in 0.88 sec. BPR loss is 2.22E+01. Sample per second: 47182\n",
      "SLIM_BPR_Recommender: Epoch 544 of 615. Elapsed time 2.50 min\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 2.31E+01. Sample per second: 35930\n",
      "SLIM_BPR_Recommender: Epoch 545 of 615. Elapsed time 2.51 min\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 2.26E+01. Sample per second: 96828\n",
      "SLIM_BPR_Recommender: Epoch 546 of 615. Elapsed time 2.51 min\n",
      "Processed 41629 (100.0%) in 0.71 sec. BPR loss is 2.26E+01. Sample per second: 58364\n",
      "SLIM_BPR_Recommender: Epoch 547 of 615. Elapsed time 2.52 min\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 2.31E+01. Sample per second: 41961\n",
      "SLIM_BPR_Recommender: Epoch 548 of 615. Elapsed time 2.52 min\n",
      "Processed 41629 (100.0%) in 1.26 sec. BPR loss is 2.23E+01. Sample per second: 32949\n",
      "SLIM_BPR_Recommender: Epoch 549 of 615. Elapsed time 2.53 min\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 2.27E+01. Sample per second: 77396\n",
      "SLIM_BPR_Recommender: Epoch 550 of 615. Elapsed time 2.53 min\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 2.24E+01. Sample per second: 51566\n",
      "SLIM_BPR_Recommender: Epoch 551 of 615. Elapsed time 2.53 min\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 2.28E+01. Sample per second: 38466\n",
      "SLIM_BPR_Recommender: Epoch 552 of 615. Elapsed time 2.54 min\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 2.24E+01. Sample per second: 118742\n",
      "SLIM_BPR_Recommender: Epoch 553 of 615. Elapsed time 2.54 min\n",
      "Processed 41629 (100.0%) in 0.62 sec. BPR loss is 2.26E+01. Sample per second: 66743\n",
      "SLIM_BPR_Recommender: Epoch 554 of 615. Elapsed time 2.55 min\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 2.30E+01. Sample per second: 46205\n",
      "SLIM_BPR_Recommender: Epoch 555 of 615. Elapsed time 2.55 min\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 2.28E+01. Sample per second: 35511\n",
      "SLIM_BPR_Recommender: Epoch 556 of 615. Elapsed time 2.56 min\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 2.24E+01. Sample per second: 94189\n",
      "SLIM_BPR_Recommender: Epoch 557 of 615. Elapsed time 2.56 min\n",
      "Processed 41629 (100.0%) in 0.71 sec. BPR loss is 2.31E+01. Sample per second: 58274\n",
      "SLIM_BPR_Recommender: Epoch 558 of 615. Elapsed time 2.57 min\n",
      "Processed 41629 (100.0%) in 0.99 sec. BPR loss is 2.29E+01. Sample per second: 42197\n",
      "SLIM_BPR_Recommender: Epoch 559 of 615. Elapsed time 2.57 min\n",
      "Processed 41629 (100.0%) in 1.25 sec. BPR loss is 2.28E+01. Sample per second: 33177\n",
      "SLIM_BPR_Recommender: Epoch 560 of 615. Elapsed time 2.58 min\n",
      "Processed 41629 (100.0%) in 0.52 sec. BPR loss is 2.29E+01. Sample per second: 80291\n",
      "SLIM_BPR_Recommender: Epoch 561 of 615. Elapsed time 2.58 min\n",
      "Processed 41629 (100.0%) in 0.78 sec. BPR loss is 2.27E+01. Sample per second: 53186\n",
      "SLIM_BPR_Recommender: Epoch 562 of 615. Elapsed time 2.58 min\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 2.28E+01. Sample per second: 39675\n",
      "SLIM_BPR_Recommender: Epoch 563 of 615. Elapsed time 2.59 min\n",
      "Processed 41629 (100.0%) in 0.32 sec. BPR loss is 2.28E+01. Sample per second: 131800\n",
      "SLIM_BPR_Recommender: Epoch 564 of 615. Elapsed time 2.59 min\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 2.27E+01. Sample per second: 71816\n",
      "SLIM_BPR_Recommender: Epoch 565 of 615. Elapsed time 2.60 min\n",
      "Processed 41629 (100.0%) in 0.85 sec. BPR loss is 2.28E+01. Sample per second: 48807\n",
      "SLIM_BPR_Recommender: Epoch 566 of 615. Elapsed time 2.60 min\n",
      "Processed 41629 (100.0%) in 1.12 sec. BPR loss is 2.31E+01. Sample per second: 37106\n",
      "SLIM_BPR_Recommender: Epoch 567 of 615. Elapsed time 2.61 min\n",
      "Processed 41629 (100.0%) in 0.39 sec. BPR loss is 2.25E+01. Sample per second: 106482\n",
      "SLIM_BPR_Recommender: Epoch 568 of 615. Elapsed time 2.61 min\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 2.29E+01. Sample per second: 62842\n",
      "SLIM_BPR_Recommender: Epoch 569 of 615. Elapsed time 2.62 min\n",
      "Processed 41629 (100.0%) in 0.94 sec. BPR loss is 2.31E+01. Sample per second: 44455\n",
      "SLIM_BPR_Recommender: Epoch 570 of 615. Elapsed time 2.62 min\n",
      "Processed 41629 (100.0%) in 1.21 sec. BPR loss is 2.32E+01. Sample per second: 34424\n",
      "SLIM_BPR_Recommender: Epoch 571 of 615. Elapsed time 2.62 min\n",
      "Processed 41629 (100.0%) in 0.48 sec. BPR loss is 2.30E+01. Sample per second: 86690\n",
      "SLIM_BPR_Recommender: Epoch 572 of 615. Elapsed time 2.63 min\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 2.29E+01. Sample per second: 55701\n",
      "SLIM_BPR_Recommender: Epoch 573 of 615. Elapsed time 2.63 min\n",
      "Processed 41629 (100.0%) in 1.02 sec. BPR loss is 2.27E+01. Sample per second: 40996\n",
      "SLIM_BPR_Recommender: Epoch 574 of 615. Elapsed time 2.64 min\n",
      "Processed 41629 (100.0%) in 0.28 sec. BPR loss is 2.34E+01. Sample per second: 145982\n",
      "SLIM_BPR_Recommender: Epoch 575 of 615. Elapsed time 2.64 min\n",
      "Processed 41629 (100.0%) in 0.56 sec. BPR loss is 2.31E+01. Sample per second: 74317\n",
      "SLIM_BPR_Recommender: Epoch 576 of 615. Elapsed time 2.65 min\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 2.26E+01. Sample per second: 49982\n",
      "SLIM_BPR_Recommender: Epoch 577 of 615. Elapsed time 2.65 min\n",
      "Processed 41629 (100.0%) in 1.11 sec. BPR loss is 2.29E+01. Sample per second: 37353\n",
      "SLIM_BPR_Recommender: Epoch 578 of 615. Elapsed time 2.66 min\n",
      "Processed 41629 (100.0%) in 0.38 sec. BPR loss is 2.31E+01. Sample per second: 108360\n",
      "SLIM_BPR_Recommender: Epoch 579 of 615. Elapsed time 2.66 min\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 2.31E+01. Sample per second: 63224\n",
      "SLIM_BPR_Recommender: Epoch 580 of 615. Elapsed time 2.67 min\n",
      "Processed 41629 (100.0%) in 0.93 sec. BPR loss is 2.32E+01. Sample per second: 44589\n",
      "SLIM_BPR_Recommender: Epoch 581 of 615. Elapsed time 2.67 min\n",
      "Processed 41629 (100.0%) in 1.24 sec. BPR loss is 2.31E+01. Sample per second: 33599\n",
      "SLIM_BPR_Recommender: Epoch 582 of 615. Elapsed time 2.68 min\n",
      "Processed 41629 (100.0%) in 0.51 sec. BPR loss is 2.33E+01. Sample per second: 82125\n",
      "SLIM_BPR_Recommender: Epoch 583 of 615. Elapsed time 2.68 min\n",
      "Processed 41629 (100.0%) in 0.80 sec. BPR loss is 2.29E+01. Sample per second: 52032\n",
      "SLIM_BPR_Recommender: Epoch 584 of 615. Elapsed time 2.68 min\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 2.32E+01. Sample per second: 38173\n",
      "SLIM_BPR_Recommender: Epoch 585 of 615. Elapsed time 2.69 min\n",
      "Processed 41629 (100.0%) in 0.39 sec. BPR loss is 2.37E+01. Sample per second: 107996\n",
      "SLIM_BPR_Recommender: Epoch 586 of 615. Elapsed time 2.69 min\n",
      "Processed 41629 (100.0%) in 0.67 sec. BPR loss is 2.32E+01. Sample per second: 62243\n",
      "SLIM_BPR_Recommender: Epoch 587 of 615. Elapsed time 2.70 min\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 2.37E+01. Sample per second: 43785\n",
      "SLIM_BPR_Recommender: Epoch 588 of 615. Elapsed time 2.70 min\n",
      "Processed 41629 (100.0%) in 1.23 sec. BPR loss is 2.30E+01. Sample per second: 33740\n",
      "SLIM_BPR_Recommender: Epoch 589 of 615. Elapsed time 2.71 min\n",
      "Processed 41629 (100.0%) in 0.51 sec. BPR loss is 2.32E+01. Sample per second: 81004\n",
      "SLIM_BPR_Recommender: Epoch 590 of 615. Elapsed time 2.71 min\n",
      "Processed 41629 (100.0%) in 0.79 sec. BPR loss is 2.34E+01. Sample per second: 52476\n",
      "SLIM_BPR_Recommender: Epoch 591 of 615. Elapsed time 2.72 min\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 2.31E+01. Sample per second: 39027\n",
      "SLIM_BPR_Recommender: Epoch 592 of 615. Elapsed time 2.72 min\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 2.38E+01. Sample per second: 119466\n",
      "SLIM_BPR_Recommender: Epoch 593 of 615. Elapsed time 2.73 min\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 2.37E+01. Sample per second: 66157\n",
      "SLIM_BPR_Recommender: Epoch 594 of 615. Elapsed time 2.73 min\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 2.33E+01. Sample per second: 46226\n",
      "SLIM_BPR_Recommender: Epoch 595 of 615. Elapsed time 2.74 min\n",
      "Processed 41629 (100.0%) in 1.18 sec. BPR loss is 2.30E+01. Sample per second: 35297\n",
      "SLIM_BPR_Recommender: Epoch 596 of 615. Elapsed time 2.74 min\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 2.36E+01. Sample per second: 90255\n",
      "SLIM_BPR_Recommender: Epoch 597 of 615. Elapsed time 2.75 min\n",
      "Processed 41629 (100.0%) in 0.74 sec. BPR loss is 2.34E+01. Sample per second: 56230\n",
      "SLIM_BPR_Recommender: Epoch 598 of 615. Elapsed time 2.75 min\n",
      "Processed 41629 (100.0%) in 1.02 sec. BPR loss is 2.32E+01. Sample per second: 40641\n",
      "SLIM_BPR_Recommender: Epoch 599 of 615. Elapsed time 2.76 min\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 2.34E+01. Sample per second: 138196\n",
      "SLIM_BPR_Recommender: Epoch 600 of 615. Elapsed time 2.76 min\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 2.34E+01. Sample per second: 71381\n",
      "SLIM_BPR_Recommender: Epoch 601 of 615. Elapsed time 2.76 min\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 2.30E+01. Sample per second: 48096\n",
      "SLIM_BPR_Recommender: Epoch 602 of 615. Elapsed time 2.77 min\n",
      "Processed 41629 (100.0%) in 1.15 sec. BPR loss is 2.32E+01. Sample per second: 36219\n",
      "SLIM_BPR_Recommender: Epoch 603 of 615. Elapsed time 2.77 min\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 2.32E+01. Sample per second: 96624\n",
      "SLIM_BPR_Recommender: Epoch 604 of 615. Elapsed time 2.78 min\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 2.35E+01. Sample per second: 58012\n",
      "SLIM_BPR_Recommender: Epoch 605 of 615. Elapsed time 2.78 min\n",
      "Processed 41629 (100.0%) in 1.00 sec. BPR loss is 2.31E+01. Sample per second: 41685\n",
      "SLIM_BPR_Recommender: Epoch 606 of 615. Elapsed time 2.79 min\n",
      "Processed 41629 (100.0%) in 0.28 sec. BPR loss is 2.37E+01. Sample per second: 150511\n",
      "SLIM_BPR_Recommender: Epoch 607 of 615. Elapsed time 2.79 min\n",
      "Processed 41629 (100.0%) in 0.55 sec. BPR loss is 2.31E+01. Sample per second: 76131\n",
      "SLIM_BPR_Recommender: Epoch 608 of 615. Elapsed time 2.80 min\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 2.34E+01. Sample per second: 50956\n",
      "SLIM_BPR_Recommender: Epoch 609 of 615. Elapsed time 2.80 min\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 2.34E+01. Sample per second: 38484\n",
      "SLIM_BPR_Recommender: Epoch 610 of 615. Elapsed time 2.81 min\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 2.35E+01. Sample per second: 117487\n",
      "SLIM_BPR_Recommender: Epoch 611 of 615. Elapsed time 2.81 min\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 2.33E+01. Sample per second: 65897\n",
      "SLIM_BPR_Recommender: Epoch 612 of 615. Elapsed time 2.82 min\n",
      "Processed 41629 (100.0%) in 0.91 sec. BPR loss is 2.34E+01. Sample per second: 45954\n",
      "SLIM_BPR_Recommender: Epoch 613 of 615. Elapsed time 2.82 min\n",
      "Processed 41629 (100.0%) in 1.18 sec. BPR loss is 2.39E+01. Sample per second: 35285\n",
      "SLIM_BPR_Recommender: Epoch 614 of 615. Elapsed time 2.82 min\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 2.36E+01. Sample per second: 92016\n",
      "SLIM_BPR_Recommender: Epoch 615 of 615. Elapsed time 2.83 min\n",
      "SLIM_BPR_Recommender: Terminating at epoch 615. Elapsed time 3.15 min\n",
      "Deallocating Cython objects\n"
     ]
    }
   ],
   "source": [
    "from Recommenders.SLIM.Cython.SLIM_BPR_Cython import SLIM_BPR_Cython\n",
    "recommender_SLIM_BPR_Cython = SLIM_BPR_Cython(URM_all)\n",
    "recommender_SLIM_BPR_Cython.fit(epochs= 615, sgd_mode= 'sgd', topK= 49, lambda_i= 0.0001, lambda_j= 0.0017579136035800475, learning_rate= 0.032671047315169746)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac38a3a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:10:27.005600Z",
     "iopub.status.busy": "2022-12-02T11:10:27.004971Z",
     "iopub.status.idle": "2022-12-02T11:11:32.316813Z",
     "shell.execute_reply": "2022-12-02T11:11:32.315522Z"
    },
    "papermill": {
     "duration": 65.398421,
     "end_time": "2022-12-02T11:11:32.319595",
     "exception": false,
     "start_time": "2022-12-02T11:10:26.921174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP of the starting models\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 40.24 sec. Users per second: 1027\n",
      "SLIM - MAP: 0.03458570998460277\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 25.03 sec. Users per second: 1652\n",
      "RP3beta - MAP: 0.03392776209024571\n"
     ]
    }
   ],
   "source": [
    "print(\"MAP of the starting models\")\n",
    "\n",
    "result_df, _ = evaluator_valid.evaluateRecommender(recommender_SLIMElasticNet)\n",
    "print(\"SLIM - MAP: {}\".format(result_df.loc[10][\"MAP\"]))\n",
    "\n",
    "result_df, _ = evaluator_valid.evaluateRecommender(RP3beta_all)\n",
    "print(\"RP3beta - MAP: {}\".format(result_df.loc[10][\"MAP\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7458cc92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:11:32.487114Z",
     "iopub.status.busy": "2022-12-02T11:11:32.486156Z",
     "iopub.status.idle": "2022-12-02T11:11:32.500891Z",
     "shell.execute_reply": "2022-12-02T11:11:32.499615Z"
    },
    "papermill": {
     "duration": 0.102536,
     "end_time": "2022-12-02T11:11:32.503651",
     "exception": false,
     "start_time": "2022-12-02T11:11:32.401115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "\n",
    "class DifferentLossScoresHybridRecommender(BaseRecommender):\n",
    "    \"\"\" ScoresHybridRecommender\n",
    "    Hybrid of four predictions scores\n",
    "    R = R1*alpha + R2*beta + R3*theta + R3*(1-alpha-beta-theta)\n",
    "    \n",
    "    Class from Dacrema exercise modified by Antonio Ercolani\n",
    "    The original took as input 2 recommender\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"DifferentLossScoresHybridRecommender\"\n",
    "\n",
    "\n",
    "    def __init__(self, URM_train, recommender_1, recommender_2, recommender_3, recommender_4):\n",
    "        super(DifferentLossScoresHybridRecommender, self).__init__(URM_train)\n",
    "\n",
    "        self.URM_train = sps.csr_matrix(URM_train)\n",
    "        self.recommender_1 = recommender_1\n",
    "        self.recommender_2 = recommender_2\n",
    "        self.recommender_3 = recommender_3\n",
    "        self.recommender_4 = recommender_4\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self, norm, alpha = 0.5, beta = 0.5, theta = 0):\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.theta = theta\n",
    "        self.norm = norm\n",
    "\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute):\n",
    "        \n",
    "        item_weights_1 = self.recommender_1._compute_item_score(user_id_array)\n",
    "        item_weights_2 = self.recommender_2._compute_item_score(user_id_array)\n",
    "        item_weights_3 = self.recommender_3._compute_item_score(user_id_array)\n",
    "        item_weights_4 = self.recommender_4._compute_item_score(user_id_array)\n",
    "\n",
    "        norm_item_weights_1 = LA.norm(item_weights_1, self.norm)\n",
    "        norm_item_weights_2 = LA.norm(item_weights_2, self.norm)\n",
    "        norm_item_weights_3 = LA.norm(item_weights_3, self.norm)\n",
    "        norm_item_weights_4 = LA.norm(item_weights_4, self.norm)\n",
    "        \n",
    "        \n",
    "        if norm_item_weights_1 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 1 is zero. Avoiding division by zero\".format(self.norm))\n",
    "        \n",
    "        if norm_item_weights_2 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 2 is zero. Avoiding division by zero\".format(self.norm))\n",
    "            \n",
    "        if norm_item_weights_3 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 3 is zero. Avoiding division by zero\".format(self.norm))\n",
    "            \n",
    "        if norm_item_weights_4 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 4 is zero. Avoiding division by zero\".format(self.norm))\n",
    "        \n",
    "        item_weights = item_weights_1 / norm_item_weights_1 * self.alpha + item_weights_2 / norm_item_weights_2 * self.beta + item_weights_3 / norm_item_weights_3 * self.theta + item_weights_4 / norm_item_weights_4 * (1-self.alpha-self.beta-self.theta)\n",
    "\n",
    "        return item_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3f788b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:11:32.759933Z",
     "iopub.status.busy": "2022-12-02T11:11:32.759545Z",
     "iopub.status.idle": "2022-12-02T11:36:24.960416Z",
     "shell.execute_reply": "2022-12-02T11:36:24.959077Z"
    },
    "papermill": {
     "duration": 1492.469739,
     "end_time": "2022-12-02T11:36:25.057073",
     "exception": false,
     "start_time": "2022-12-02T11:11:32.587334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.23 min. Users per second: 560\n",
      "Norm: 1, Alpha: 0.4481676635396029, Beta: 0.34490840535423567, Theta: 0.08754136378292977, Gamma: 0.11938256732323171, Result: 0.03813008764663454\n",
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.23 min. Users per second: 558\n",
      "Norm: 1, Alpha: 0.2064685472454021, Beta: 0.7928179637119308, Theta: 0.0002642262777013883, Gamma: 0.0004492627649657077, Result: 0.034650219913446266\n",
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.24 min. Users per second: 556\n",
      "Norm: 1, Alpha: 0.3975510044964625, Beta: 0.2846439048040098, Theta: 0.08862794490606411, Gamma: 0.2291771457934636, Result: 0.04223097997333898\n",
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.26 min. Users per second: 549\n",
      "Norm: 1, Alpha: 0.9468944546049125, Beta: 0.04751570022842514, Theta: 0.004504226926927876, Gamma: 0.0010856182397345204, Result: 0.034908221226052985\n",
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.26 min. Users per second: 547\n",
      "Norm: 1, Alpha: 0.8931299090603675, Beta: 0.08391454697396764, Theta: 0.019154769048751394, Gamma: 0.003800774916913552, Result: 0.03530836366191739\n",
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.26 min. Users per second: 549\n",
      "Norm: 1, Alpha: 0.39884815529946827, Beta: 0.010177669065234374, Theta: 0.03127314249236872, Gamma: 0.5597010331429286, Result: 0.051197679589580186\n",
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.25 min. Users per second: 551\n",
      "Norm: 1, Alpha: 0.4201628053714719, Beta: 0.5505322658271875, Theta: 0.003907740757664663, Gamma: 0.025397188043675967, Result: 0.035139485571886585\n",
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.25 min. Users per second: 549\n",
      "Norm: 1, Alpha: 0.07186047820021357, Beta: 0.2828612871567559, Theta: 0.45915704395670526, Gamma: 0.18612119068632527, Result: 0.05773933276727484\n",
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.25 min. Users per second: 550\n",
      "Norm: 1, Alpha: 0.12288872291039232, Beta: 0.1017346402262704, Theta: 0.030066015380456574, Gamma: 0.7453106214828806, Result: 0.05308209186786662\n",
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.24 min. Users per second: 555\n",
      "Norm: 1, Alpha: 0.24780234111632693, Beta: 0.6366249784589095, Theta: 0.07248480657964536, Gamma: 0.04308787384511814, Result: 0.035938903501140415\n",
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.26 min. Users per second: 547\n",
      "Norm: 1, Alpha: 0.13355862265908824, Beta: 0.42821463094465184, Theta: 0.0050972846812323115, Gamma: 0.43312946171502764, Result: 0.044763650167684195\n",
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.25 min. Users per second: 551\n",
      "Norm: 1, Alpha: 0.6919553210419599, Beta: 0.16460866719700615, Theta: 0.012926361259192472, Gamma: 0.1305096505018415, Result: 0.03771694011357066\n",
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.25 min. Users per second: 553\n",
      "Norm: 1, Alpha: 0.7966378939181868, Beta: 0.11672351438618253, Theta: 0.07298956328146908, Gamma: 0.01364902841416149, Result: 0.036341135047554436\n",
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.24 min. Users per second: 554\n",
      "Norm: 1, Alpha: 0.3285410665438554, Beta: 0.22100710957111802, Theta: 0.4065777019981808, Gamma: 0.04387412188684581, Result: 0.05143897569834359\n",
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.24 min. Users per second: 555\n",
      "Norm: 1, Alpha: 0.4004347671676416, Beta: 0.12114916849047103, Theta: 0.43459520563306986, Gamma: 0.04382085870881747, Result: 0.055183970377639356\n",
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.23 min. Users per second: 559\n",
      "Norm: 1, Alpha: 0.1056856739295502, Beta: 0.5165385746423772, Theta: 0.09790661107778648, Gamma: 0.2798691403502862, Result: 0.041724965907941655\n",
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.23 min. Users per second: 562\n",
      "Norm: 1, Alpha: 0.5453898502508582, Beta: 0.17495052912103204, Theta: 0.1948190533925399, Gamma: 0.08484056723556987, Result: 0.04224275234170323\n",
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.23 min. Users per second: 561\n",
      "Norm: 1, Alpha: 0.266724905598539, Beta: 0.20288623471434042, Theta: 0.14431622390076793, Gamma: 0.38607263578635265, Result: 0.04973447174497009\n",
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.24 min. Users per second: 558\n",
      "Norm: 1, Alpha: 0.3923603642933161, Beta: 0.25154483015716, Theta: 0.003802775808496987, Gamma: 0.3522920297410269, Result: 0.04396099104485702\n",
      "----\n",
      "EvaluatorHoldout: Processed 41333 (100.0%) in 1.23 min. Users per second: 559\n",
      "Norm: 1, Alpha: 0.250566125884653, Beta: 0.1663158546388771, Theta: 0.573487903866556, Gamma: 0.009630115609913892, Result: 0.06306916453627118\n",
      "----\n",
      "Best model has MAP: 0.06306916453627118 with alpha: 0.250566125884653, norm: 1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "recommender_object = DifferentLossScoresHybridRecommender(URM_train, recommender_SLIMElasticNet, RP3beta_all, EASE_R, recommender_SLIM_BPR_Cython)\n",
    "\n",
    "best_model = {\n",
    "    \"MAP\" : 0,\n",
    "    \"alpha\" : 0,\n",
    "    \"beta\": 0,\n",
    "    \"theta\": 0,\n",
    "    \"norm\" : 0\n",
    "}\n",
    "\n",
    "n_searches = 0\n",
    "\n",
    "for norm in [1,2]:\n",
    "    while n_searches<20:\n",
    "        alpha = random.uniform(0, 1)\n",
    "        beta = random.uniform(0, 1-alpha)\n",
    "        theta = random.uniform(0, 1- (alpha+beta))\n",
    "        print(\"----\")\n",
    "        recommender_object.fit(norm, alpha, beta, theta)\n",
    "\n",
    "        result_df, _ = evaluator_valid.evaluateRecommender(recommender_object)\n",
    "        print(\"Norm: {}, Alpha: {}, Beta: {}, Theta: {}, Gamma: {}, Result: {}\".format(norm, alpha, beta, theta, 1-(alpha+beta+theta), result_df.loc[10][\"MAP\"]))\n",
    "\n",
    "        if result_df.loc[10][\"MAP\"] > best_model[\"MAP\"]:\n",
    "            best_model[\"MAP\"] = result_df.loc[10][\"MAP\"]\n",
    "            best_model[\"alpha\"] = alpha\n",
    "            best_model[\"beta\"] = beta\n",
    "            best_model[\"theta\"] = theta\n",
    "            best_model[\"norm\"] = norm\n",
    "                \n",
    "        n_searches += 1\n",
    "print(\"----\")\n",
    "print(\"Best model has MAP: {} with alpha: {}, norm: {}\".format(best_model[\"MAP\"], best_model[\"alpha\"], best_model[\"norm\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9865b10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:36:25.230790Z",
     "iopub.status.busy": "2022-12-02T11:36:25.230062Z",
     "iopub.status.idle": "2022-12-02T11:36:25.274835Z",
     "shell.execute_reply": "2022-12-02T11:36:25.273536Z"
    },
    "papermill": {
     "duration": 0.135674,
     "end_time": "2022-12-02T11:36:25.277602",
     "exception": false,
     "start_time": "2022-12-02T11:36:25.141928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "recommender = DifferentLossScoresHybridRecommender(URM_all, recommender_SLIMElasticNet, RP3beta_all, EASE_R, recommender_SLIM_BPR_Cython)\n",
    "recommender.fit(1, 0.07510083706775092, 0.034152002358325294, 0.6216734083665473)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16d8c515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:36:25.449061Z",
     "iopub.status.busy": "2022-12-02T11:36:25.448659Z",
     "iopub.status.idle": "2022-12-02T11:36:25.489343Z",
     "shell.execute_reply": "2022-12-02T11:36:25.488398Z"
    },
    "papermill": {
     "duration": 0.129624,
     "end_time": "2022-12-02T11:36:25.491793",
     "exception": false,
     "start_time": "2022-12-02T11:36:25.362169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41111</th>\n",
       "      <td>41624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41112</th>\n",
       "      <td>41625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41113</th>\n",
       "      <td>41626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41114</th>\n",
       "      <td>41627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41115</th>\n",
       "      <td>41628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41116 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id\n",
       "0            0\n",
       "1            1\n",
       "2            2\n",
       "3            3\n",
       "4            4\n",
       "...        ...\n",
       "41111    41624\n",
       "41112    41625\n",
       "41113    41626\n",
       "41114    41627\n",
       "41115    41628\n",
       "\n",
       "[41116 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_users = pd.read_csv('/kaggle/input/competition-data/data_target_users_test.csv')\n",
    "test_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b041b308",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:36:25.662799Z",
     "iopub.status.busy": "2022-12-02T11:36:25.662376Z",
     "iopub.status.idle": "2022-12-02T11:38:16.104949Z",
     "shell.execute_reply": "2022-12-02T11:38:16.103844Z"
    },
    "papermill": {
     "duration": 110.531101,
     "end_time": "2022-12-02T11:38:16.107856",
     "exception": false,
     "start_time": "2022-12-02T11:36:25.576755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_id = test_users['user_id']\n",
    "recommendations = []\n",
    "for user in user_id:\n",
    "    recommendations.append(recommender.recommend(user,cutoff = 10, remove_seen_flag = True))\n",
    "for index in range(len(recommendations)):\n",
    "    recommendations[index]=np.array(recommendations[index])\n",
    "    \n",
    "test_users['item_list']= recommendations\n",
    "test_users['item_list'] = pd.DataFrame([str(line).strip('[').strip(']').replace(\"'\",\"\") for line in test_users['item_list']])\n",
    "test_users.to_csv('submission4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83582792",
   "metadata": {
    "papermill": {
     "duration": 0.086993,
     "end_time": "2022-12-02T11:38:16.280467",
     "exception": false,
     "start_time": "2022-12-02T11:38:16.193474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4911.459422,
   "end_time": "2022-12-02T11:38:19.096333",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-02T10:16:27.636911",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
